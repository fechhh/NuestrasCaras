{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import re    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametros notebook\n",
    "DIM = 30\n",
    "seed = 42\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# planteamos distintas pruebas\n",
    "\n",
    "#n_pca: cantidad de componentes principales a considerar\n",
    "#excl_n_prim_comp: excluir las primeras excl_n_prim_comp componenetes principales (0 no se excluye ninguna)\n",
    "#nueronas_layer_1: neuronas capa oculta 1\n",
    "#nueronas_layer_2: neuronas capa oculta 2\n",
    "#n_epochs: cantidad de epochs... NO SE TOMA EN CUENTA... SE HARDCODEA MÁS ABAJO!!!\n",
    "\n",
    "# PARA LA ULTIMA PARTE DE LA NOTEBOOK ES IMPORTANTE TENER A MANO LOS PARAMETROS\n",
    "# \"n_pca\" y \"excl_n_prim_comp\" del modelo seleccionado!!!\n",
    "\n",
    "pruebas = {\n",
    "    #\"prueba_1\": {\"n_pca\":100, \"excl_n_prim_comp\":5, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_2\": {\"n_pca\":150, \"excl_n_prim_comp\":5, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_3\": {\"n_pca\":170, \"excl_n_prim_comp\":5, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_4\": {\"n_pca\":50, \"excl_n_prim_comp\":5, \"nueronas_layer_1\":36, \"nueronas_layer_2\":22, \"n_epochs\":100},\n",
    "    \"prueba_4_1\": {\"n_pca\":60, \"excl_n_prim_comp\":5, \"nueronas_layer_1\":40, \"nueronas_layer_2\":25, \"n_epochs\":100},\n",
    "    #\"prueba_4_2\": {\"n_pca\":40, \"excl_n_prim_comp\":3, \"nueronas_layer_1\":32, \"nueronas_layer_2\":22, \"n_epochs\":100},\n",
    "    #\"prueba_5\": {\"n_pca\":100, \"excl_n_prim_comp\":4, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_6\": {\"n_pca\":100, \"excl_n_prim_comp\":3, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_7\": {\"n_pca\":100, \"excl_n_prim_comp\":2, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_8\": {\"n_pca\":100, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_9\": {\"n_pca\":100, \"excl_n_prim_comp\":5, \"nueronas_layer_1\":60, \"nueronas_layer_2\":40, \"n_epochs\":100},\n",
    "    #\"prueba_10\": {\"n_pca\":100, \"excl_n_prim_comp\":5, \"nueronas_layer_1\":60, \"nueronas_layer_2\":20, \"n_epochs\":100},\n",
    "    #\"prueba_11\": {\"n_pca\":100, \"excl_n_prim_comp\":5, \"nueronas_layer_1\":50, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    \"prueba_12\": {\"n_pca\":100, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    \"prueba_13\": {\"n_pca\":100, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":45, \"nueronas_layer_2\":26, \"n_epochs\":100},\n",
    "    \"prueba_14\": {\"n_pca\":100, \"excl_n_prim_comp\":3, \"nueronas_layer_1\":45, \"nueronas_layer_2\":26, \"n_epochs\":100},\n",
    "    #\"prueba_14\": {\"n_pca\":60, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":40, \"nueronas_layer_2\":25, \"n_epochs\":100},\n",
    "    #\"prueba_15\": {\"n_pca\":60, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":36, \"nueronas_layer_2\":22, \"n_epochs\":100},\n",
    "    #\"prueba_16\": {\"n_pca\":40, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_17\": {\"n_pca\":100, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_18\": {\"n_pca\":100, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCIONES DE LA NOTEBOOK (podrian ir en un script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defino funciones utiles\n",
    "def eliminar_numeros(texto):\n",
    "    return re.sub(r'\\d+', '', texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defino funcion para cortar caras de una imagen\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import face_recognition\n",
    "from PIL import Image\n",
    "\n",
    "def cortar_imagenes(input_dir, output_dir, dim=DIM):\n",
    "    # Cargamos el detector de rostros de la libreria face_recognition\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    i = 0\n",
    "    # Para cada archivo del directorio de imput comenzamos el loop\n",
    "    for filename in os.listdir(input_dir):\n",
    "        i += 1\n",
    "        # Cargamos la imagen\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        img = cv2.imread(input_path)\n",
    "\n",
    "        # Detectamos el rostro en la imagen\n",
    "        face_locations = face_recognition.face_locations(img)\n",
    "        \n",
    "        # Cortamos y cambiamos a escala de grises\n",
    "        for (top, right, bottom, left) in face_locations:\n",
    "            face = img[top:bottom, left:right]\n",
    "            face = cv2.resize(face, (dim, dim))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Guardamos el proceso en la carpeta de salida\n",
    "            output_path = os.path.join(output_dir, f\"{filename}\")\n",
    "            cv2.imwrite(output_path, face)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defino funcion para generar nuevas caras\n",
    "# Generar imagenes aleatorias a partir de imagenes existentes\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "def gen_new_image(folder_path, prefix, cantidad_imagenes):\n",
    "\n",
    "    # obtiene nombre de los archivos con las imagenes\n",
    "    file_names = os.listdir(folder_path)\n",
    "\n",
    "    # itera sobre los archivos\n",
    "    for file_name in file_names:\n",
    "        # arma ruta a la imagen\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # carga la imagen\n",
    "        img = image.load_img(file_path)\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "\n",
    "        # crea un generador de datos con aumentos\n",
    "        datagen = ImageDataGenerator(\n",
    "            rotation_range=3,\n",
    "            width_shift_range=0.025,\n",
    "            height_shift_range=0.025,\n",
    "            shear_range=0.025,\n",
    "            zoom_range=0.025,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode=\"nearest\",\n",
    "        )\n",
    "\n",
    "        # separa nombre archivo y extension (a usar en el nombre de la nueva imagen generada)\n",
    "        name, ext = os.path.splitext(file_name)\n",
    "\n",
    "        # inicializa el bucle para las 'cantidad_imagenes' a generar\n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, batch_size=1):\n",
    "            # define nombre de la nueva imagen generada segun prefijo\n",
    "            new_filename = f\"{name}_{prefix}_{i}{ext}\"\n",
    "\n",
    "            # guarda la imagen aumentada\n",
    "            new_file_path = os.path.join(folder_path, new_filename)\n",
    "            img_augmented = image.array_to_img(batch[0])\n",
    "            img_augmented.save(new_file_path)\n",
    "            i += 1\n",
    "            if i >= cantidad_imagenes:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defino funcion para entrenar \n",
    "def run_keras_model(n_pca, excl_n_prim_comp, nueronas_layer_1, nueronas_layer_2, n_epochs, imagenes, nombres, nuevas_imagenes, nuevos_nombres):\n",
    "    \n",
    "    # Dividir en entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(imagenes, nombres, test_size=0.05, random_state=42, stratify=nombres)\n",
    "\n",
    "    # Aplicar PCA\n",
    "    pca = PCA(n_components=n_pca, random_state=seed)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    #X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    # Escalar los datos \n",
    "    scaler = StandardScaler()\n",
    "    #scaler = MinMaxScaler()\n",
    "    X_train_pca_scaled = scaler.fit_transform(X_train_pca)\n",
    "    #X_test_pca_scaled = scaler.transform(X_test_pca)\n",
    "    \n",
    "    \n",
    "    # Codificar las etiquetas\n",
    "    encoder = LabelEncoder()\n",
    "    y_train_encoded = encoder.fit_transform(y_train)\n",
    "    #y_test_encoded = encoder.transform(y_test)\n",
    "    y_train_categorical = to_categorical(y_train_encoded, num_classes=18)\n",
    "    #y_test_categorical = to_categorical(y_test_encoded, num_classes=18)\n",
    "    \n",
    "    \n",
    "    # Definir la red neuronal\n",
    "    entreno_con = X_train_pca_scaled[:,excl_n_prim_comp:]\n",
    "    #testeo_con = X_test_pca_scaled[:,excl_n_prim_comp:]\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=entreno_con.shape[1:]))  # Definir la entrada del modelo\n",
    "    model.add(Dense(nueronas_layer_1, activation='sigmoid'))\n",
    "    model.add(Dense(nueronas_layer_2, activation='sigmoid'))\n",
    "    model.add(Dense(y_train_categorical.shape[1], activation='softmax'))\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    model.fit(entreno_con, y_train_categorical, epochs=n_epochs, batch_size=10, validation_split=0.3)\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    #loss, accuracy = model.evaluate(testeo_con, y_test_categorical)\n",
    "    #print(f'Precisión en el conjunto de prueba: {accuracy * 100:.2f}%')\n",
    "    \n",
    "    \n",
    "    # PREDICCIONES\n",
    "    # 2. Aplicar PCA\n",
    "    new_images_pca = pca.transform(nuevas_imagenes)\n",
    "    new_images_pca_scaled = scaler.transform(new_images_pca)\n",
    "    evaluo_con = new_images_pca_scaled[:,excl_n_prim_comp:]\n",
    "\n",
    "    # 3. Hacer predicciones\n",
    "    predictions = model.predict(evaluo_con)\n",
    "\n",
    "    # Obtener los nombres correspondientes a las clases predichas\n",
    "    predicted_names = encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
    "\n",
    "    # Imprimir las predicciones\n",
    "    total_predict = len(nuevos_nombres)\n",
    "    total_correcto = 0\n",
    "    for real, pred in zip(nuevos_nombres, predicted_names):\n",
    "        if real == pred:\n",
    "            total_correcto += 1\n",
    "    \n",
    "    # devuelve resultado corrida\n",
    "    resultado = total_correcto/total_predict\n",
    "    return resultado, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo de uso\n",
    "#cortar_imagenes(input_dir=\"fotos/Recorte manual\", output_dir=\"fotos/Recorte manual otutput 35\")\n",
    "#gen_new_image(folder_path=\"fotos/Recorte manual otutput 35\", prefix=\"gen_aut\", cantidad_imagenes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEER IMAGENES PARA ENTRENAMIENTO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración inicial\n",
    "dim_imagenes = DIM\n",
    "data_dir = \"fotos_probamos_distintas_opciones/entrenamiento\"\n",
    "nombres = []\n",
    "imagenes = []\n",
    "\n",
    "# Cargar imágenes y etiquetas\n",
    "for archivo in os.listdir(data_dir):\n",
    "    if archivo.endswith('.jpeg') or archivo.endswith('.jpg'):\n",
    "        nombre = archivo.split('_')[0].replace(\".jpg\",\"\").replace(\".jpeg\",\"\")\n",
    "        nombre = eliminar_numeros(nombre)\n",
    "        ruta_imagen = os.path.join(data_dir, archivo)\n",
    "        imagen = Image.open(ruta_imagen)\n",
    "        imagen = np.array(imagen.resize((dim_imagenes, dim_imagenes)))  # Redimensionar imágenes para un tamaño uniforme\n",
    "        if len(imagen.shape) == 3 and imagen.shape[2] == 3:\n",
    "            imagen = cv2.cvtColor(imagen, cv2.COLOR_RGB2GRAY)  # Convertir a escala de grises si es necesario\n",
    "        imagenes.append(imagen.flatten())\n",
    "        nombres.append(nombre)\n",
    "\n",
    "imagenes_all = np.array(imagenes)\n",
    "nombres_all = np.array(nombres)\n",
    "\n",
    "# estand\n",
    "imagenes_all = imagenes_all/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10261, 900)\n",
      "(10261,)\n"
     ]
    }
   ],
   "source": [
    "print(imagenes_all.shape)\n",
    "print(nombres_all.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEER IMAGENES PARA PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración inicial\n",
    "data_dir = (\"fotos_probamos_distintas_opciones/predict\")  # Cambia esto a la ruta de tu directorio de imágenes\n",
    "nombres = []\n",
    "imagenes = []\n",
    "\n",
    "# Cargar imágenes y etiquetas\n",
    "for archivo in os.listdir(data_dir):\n",
    "    if archivo.endswith('.jpeg') or archivo.endswith('.jpg'):\n",
    "        nombre = archivo.split('_')[0].replace(\".jpg\",\"\").replace(\".jpeg\",\"\")\n",
    "        nombre = eliminar_numeros(nombre)\n",
    "        ruta_imagen = os.path.join(data_dir, archivo)\n",
    "        imagen = Image.open(ruta_imagen)\n",
    "        imagen = np.array(imagen.resize((dim_imagenes, dim_imagenes)))  # Redimensionar imágenes para un tamaño uniforme\n",
    "        if len(imagen.shape) == 3 and imagen.shape[2] == 3:\n",
    "            imagen = cv2.cvtColor(imagen, cv2.COLOR_RGB2GRAY)  # Convertir a escala de grises si es necesario\n",
    "        imagenes.append(imagen.flatten())\n",
    "        nombres.append(nombre)\n",
    "\n",
    "new_images = np.array(imagenes)\n",
    "nombres_new = np.array(nombres)\n",
    "\n",
    "# estand\n",
    "new_images = new_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 900)\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "print(new_images.shape)\n",
    "print(nombres_new.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prueba_4_1: \n",
      "Epoch 1/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1076 - loss: 2.8648 - val_accuracy: 0.3115 - val_loss: 2.5534\n",
      "Epoch 2/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3903 - loss: 2.4060 - val_accuracy: 0.4988 - val_loss: 1.9761\n",
      "Epoch 3/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5553 - loss: 1.8331 - val_accuracy: 0.6003 - val_loss: 1.5449\n",
      "Epoch 4/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6473 - loss: 1.4312 - val_accuracy: 0.6605 - val_loss: 1.2665\n",
      "Epoch 5/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7014 - loss: 1.1673 - val_accuracy: 0.6937 - val_loss: 1.0874\n",
      "Epoch 6/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7347 - loss: 0.9939 - val_accuracy: 0.7176 - val_loss: 0.9669\n",
      "Epoch 7/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7599 - loss: 0.8734 - val_accuracy: 0.7460 - val_loss: 0.8783\n",
      "Epoch 8/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7830 - loss: 0.7827 - val_accuracy: 0.7665 - val_loss: 0.8082\n",
      "Epoch 9/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8012 - loss: 0.7097 - val_accuracy: 0.7805 - val_loss: 0.7499\n",
      "Epoch 10/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8172 - loss: 0.6483 - val_accuracy: 0.7962 - val_loss: 0.7003\n",
      "Epoch 11/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8308 - loss: 0.5951 - val_accuracy: 0.8062 - val_loss: 0.6572\n",
      "Epoch 12/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8466 - loss: 0.5483 - val_accuracy: 0.8168 - val_loss: 0.6193\n",
      "Epoch 13/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8576 - loss: 0.5065 - val_accuracy: 0.8284 - val_loss: 0.5857\n",
      "Epoch 14/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8736 - loss: 0.4691 - val_accuracy: 0.8369 - val_loss: 0.5557\n",
      "Epoch 15/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8865 - loss: 0.4352 - val_accuracy: 0.8434 - val_loss: 0.5287\n",
      "Epoch 16/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8961 - loss: 0.4045 - val_accuracy: 0.8513 - val_loss: 0.5044\n",
      "Epoch 17/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9011 - loss: 0.3765 - val_accuracy: 0.8595 - val_loss: 0.4823\n",
      "Epoch 18/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9078 - loss: 0.3509 - val_accuracy: 0.8626 - val_loss: 0.4623\n",
      "Epoch 19/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.3275 - val_accuracy: 0.8677 - val_loss: 0.4442\n",
      "Epoch 20/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9238 - loss: 0.3061 - val_accuracy: 0.8732 - val_loss: 0.4277\n",
      "Epoch 21/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9303 - loss: 0.2863 - val_accuracy: 0.8769 - val_loss: 0.4126\n",
      "Epoch 22/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9363 - loss: 0.2681 - val_accuracy: 0.8817 - val_loss: 0.3989\n",
      "Epoch 23/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9405 - loss: 0.2511 - val_accuracy: 0.8862 - val_loss: 0.3864\n",
      "Epoch 24/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9461 - loss: 0.2354 - val_accuracy: 0.8879 - val_loss: 0.3749\n",
      "Epoch 25/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9509 - loss: 0.2207 - val_accuracy: 0.8892 - val_loss: 0.3643\n",
      "Epoch 26/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9540 - loss: 0.2070 - val_accuracy: 0.8930 - val_loss: 0.3546\n",
      "Epoch 27/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9585 - loss: 0.1942 - val_accuracy: 0.8974 - val_loss: 0.3456\n",
      "Epoch 28/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9628 - loss: 0.1821 - val_accuracy: 0.9002 - val_loss: 0.3373\n",
      "Epoch 29/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9671 - loss: 0.1708 - val_accuracy: 0.9009 - val_loss: 0.3296\n",
      "Epoch 30/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.1602 - val_accuracy: 0.9019 - val_loss: 0.3225\n",
      "Epoch 31/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9708 - loss: 0.1503 - val_accuracy: 0.9043 - val_loss: 0.3158\n",
      "Epoch 32/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9740 - loss: 0.1410 - val_accuracy: 0.9067 - val_loss: 0.3097\n",
      "Epoch 33/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9774 - loss: 0.1322 - val_accuracy: 0.9094 - val_loss: 0.3041\n",
      "Epoch 34/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9810 - loss: 0.1240 - val_accuracy: 0.9097 - val_loss: 0.2988\n",
      "Epoch 35/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9822 - loss: 0.1164 - val_accuracy: 0.9115 - val_loss: 0.2941\n",
      "Epoch 36/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9843 - loss: 0.1092 - val_accuracy: 0.9121 - val_loss: 0.2897\n",
      "Epoch 37/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9856 - loss: 0.1025 - val_accuracy: 0.9125 - val_loss: 0.2858\n",
      "Epoch 38/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9881 - loss: 0.0963 - val_accuracy: 0.9132 - val_loss: 0.2822\n",
      "Epoch 39/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9896 - loss: 0.0905 - val_accuracy: 0.9145 - val_loss: 0.2791\n",
      "Epoch 40/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9905 - loss: 0.0850 - val_accuracy: 0.9145 - val_loss: 0.2762\n",
      "Epoch 41/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0799 - val_accuracy: 0.9162 - val_loss: 0.2736\n",
      "Epoch 42/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9928 - loss: 0.0750 - val_accuracy: 0.9162 - val_loss: 0.2713\n",
      "Epoch 43/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9935 - loss: 0.0704 - val_accuracy: 0.9173 - val_loss: 0.2692\n",
      "Epoch 44/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0661 - val_accuracy: 0.9186 - val_loss: 0.2673\n",
      "Epoch 45/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0619 - val_accuracy: 0.9197 - val_loss: 0.2658\n",
      "Epoch 46/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9952 - loss: 0.0579 - val_accuracy: 0.9217 - val_loss: 0.2644\n",
      "Epoch 47/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9966 - loss: 0.0542 - val_accuracy: 0.9217 - val_loss: 0.2634\n",
      "Epoch 48/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9971 - loss: 0.0506 - val_accuracy: 0.9231 - val_loss: 0.2625\n",
      "Epoch 49/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9974 - loss: 0.0473 - val_accuracy: 0.9244 - val_loss: 0.2618\n",
      "Epoch 50/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0442 - val_accuracy: 0.9251 - val_loss: 0.2613\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "prueba_12: \n",
      "Epoch 1/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1704 - loss: 2.7889 - val_accuracy: 0.4981 - val_loss: 2.1645\n",
      "Epoch 2/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5861 - loss: 1.9075 - val_accuracy: 0.7303 - val_loss: 1.2813\n",
      "Epoch 3/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7909 - loss: 1.1190 - val_accuracy: 0.8267 - val_loss: 0.8300\n",
      "Epoch 4/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8700 - loss: 0.7174 - val_accuracy: 0.8759 - val_loss: 0.5993\n",
      "Epoch 5/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9073 - loss: 0.5044 - val_accuracy: 0.9019 - val_loss: 0.4663\n",
      "Epoch 6/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9328 - loss: 0.3761 - val_accuracy: 0.9162 - val_loss: 0.3790\n",
      "Epoch 7/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9520 - loss: 0.2897 - val_accuracy: 0.9296 - val_loss: 0.3163\n",
      "Epoch 8/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9620 - loss: 0.2269 - val_accuracy: 0.9395 - val_loss: 0.2689\n",
      "Epoch 9/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9710 - loss: 0.1794 - val_accuracy: 0.9470 - val_loss: 0.2320\n",
      "Epoch 10/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9797 - loss: 0.1425 - val_accuracy: 0.9521 - val_loss: 0.2029\n",
      "Epoch 11/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.1131 - val_accuracy: 0.9569 - val_loss: 0.1798\n",
      "Epoch 12/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9889 - loss: 0.0895 - val_accuracy: 0.9607 - val_loss: 0.1616\n",
      "Epoch 13/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9940 - loss: 0.0705 - val_accuracy: 0.9631 - val_loss: 0.1470\n",
      "Epoch 14/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9968 - loss: 0.0553 - val_accuracy: 0.9668 - val_loss: 0.1353\n",
      "Epoch 15/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0432 - val_accuracy: 0.9682 - val_loss: 0.1257\n",
      "Epoch 16/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0337 - val_accuracy: 0.9692 - val_loss: 0.1178\n",
      "Epoch 17/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0263 - val_accuracy: 0.9699 - val_loss: 0.1113\n",
      "Epoch 18/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0206 - val_accuracy: 0.9706 - val_loss: 0.1058\n",
      "Epoch 19/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0161 - val_accuracy: 0.9733 - val_loss: 0.1013\n",
      "Epoch 20/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0125 - val_accuracy: 0.9737 - val_loss: 0.0975\n",
      "Epoch 21/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.9750 - val_loss: 0.0945\n",
      "Epoch 22/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 0.9771 - val_loss: 0.0920\n",
      "Epoch 23/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.9774 - val_loss: 0.0900\n",
      "Epoch 24/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9781 - val_loss: 0.0885\n",
      "Epoch 25/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9785 - val_loss: 0.0873\n",
      "Epoch 26/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9785 - val_loss: 0.0863\n",
      "Epoch 27/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9788 - val_loss: 0.0857\n",
      "Epoch 28/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9795 - val_loss: 0.0852\n",
      "Epoch 29/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9795 - val_loss: 0.0848\n",
      "Epoch 30/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.5428e-04 - val_accuracy: 0.9798 - val_loss: 0.0847\n",
      "Epoch 31/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3248e-04 - val_accuracy: 0.9798 - val_loss: 0.0846\n",
      "Epoch 32/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.6148e-04 - val_accuracy: 0.9805 - val_loss: 0.0847\n",
      "Epoch 33/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.2983e-04 - val_accuracy: 0.9805 - val_loss: 0.0849\n",
      "Epoch 34/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.2865e-04 - val_accuracy: 0.9812 - val_loss: 0.0852\n",
      "Epoch 35/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5100e-04 - val_accuracy: 0.9809 - val_loss: 0.0855\n",
      "Epoch 36/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9149e-04 - val_accuracy: 0.9819 - val_loss: 0.0859\n",
      "Epoch 37/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4595e-04 - val_accuracy: 0.9819 - val_loss: 0.0864\n",
      "Epoch 38/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1115e-04 - val_accuracy: 0.9826 - val_loss: 0.0870\n",
      "Epoch 39/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4587e-05 - val_accuracy: 0.9826 - val_loss: 0.0875\n",
      "Epoch 40/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.4342e-05 - val_accuracy: 0.9826 - val_loss: 0.0882\n",
      "Epoch 41/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8921e-05 - val_accuracy: 0.9826 - val_loss: 0.0888\n",
      "Epoch 42/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.7191e-05 - val_accuracy: 0.9829 - val_loss: 0.0896\n",
      "Epoch 43/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8273e-05 - val_accuracy: 0.9832 - val_loss: 0.0903\n",
      "Epoch 44/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1497e-05 - val_accuracy: 0.9836 - val_loss: 0.0911\n",
      "Epoch 45/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6351e-05 - val_accuracy: 0.9836 - val_loss: 0.0919\n",
      "Epoch 46/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.2447e-05 - val_accuracy: 0.9836 - val_loss: 0.0927\n",
      "Epoch 47/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4821e-06 - val_accuracy: 0.9843 - val_loss: 0.0936\n",
      "Epoch 48/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.2359e-06 - val_accuracy: 0.9843 - val_loss: 0.0944\n",
      "Epoch 49/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5339e-06 - val_accuracy: 0.9846 - val_loss: 0.0953\n",
      "Epoch 50/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.2429e-06 - val_accuracy: 0.9853 - val_loss: 0.0962\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "prueba_13: \n",
      "Epoch 1/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1352 - loss: 2.8304 - val_accuracy: 0.4246 - val_loss: 2.3772\n",
      "Epoch 2/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5615 - loss: 2.1202 - val_accuracy: 0.7046 - val_loss: 1.5023\n",
      "Epoch 3/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7634 - loss: 1.3024 - val_accuracy: 0.8031 - val_loss: 0.9805\n",
      "Epoch 4/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8526 - loss: 0.8425 - val_accuracy: 0.8533 - val_loss: 0.7065\n",
      "Epoch 5/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8937 - loss: 0.5930 - val_accuracy: 0.8879 - val_loss: 0.5441\n",
      "Epoch 6/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9253 - loss: 0.4412 - val_accuracy: 0.9118 - val_loss: 0.4372\n",
      "Epoch 7/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9422 - loss: 0.3401 - val_accuracy: 0.9248 - val_loss: 0.3623\n",
      "Epoch 8/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9544 - loss: 0.2687 - val_accuracy: 0.9361 - val_loss: 0.3073\n",
      "Epoch 9/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9637 - loss: 0.2159 - val_accuracy: 0.9439 - val_loss: 0.2658\n",
      "Epoch 10/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9758 - loss: 0.1755 - val_accuracy: 0.9504 - val_loss: 0.2337\n",
      "Epoch 11/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9811 - loss: 0.1440 - val_accuracy: 0.9538 - val_loss: 0.2087\n",
      "Epoch 12/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9850 - loss: 0.1189 - val_accuracy: 0.9556 - val_loss: 0.1888\n",
      "Epoch 13/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9896 - loss: 0.0985 - val_accuracy: 0.9593 - val_loss: 0.1725\n",
      "Epoch 14/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0818 - val_accuracy: 0.9610 - val_loss: 0.1590\n",
      "Epoch 15/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9945 - loss: 0.0678 - val_accuracy: 0.9648 - val_loss: 0.1476\n",
      "Epoch 16/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9954 - loss: 0.0561 - val_accuracy: 0.9675 - val_loss: 0.1379\n",
      "Epoch 17/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9969 - loss: 0.0462 - val_accuracy: 0.9679 - val_loss: 0.1296\n",
      "Epoch 18/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0378 - val_accuracy: 0.9689 - val_loss: 0.1226\n",
      "Epoch 19/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0309 - val_accuracy: 0.9696 - val_loss: 0.1168\n",
      "Epoch 20/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0252 - val_accuracy: 0.9706 - val_loss: 0.1118\n",
      "Epoch 21/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0206 - val_accuracy: 0.9720 - val_loss: 0.1076\n",
      "Epoch 22/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0168 - val_accuracy: 0.9723 - val_loss: 0.1040\n",
      "Epoch 23/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0136 - val_accuracy: 0.9726 - val_loss: 0.1009\n",
      "Epoch 24/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0110 - val_accuracy: 0.9737 - val_loss: 0.0984\n",
      "Epoch 25/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 0.9733 - val_loss: 0.0964\n",
      "Epoch 26/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9726 - val_loss: 0.0948\n",
      "Epoch 27/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.9737 - val_loss: 0.0935\n",
      "Epoch 28/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9737 - val_loss: 0.0925\n",
      "Epoch 29/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9744 - val_loss: 0.0917\n",
      "Epoch 30/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9740 - val_loss: 0.0911\n",
      "Epoch 31/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9744 - val_loss: 0.0907\n",
      "Epoch 32/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9744 - val_loss: 0.0905\n",
      "Epoch 33/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9757 - val_loss: 0.0904\n",
      "Epoch 34/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9761 - val_loss: 0.0904\n",
      "Epoch 35/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.6967e-04 - val_accuracy: 0.9768 - val_loss: 0.0905\n",
      "Epoch 36/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7169e-04 - val_accuracy: 0.9761 - val_loss: 0.0907\n",
      "Epoch 37/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1336e-04 - val_accuracy: 0.9764 - val_loss: 0.0909\n",
      "Epoch 38/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.8689e-04 - val_accuracy: 0.9768 - val_loss: 0.0913\n",
      "Epoch 39/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8603e-04 - val_accuracy: 0.9764 - val_loss: 0.0917\n",
      "Epoch 40/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.0571e-04 - val_accuracy: 0.9761 - val_loss: 0.0921\n",
      "Epoch 41/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4184e-04 - val_accuracy: 0.9761 - val_loss: 0.0926\n",
      "Epoch 42/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9112e-04 - val_accuracy: 0.9761 - val_loss: 0.0931\n",
      "Epoch 43/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5090e-04 - val_accuracy: 0.9761 - val_loss: 0.0937\n",
      "Epoch 44/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1903e-04 - val_accuracy: 0.9764 - val_loss: 0.0943\n",
      "Epoch 45/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.3820e-05 - val_accuracy: 0.9768 - val_loss: 0.0950\n",
      "Epoch 46/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.3886e-05 - val_accuracy: 0.9771 - val_loss: 0.0957\n",
      "Epoch 47/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.8151e-05 - val_accuracy: 0.9774 - val_loss: 0.0965\n",
      "Epoch 48/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.5741e-05 - val_accuracy: 0.9774 - val_loss: 0.0973\n",
      "Epoch 49/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5955e-05 - val_accuracy: 0.9764 - val_loss: 0.0981\n",
      "Epoch 50/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8256e-05 - val_accuracy: 0.9768 - val_loss: 0.0989\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "prueba_14: \n",
      "Epoch 1/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1285 - loss: 2.8482 - val_accuracy: 0.3364 - val_loss: 2.4151\n",
      "Epoch 2/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4566 - loss: 2.2149 - val_accuracy: 0.6038 - val_loss: 1.7071\n",
      "Epoch 3/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6569 - loss: 1.5556 - val_accuracy: 0.7074 - val_loss: 1.2644\n",
      "Epoch 4/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7539 - loss: 1.1484 - val_accuracy: 0.7638 - val_loss: 0.9988\n",
      "Epoch 5/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8057 - loss: 0.8937 - val_accuracy: 0.7969 - val_loss: 0.8254\n",
      "Epoch 6/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8416 - loss: 0.7214 - val_accuracy: 0.8178 - val_loss: 0.7031\n",
      "Epoch 7/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8667 - loss: 0.5969 - val_accuracy: 0.8410 - val_loss: 0.6121\n",
      "Epoch 8/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8912 - loss: 0.5027 - val_accuracy: 0.8564 - val_loss: 0.5415\n",
      "Epoch 9/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.4285 - val_accuracy: 0.8745 - val_loss: 0.4850\n",
      "Epoch 10/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9189 - loss: 0.3682 - val_accuracy: 0.8865 - val_loss: 0.4387\n",
      "Epoch 11/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9318 - loss: 0.3181 - val_accuracy: 0.8964 - val_loss: 0.4001\n",
      "Epoch 12/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9413 - loss: 0.2757 - val_accuracy: 0.9067 - val_loss: 0.3674\n",
      "Epoch 13/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9533 - loss: 0.2392 - val_accuracy: 0.9118 - val_loss: 0.3395\n",
      "Epoch 14/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9602 - loss: 0.2075 - val_accuracy: 0.9173 - val_loss: 0.3153\n",
      "Epoch 15/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9686 - loss: 0.1799 - val_accuracy: 0.9217 - val_loss: 0.2945\n",
      "Epoch 16/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9740 - loss: 0.1557 - val_accuracy: 0.9279 - val_loss: 0.2765\n",
      "Epoch 17/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9803 - loss: 0.1345 - val_accuracy: 0.9323 - val_loss: 0.2610\n",
      "Epoch 18/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9840 - loss: 0.1162 - val_accuracy: 0.9357 - val_loss: 0.2479\n",
      "Epoch 19/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9894 - loss: 0.1003 - val_accuracy: 0.9354 - val_loss: 0.2367\n",
      "Epoch 20/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.0865 - val_accuracy: 0.9381 - val_loss: 0.2273\n",
      "Epoch 21/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0745 - val_accuracy: 0.9398 - val_loss: 0.2193\n",
      "Epoch 22/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9956 - loss: 0.0641 - val_accuracy: 0.9422 - val_loss: 0.2126\n",
      "Epoch 23/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9972 - loss: 0.0549 - val_accuracy: 0.9436 - val_loss: 0.2071\n",
      "Epoch 24/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0469 - val_accuracy: 0.9453 - val_loss: 0.2025\n",
      "Epoch 25/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0400 - val_accuracy: 0.9439 - val_loss: 0.1985\n",
      "Epoch 26/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0342 - val_accuracy: 0.9450 - val_loss: 0.1951\n",
      "Epoch 27/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0292 - val_accuracy: 0.9456 - val_loss: 0.1920\n",
      "Epoch 28/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0249 - val_accuracy: 0.9467 - val_loss: 0.1894\n",
      "Epoch 29/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0212 - val_accuracy: 0.9474 - val_loss: 0.1871\n",
      "Epoch 30/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0180 - val_accuracy: 0.9480 - val_loss: 0.1852\n",
      "Epoch 31/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0153 - val_accuracy: 0.9491 - val_loss: 0.1836\n",
      "Epoch 32/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 0.9491 - val_loss: 0.1824\n",
      "Epoch 33/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.9504 - val_loss: 0.1814\n",
      "Epoch 34/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.9511 - val_loss: 0.1806\n",
      "Epoch 35/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.9525 - val_loss: 0.1802\n",
      "Epoch 36/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.9532 - val_loss: 0.1799\n",
      "Epoch 37/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9532 - val_loss: 0.1799\n",
      "Epoch 38/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9528 - val_loss: 0.1800\n",
      "Epoch 39/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9521 - val_loss: 0.1804\n",
      "Epoch 40/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9521 - val_loss: 0.1809\n",
      "Epoch 41/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9515 - val_loss: 0.1816\n",
      "Epoch 42/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9518 - val_loss: 0.1824\n",
      "Epoch 43/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9518 - val_loss: 0.1833\n",
      "Epoch 44/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9525 - val_loss: 0.1844\n",
      "Epoch 45/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9518 - val_loss: 0.1856\n",
      "Epoch 46/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9515 - val_loss: 0.1870\n",
      "Epoch 47/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.1099e-04 - val_accuracy: 0.9515 - val_loss: 0.1884\n",
      "Epoch 48/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5729e-04 - val_accuracy: 0.9521 - val_loss: 0.1901\n",
      "Epoch 49/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.2910e-04 - val_accuracy: 0.9521 - val_loss: 0.1919\n",
      "Epoch 50/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2227e-04 - val_accuracy: 0.9525 - val_loss: 0.1938\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prueba_4_1': 0.6333333333333333,\n",
       " 'prueba_12': 0.5333333333333333,\n",
       " 'prueba_13': 0.6333333333333333,\n",
       " 'prueba_14': 0.6}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PRUEBAS CON epochs 500 # SI TARDA MUCHO PROBAR CON 250...\n",
    "resutados = {}\n",
    "modelos_500 = {}\n",
    "for prueba, params in pruebas.items():\n",
    "    print(f\"{prueba}: \")\n",
    "    resultado, modelo = run_keras_model(n_pca=params.get('n_pca'), \n",
    "                    excl_n_prim_comp=params.get('excl_n_prim_comp'), \n",
    "                    nueronas_layer_1=params.get('nueronas_layer_1'),\n",
    "                    nueronas_layer_2=params.get('nueronas_layer_2'),\n",
    "                    n_epochs=500, # NO TOMA EL QUE DEFINIMOS EN PRUEBAS\n",
    "                    imagenes=imagenes_all,\n",
    "                    nombres=nombres_all,\n",
    "                    nuevas_imagenes=new_images,\n",
    "                    nuevos_nombres=nombres_new\n",
    "                    )\n",
    "    resutados[prueba]=resultado\n",
    "    modelos_500[prueba]=modelo\n",
    "resutados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRUEBAS CON epochs 200\n",
    "resutados = {}\n",
    "modelos_200 = {}\n",
    "for prueba, params in pruebas.items():\n",
    "    print(f\"{prueba}: \")\n",
    "    resultado, modelo = run_keras_model(n_pca=params.get('n_pca'), \n",
    "                    excl_n_prim_comp=params.get('excl_n_prim_comp'), \n",
    "                    nueronas_layer_1=params.get('nueronas_layer_1'),\n",
    "                    nueronas_layer_2=params.get('nueronas_layer_2'),\n",
    "                    n_epochs=200, # NO TOMA EL QUE DEFINIMOS EN PRUEBAS\n",
    "                    imagenes=imagenes_all,\n",
    "                    nombres=nombres_all,\n",
    "                    nuevas_imagenes=new_images,\n",
    "                    nuevos_nombres=nombres_new\n",
    "                    )\n",
    "    resutados[prueba]=resultado\n",
    "    modelos_200[prueba]=modelo\n",
    "resutados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebo predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si cargo nuevas fotos es importante correr esta parte (con True en lugar de False)\n",
    "# hacer check manual que TOME BIEN LAS CARAS (puede pasar que recorte algo que NO es una cara)\n",
    "if False:\n",
    "    cortar_imagenes(input_dir=\"fotos_probamos_distintas_opciones/probar_nuevas_fotos_input\", output_dir=\"fotos_probamos_distintas_opciones/probar_nuevas_fotos_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 900)\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "# importo imagenes predict 2\n",
    "data_dir = (\"fotos_probamos_distintas_opciones/probar_nuevas_fotos_output\")  # Cambia esto a la ruta de tu directorio de imágenes\n",
    "nombres = []\n",
    "imagenes = []\n",
    "\n",
    "# Cargar imágenes y etiquetas\n",
    "for archivo in os.listdir(data_dir):\n",
    "    if archivo.endswith('.jpeg') or archivo.endswith('.jpg'):\n",
    "        nombre = archivo.split('_')[0].replace(\".jpg\",\"\").replace(\".jpeg\",\"\")\n",
    "        nombre = eliminar_numeros(nombre)\n",
    "        ruta_imagen = os.path.join(data_dir, archivo)\n",
    "        imagen = Image.open(ruta_imagen)\n",
    "        imagen = np.array(imagen.resize((dim_imagenes, dim_imagenes)))  # Redimensionar imágenes para un tamaño uniforme\n",
    "        if len(imagen.shape) == 3 and imagen.shape[2] == 3:\n",
    "            imagen = cv2.cvtColor(imagen, cv2.COLOR_RGB2GRAY)  # Convertir a escala de grises si es necesario\n",
    "        imagenes.append(imagen.flatten())\n",
    "        nombres.append(nombre)\n",
    "\n",
    "new_images = np.array(imagenes)\n",
    "nombres_new = np.array(nombres)\n",
    "\n",
    "# estand\n",
    "new_images = new_images/255.0\n",
    "print(new_images.shape)\n",
    "print(nombres_new.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nombres_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_predict2(model, n_pca, excl_n_prim_comp, imagenes, nombres, nuevas_imagenes, nuevos_nombres):\n",
    "    \n",
    "    # Dividir en entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(imagenes, nombres, test_size=0.05, random_state=42, stratify=nombres)\n",
    "\n",
    "    # Aplicar PCA\n",
    "    pca = PCA(n_components=n_pca, random_state=12)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    #X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    # Escalar los datos \n",
    "    scaler = StandardScaler()\n",
    "    #scaler = MinMaxScaler()\n",
    "    X_train_pca_scaled = scaler.fit_transform(X_train_pca)\n",
    "    #X_test_pca_scaled = scaler.transform(X_test_pca)\n",
    "    \n",
    "    \n",
    "    # Codificar las etiquetas\n",
    "    encoder = LabelEncoder()\n",
    "    y_train_encoded = encoder.fit_transform(y_train)\n",
    "    #y_test_encoded = encoder.transform(y_test)\n",
    "    y_train_categorical = to_categorical(y_train_encoded, num_classes=18)\n",
    "    #y_test_categorical = to_categorical(y_test_encoded, num_classes=18)\n",
    "    \n",
    "    \n",
    "    # Definir la red neuronal\n",
    "    entreno_con = X_train_pca_scaled[:,excl_n_prim_comp:]\n",
    "    #testeo_con = X_test_pca_scaled[:,excl_n_prim_comp:]    \n",
    "    \n",
    "    # PREDICCIONES\n",
    "    # 2. Aplicar PCA\n",
    "    new_images_pca = pca.transform(nuevas_imagenes)\n",
    "    new_images_pca_scaled = scaler.transform(new_images_pca)\n",
    "    evaluo_con = new_images_pca_scaled[:,excl_n_prim_comp:]\n",
    "\n",
    "    # 3. Hacer predicciones\n",
    "    predictions = model.predict(evaluo_con)\n",
    "\n",
    "    # Obtener los nombres correspondientes a las clases predichas\n",
    "    predicted_names = encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
    "\n",
    "    # Imprimir las predicciones\n",
    "    total_predict = len(nuevos_nombres)\n",
    "    total_correcto = 0\n",
    "    for real, pred in zip(nuevos_nombres, predicted_names):\n",
    "        if real == pred:\n",
    "            total_correcto += 1\n",
    "         \n",
    "    # df predicciones        \n",
    "    df_preds = pd.DataFrame(predictions.round(2))\n",
    "    class_names = encoder.classes_\n",
    "    df_preds.columns = class_names\n",
    "    \n",
    "    # devuelve resultado corrida\n",
    "    resultado = total_correcto/total_predict\n",
    "    return resultado, df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000017AC9257420> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n"
     ]
    }
   ],
   "source": [
    "resultado13, df_preds13 = get_preds_predict2(\n",
    "    model=modelos_500[\"prueba_13\"], \n",
    "    n_pca=100, \n",
    "    excl_n_prim_comp=0, \n",
    "    imagenes=imagenes_all, \n",
    "    nombres=nombres_all, \n",
    "    nuevas_imagenes=new_images, \n",
    "    nuevos_nombres=nombres_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carlos</th>\n",
       "      <th>federicoG</th>\n",
       "      <th>federicoR</th>\n",
       "      <th>florencia</th>\n",
       "      <th>francoA</th>\n",
       "      <th>francoS</th>\n",
       "      <th>gerard</th>\n",
       "      <th>gustavo</th>\n",
       "      <th>joaquin</th>\n",
       "      <th>juan</th>\n",
       "      <th>lautaro</th>\n",
       "      <th>lisandro</th>\n",
       "      <th>marco</th>\n",
       "      <th>matias</th>\n",
       "      <th>natalia</th>\n",
       "      <th>noelia</th>\n",
       "      <th>paola</th>\n",
       "      <th>victorio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carlos  federicoG  federicoR  florencia  francoA  francoS  gerard  gustavo  \\\n",
       "0    0.89        0.0        0.0        0.0      0.0      0.0    0.01      0.0   \n",
       "1    0.01        0.0        0.0        0.0      0.0      0.0    0.00      0.0   \n",
       "2    0.00        0.0        0.0        0.0      0.0      0.0    0.01      0.0   \n",
       "3    0.00        0.0        0.0        0.0      0.0      0.0    0.00      0.3   \n",
       "\n",
       "   joaquin  juan  lautaro  lisandro  marco  matias  natalia  noelia  paola  \\\n",
       "0      0.0   0.0     0.07      0.00   0.02    0.00      0.0    0.00    0.0   \n",
       "1      0.0   0.0     0.95      0.00   0.00    0.00      0.0    0.04    0.0   \n",
       "2      0.0   0.0     0.99      0.00   0.00    0.00      0.0    0.00    0.0   \n",
       "3      0.0   0.0     0.01      0.46   0.20    0.01      0.0    0.00    0.0   \n",
       "\n",
       "   victorio  \n",
       "0      0.01  \n",
       "1      0.00  \n",
       "2      0.00  \n",
       "3      0.02  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
     ]
    }
   ],
   "source": [
    "resultado14, df_preds14 = get_preds_predict2(\n",
    "    model=modelos_500[\"prueba_14\"], \n",
    "    n_pca=100, \n",
    "    excl_n_prim_comp=3, \n",
    "    imagenes=imagenes_all, \n",
    "    nombres=nombres_all, \n",
    "    nuevas_imagenes=new_images, \n",
    "    nuevos_nombres=nombres_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carlos</th>\n",
       "      <th>federicoG</th>\n",
       "      <th>federicoR</th>\n",
       "      <th>florencia</th>\n",
       "      <th>francoA</th>\n",
       "      <th>francoS</th>\n",
       "      <th>gerard</th>\n",
       "      <th>gustavo</th>\n",
       "      <th>joaquin</th>\n",
       "      <th>juan</th>\n",
       "      <th>lautaro</th>\n",
       "      <th>lisandro</th>\n",
       "      <th>marco</th>\n",
       "      <th>matias</th>\n",
       "      <th>natalia</th>\n",
       "      <th>noelia</th>\n",
       "      <th>paola</th>\n",
       "      <th>victorio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carlos  federicoG  federicoR  florencia  francoA  francoS  gerard  gustavo  \\\n",
       "0     0.0        0.0        0.0        0.0      0.0      0.0    0.00      0.0   \n",
       "1     0.0        0.0        0.0        0.0      0.0      0.0    0.00      0.0   \n",
       "2     0.0        0.0        0.0        0.0      0.0      0.0    0.99      0.0   \n",
       "3     0.0        0.0        0.0        0.0      0.0      0.0    0.00      0.0   \n",
       "\n",
       "   joaquin  juan  lautaro  lisandro  marco  matias  natalia  noelia  paola  \\\n",
       "0      0.0   0.0     1.00      0.00    0.0    0.00      0.0     0.0   0.00   \n",
       "1      0.0   0.0     0.86      0.00    0.0    0.09      0.0     0.0   0.00   \n",
       "2      0.0   0.0     0.01      0.00    0.0    0.00      0.0     0.0   0.00   \n",
       "3      0.0   0.0     0.01      0.67    0.3    0.00      0.0     0.0   0.01   \n",
       "\n",
       "   victorio  \n",
       "0      0.00  \n",
       "1      0.05  \n",
       "2      0.00  \n",
       "3      0.00  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds14"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nuestras_caras_grupo_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

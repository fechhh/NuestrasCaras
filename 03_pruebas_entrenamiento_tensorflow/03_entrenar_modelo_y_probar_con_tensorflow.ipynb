{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y evaluación modelo de reconocimiento de caras con Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea de esta notebook es realizar el entrenamiento y evaluación de un modelo mediane tensorflow y keras.\n",
    "\n",
    "Las imagenes para ajustar y evaluar los modelos son las mismas de la notebook \"01_entrenar_modelo\\01_entrenar_modelo.ipynb\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import re    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define los parámetros de ejecución de la notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametros notebook\n",
    "DIM = 30\n",
    "seed = 42\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define los modelos a entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# planteamos distintas pruebas\n",
    "\n",
    "#n_pca: cantidad de componentes principales a considerar\n",
    "#excl_n_prim_comp: excluir las primeras excl_n_prim_comp componenetes principales (0 no se excluye ninguna)\n",
    "#nueronas_layer_1: neuronas capa oculta 1\n",
    "#nueronas_layer_2: neuronas capa oculta 2\n",
    "#n_epochs: cantidad de epochs... NO SE TOMA EN CUENTA... SE HARDCODEA MÁS ABAJO!!!\n",
    "\n",
    "# PARA LA ULTIMA PARTE DE LA NOTEBOOK ES IMPORTANTE TENER A MANO LOS PARAMETROS\n",
    "# \"n_pca\" y \"excl_n_prim_comp\" del modelo seleccionado!!!\n",
    "\n",
    "pruebas = {\n",
    "    \"prueba_1\": {\"n_pca\":60, \"excl_n_prim_comp\":5, \"nueronas_layer_1\":40, \"nueronas_layer_2\":25, \"n_epochs\":300},\n",
    "    \"prueba_2\": {\"n_pca\":100, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":300},\n",
    "    \"prueba_3\": {\"n_pca\":100, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":45, \"nueronas_layer_2\":26, \"n_epochs\":200},\n",
    "    \"prueba_4\": {\"n_pca\":100, \"excl_n_prim_comp\":3, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":200},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrego esto para realizar algunas pruebas en otro directorio pero utilizando las funciones definidas por fede...\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Obtener el path de ejecucion de la notebook\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Define el nombre del proyecto\n",
    "root_dir_name = \"NuestrasCaras\"\n",
    "\n",
    "# Obtiene el path del proyecto\n",
    "while not os.path.basename(current_dir) == root_dir_name:\n",
    "    current_dir = os.path.dirname(current_dir)\n",
    "    \n",
    "# Agrega path a librerias\n",
    "sys.path.append(current_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leer imágenes para entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_imagenes = DIM\n",
    "data_dir = \"01_entrenar_modelo/fotos_entrenamiento\"\n",
    "nombres = []\n",
    "imagenes = []\n",
    "\n",
    "# Cargar imágenes y etiquetas\n",
    "dir = os.path.join(current_dir,\"01_entrenar_modelo\",\"fotos_entrenamiento\")\n",
    "for archivo in os.listdir(dir):\n",
    "    if archivo.endswith('.jpeg') or archivo.endswith('.jpg'):\n",
    "        nombre = archivo.split('_')[0].replace(\".jpg\",\"\").replace(\".jpeg\",\"\")\n",
    "        nombre = re.sub(r\"\\d+\", \"\", nombre)\n",
    "        ruta_imagen = os.path.join(dir, archivo)\n",
    "        imagen = Image.open(ruta_imagen)\n",
    "        imagen = np.array(imagen.resize((dim_imagenes, dim_imagenes)))  # Redimensionar imágenes para un tamaño uniforme\n",
    "        if len(imagen.shape) == 3 and imagen.shape[2] == 3:\n",
    "            imagen = cv2.cvtColor(imagen, cv2.COLOR_RGB2GRAY)  # Convertir a escala de grises si es necesario\n",
    "        imagenes.append(imagen.flatten())\n",
    "        nombres.append(nombre)\n",
    "\n",
    "imagenes_all = np.array(imagenes)\n",
    "nombres_all = np.array(nombres)\n",
    "\n",
    "# estand\n",
    "imagenes_all = imagenes_all/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10459, 900)\n",
      "(10459,)\n"
     ]
    }
   ],
   "source": [
    "print(imagenes_all.shape)\n",
    "print(nombres_all.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leer imagenes para testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = (\"01_entrenar_modelo/fotos_test_entrenamiento\")\n",
    "nombres = []\n",
    "imagenes = []\n",
    "\n",
    "# Cargar imágenes y etiquetas\n",
    "dir = os.path.join(current_dir,data_dir)\n",
    "for archivo in os.listdir(dir):\n",
    "    if archivo.endswith('.jpeg') or archivo.endswith('.jpg'):\n",
    "        nombre = archivo.split('_')[0].replace(\".jpg\",\"\").replace(\".jpeg\",\"\")\n",
    "        nombre = re.sub(r\"\\d+\", \"\", nombre)\n",
    "        ruta_imagen = os.path.join(dir, archivo)\n",
    "        imagen = Image.open(ruta_imagen)\n",
    "        imagen = np.array(imagen.resize((dim_imagenes, dim_imagenes)))  # Redimensionar imágenes para un tamaño uniforme\n",
    "        if len(imagen.shape) == 3 and imagen.shape[2] == 3:\n",
    "            imagen = cv2.cvtColor(imagen, cv2.COLOR_RGB2GRAY)  # Convertir a escala de grises si es necesario\n",
    "        imagenes.append(imagen.flatten())\n",
    "        nombres.append(nombre)\n",
    "\n",
    "new_images = np.array(imagenes)\n",
    "nombres_new = np.array(nombres)\n",
    "\n",
    "# estand\n",
    "new_images = new_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 900)\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "print(new_images.shape)\n",
    "print(nombres_new.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y testeo del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define funcion para entrenar \n",
    "def run_keras_model(n_pca, excl_n_prim_comp, nueronas_layer_1, nueronas_layer_2, n_epochs, imagenes, nombres, nuevas_imagenes, nuevos_nombres):\n",
    "    \n",
    "    # Dividir en entrenamiento y prueba\n",
    "    # se comentan ya que no se divide la base en train y test...\n",
    "    # se va a utilizar TODAS las imagenes para el entrenamiento...\n",
    "    # tenemos imagenes extras de todos los integrantes para realizar la evaluacion...\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(imagenes, nombres, test_size=0.05, random_state=42, stratify=nombres)\n",
    "    X_train = imagenes #np.array(imagenes)\n",
    "    y_train = nombres #np.array(nombres).reshape(-1)\n",
    "    \n",
    "    # Aplicar PCA\n",
    "    pca = PCA(n_components=n_pca, random_state=seed)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    #X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    # Escalar los datos \n",
    "    scaler = StandardScaler()\n",
    "    #scaler = MinMaxScaler() # en caso de ser necesario probar con otro metodo de escalado\n",
    "    X_train_pca_scaled = scaler.fit_transform(X_train_pca)\n",
    "    #X_test_pca_scaled = scaler.transform(X_test_pca)\n",
    "    \n",
    "    \n",
    "    # Codificar las etiquetas\n",
    "    encoder = LabelEncoder()\n",
    "    y_train_encoded = encoder.fit_transform(y_train)\n",
    "    #y_test_encoded = encoder.transform(y_test)\n",
    "    y_train_categorical = to_categorical(y_train_encoded, num_classes=19)\n",
    "    #y_test_categorical = to_categorical(y_test_encoded, num_classes=19)\n",
    "    \n",
    "    \n",
    "    # Definir la red neuronal\n",
    "    entreno_con = X_train_pca_scaled[:,excl_n_prim_comp:]\n",
    "    #testeo_con = X_test_pca_scaled[:,excl_n_prim_comp:]\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=entreno_con.shape[1:]))  # Definir la entrada del modelo\n",
    "    model.add(Dense(nueronas_layer_1, activation='sigmoid'))\n",
    "    model.add(Dense(nueronas_layer_2, activation='sigmoid'))\n",
    "    model.add(Dense(y_train_categorical.shape[1], activation='softmax'))\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    model.fit(entreno_con, y_train_categorical, epochs=n_epochs, batch_size=10, validation_split=0.3)\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    #loss, accuracy = model.evaluate(testeo_con, y_test_categorical)\n",
    "    #print(f'Precisión en el conjunto de prueba: {accuracy * 100:.2f}%')\n",
    "    \n",
    "    \n",
    "    # PREDICCIONES\n",
    "    # 2. Aplicar PCA\n",
    "    new_images_pca = pca.transform(nuevas_imagenes)\n",
    "    new_images_pca_scaled = scaler.transform(new_images_pca)\n",
    "    evaluo_con = new_images_pca_scaled[:,excl_n_prim_comp:]\n",
    "\n",
    "    # 3. Hacer predicciones\n",
    "    predictions = model.predict(evaluo_con)\n",
    "\n",
    "    # Obtener los nombres correspondientes a las clases predichas\n",
    "    predicted_names = encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
    "\n",
    "    # Imprimir las predicciones\n",
    "    total_predict = len(nuevos_nombres)\n",
    "    total_correcto = 0\n",
    "    for real, pred in zip(nuevos_nombres, predicted_names):\n",
    "        if real == pred:\n",
    "            total_correcto += 1\n",
    "    \n",
    "    # devuelve resultado corrida\n",
    "    resultado = total_correcto/total_predict\n",
    "    return resultado, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prueba_1: \n",
      "Epoch 1/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1850 - loss: 2.6047 - val_accuracy: 0.0000e+00 - val_loss: 6.1539\n",
      "Epoch 2/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5327 - loss: 1.7958 - val_accuracy: 0.0000e+00 - val_loss: 7.1926\n",
      "Epoch 3/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7124 - loss: 1.2393 - val_accuracy: 0.0000e+00 - val_loss: 7.9184\n",
      "Epoch 4/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7778 - loss: 0.9255 - val_accuracy: 0.0000e+00 - val_loss: 8.4674\n",
      "Epoch 5/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8205 - loss: 0.7221 - val_accuracy: 0.0000e+00 - val_loss: 8.9302\n",
      "Epoch 6/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8494 - loss: 0.5870 - val_accuracy: 0.0019 - val_loss: 9.3494\n",
      "Epoch 7/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8761 - loss: 0.4918 - val_accuracy: 0.0073 - val_loss: 9.7394\n",
      "Epoch 8/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8975 - loss: 0.4193 - val_accuracy: 0.0137 - val_loss: 10.1076\n",
      "Epoch 9/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9170 - loss: 0.3616 - val_accuracy: 0.0201 - val_loss: 10.4595\n",
      "Epoch 10/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9269 - loss: 0.3144 - val_accuracy: 0.0220 - val_loss: 10.8004\n",
      "Epoch 11/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9352 - loss: 0.2753 - val_accuracy: 0.0245 - val_loss: 11.1347\n",
      "Epoch 12/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9431 - loss: 0.2423 - val_accuracy: 0.0258 - val_loss: 11.4656\n",
      "Epoch 13/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9518 - loss: 0.2142 - val_accuracy: 0.0264 - val_loss: 11.7947\n",
      "Epoch 14/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9604 - loss: 0.1899 - val_accuracy: 0.0290 - val_loss: 12.1229\n",
      "Epoch 15/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9672 - loss: 0.1688 - val_accuracy: 0.0312 - val_loss: 12.4503\n",
      "Epoch 16/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9707 - loss: 0.1501 - val_accuracy: 0.0335 - val_loss: 12.7772\n",
      "Epoch 17/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9755 - loss: 0.1336 - val_accuracy: 0.0335 - val_loss: 13.1036\n",
      "Epoch 18/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9794 - loss: 0.1190 - val_accuracy: 0.0341 - val_loss: 13.4295\n",
      "Epoch 19/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9822 - loss: 0.1060 - val_accuracy: 0.0341 - val_loss: 13.7547\n",
      "Epoch 20/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9850 - loss: 0.0944 - val_accuracy: 0.0341 - val_loss: 14.0789\n",
      "Epoch 21/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9875 - loss: 0.0840 - val_accuracy: 0.0344 - val_loss: 14.4016\n",
      "Epoch 22/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9910 - loss: 0.0748 - val_accuracy: 0.0351 - val_loss: 14.7219\n",
      "Epoch 23/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9927 - loss: 0.0666 - val_accuracy: 0.0347 - val_loss: 15.0390\n",
      "Epoch 24/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9951 - loss: 0.0593 - val_accuracy: 0.0351 - val_loss: 15.3511\n",
      "Epoch 25/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9963 - loss: 0.0527 - val_accuracy: 0.0347 - val_loss: 15.6568\n",
      "Epoch 26/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9967 - loss: 0.0469 - val_accuracy: 0.0357 - val_loss: 15.9540\n",
      "Epoch 27/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0416 - val_accuracy: 0.0360 - val_loss: 16.2409\n",
      "Epoch 28/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9984 - loss: 0.0368 - val_accuracy: 0.0360 - val_loss: 16.5158\n",
      "Epoch 29/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9984 - loss: 0.0326 - val_accuracy: 0.0366 - val_loss: 16.7772\n",
      "Epoch 30/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9986 - loss: 0.0288 - val_accuracy: 0.0370 - val_loss: 17.0236\n",
      "Epoch 31/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0254 - val_accuracy: 0.0376 - val_loss: 17.2542\n",
      "Epoch 32/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0224 - val_accuracy: 0.0379 - val_loss: 17.4687\n",
      "Epoch 33/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0197 - val_accuracy: 0.0379 - val_loss: 17.6675\n",
      "Epoch 34/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0172 - val_accuracy: 0.0379 - val_loss: 17.8512\n",
      "Epoch 35/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0151 - val_accuracy: 0.0386 - val_loss: 18.0209\n",
      "Epoch 36/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0132 - val_accuracy: 0.0382 - val_loss: 18.1780\n",
      "Epoch 37/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0115 - val_accuracy: 0.0379 - val_loss: 18.3239\n",
      "Epoch 38/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0100 - val_accuracy: 0.0382 - val_loss: 18.4603\n",
      "Epoch 39/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.0382 - val_loss: 18.5889\n",
      "Epoch 40/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.0386 - val_loss: 18.7112\n",
      "Epoch 41/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.0386 - val_loss: 18.8287\n",
      "Epoch 42/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.0389 - val_loss: 18.9422\n",
      "Epoch 43/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.0386 - val_loss: 19.0524\n",
      "Epoch 44/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.0382 - val_loss: 19.1599\n",
      "Epoch 45/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.0376 - val_loss: 19.2651\n",
      "Epoch 46/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.0373 - val_loss: 19.3684\n",
      "Epoch 47/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.0373 - val_loss: 19.4700\n",
      "Epoch 48/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.0370 - val_loss: 19.5703\n",
      "Epoch 49/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.0370 - val_loss: 19.6695\n",
      "Epoch 50/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.0370 - val_loss: 19.7678\n",
      "Epoch 51/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.0373 - val_loss: 19.8652\n",
      "Epoch 52/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.0370 - val_loss: 19.9620\n",
      "Epoch 53/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.0376 - val_loss: 20.0582\n",
      "Epoch 54/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.1268e-04 - val_accuracy: 0.0376 - val_loss: 20.1539\n",
      "Epoch 55/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.7983e-04 - val_accuracy: 0.0376 - val_loss: 20.2490\n",
      "Epoch 56/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.6579e-04 - val_accuracy: 0.0379 - val_loss: 20.3437\n",
      "Epoch 57/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.6799e-04 - val_accuracy: 0.0379 - val_loss: 20.4380\n",
      "Epoch 58/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.8422e-04 - val_accuracy: 0.0379 - val_loss: 20.5320\n",
      "Epoch 59/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.1252e-04 - val_accuracy: 0.0379 - val_loss: 20.6257\n",
      "Epoch 60/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.5121e-04 - val_accuracy: 0.0389 - val_loss: 20.7191\n",
      "Epoch 61/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.9884e-04 - val_accuracy: 0.0389 - val_loss: 20.8122\n",
      "Epoch 62/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.5413e-04 - val_accuracy: 0.0389 - val_loss: 20.9052\n",
      "Epoch 63/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.1600e-04 - val_accuracy: 0.0389 - val_loss: 20.9980\n",
      "Epoch 64/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.8350e-04 - val_accuracy: 0.0389 - val_loss: 21.0908\n",
      "Epoch 65/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.5583e-04 - val_accuracy: 0.0389 - val_loss: 21.1835\n",
      "Epoch 66/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.3227e-04 - val_accuracy: 0.0392 - val_loss: 21.2761\n",
      "Epoch 67/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.1223e-04 - val_accuracy: 0.0392 - val_loss: 21.3688\n",
      "Epoch 68/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.5197e-05 - val_accuracy: 0.0392 - val_loss: 21.4615\n",
      "Epoch 69/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.0721e-05 - val_accuracy: 0.0392 - val_loss: 21.5543\n",
      "Epoch 70/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.8426e-05 - val_accuracy: 0.0392 - val_loss: 21.6471\n",
      "Epoch 71/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.7987e-05 - val_accuracy: 0.0392 - val_loss: 21.7401\n",
      "Epoch 72/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.9128e-05 - val_accuracy: 0.0392 - val_loss: 21.8332\n",
      "Epoch 73/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.1612e-05 - val_accuracy: 0.0392 - val_loss: 21.9265\n",
      "Epoch 74/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.5235e-05 - val_accuracy: 0.0392 - val_loss: 22.0199\n",
      "Epoch 75/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.9831e-05 - val_accuracy: 0.0392 - val_loss: 22.1135\n",
      "Epoch 76/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.5250e-05 - val_accuracy: 0.0392 - val_loss: 22.2073\n",
      "Epoch 77/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.1370e-05 - val_accuracy: 0.0389 - val_loss: 22.3013\n",
      "Epoch 78/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.8084e-05 - val_accuracy: 0.0389 - val_loss: 22.3954\n",
      "Epoch 79/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.5303e-05 - val_accuracy: 0.0389 - val_loss: 22.4895\n",
      "Epoch 80/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.2951e-05 - val_accuracy: 0.0386 - val_loss: 22.5837\n",
      "Epoch 81/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.0964e-05 - val_accuracy: 0.0386 - val_loss: 22.6781\n",
      "Epoch 82/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.2838e-06 - val_accuracy: 0.0386 - val_loss: 22.7722\n",
      "Epoch 83/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.8657e-06 - val_accuracy: 0.0382 - val_loss: 22.8667\n",
      "Epoch 84/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.6662e-06 - val_accuracy: 0.0382 - val_loss: 22.9607\n",
      "Epoch 85/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.6572e-06 - val_accuracy: 0.0382 - val_loss: 23.0551\n",
      "Epoch 86/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.8045e-06 - val_accuracy: 0.0382 - val_loss: 23.1488\n",
      "Epoch 87/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.0862e-06 - val_accuracy: 0.0382 - val_loss: 23.2433\n",
      "Epoch 88/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.4781e-06 - val_accuracy: 0.0382 - val_loss: 23.3362\n",
      "Epoch 89/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.9682e-06 - val_accuracy: 0.0382 - val_loss: 23.4298\n",
      "Epoch 90/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.5352e-06 - val_accuracy: 0.0382 - val_loss: 23.5218\n",
      "Epoch 91/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.1707e-06 - val_accuracy: 0.0382 - val_loss: 23.6129\n",
      "Epoch 92/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.8634e-06 - val_accuracy: 0.0382 - val_loss: 23.7021\n",
      "Epoch 93/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.6039e-06 - val_accuracy: 0.0382 - val_loss: 23.7906\n",
      "Epoch 94/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.3857e-06 - val_accuracy: 0.0382 - val_loss: 23.8778\n",
      "Epoch 95/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.1985e-06 - val_accuracy: 0.0382 - val_loss: 23.9635\n",
      "Epoch 96/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.0415e-06 - val_accuracy: 0.0382 - val_loss: 24.0470\n",
      "Epoch 97/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.0925e-07 - val_accuracy: 0.0379 - val_loss: 24.1299\n",
      "Epoch 98/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.9580e-07 - val_accuracy: 0.0382 - val_loss: 24.2094\n",
      "Epoch 99/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.9913e-07 - val_accuracy: 0.0382 - val_loss: 24.2852\n",
      "Epoch 100/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.1661e-07 - val_accuracy: 0.0382 - val_loss: 24.3598\n",
      "Epoch 101/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.4673e-07 - val_accuracy: 0.0386 - val_loss: 24.4312\n",
      "Epoch 102/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.8640e-07 - val_accuracy: 0.0386 - val_loss: 24.5001\n",
      "Epoch 103/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.3280e-07 - val_accuracy: 0.0386 - val_loss: 24.5616\n",
      "Epoch 104/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 941us/step - accuracy: 1.0000 - loss: 3.8953e-07 - val_accuracy: 0.0382 - val_loss: 24.6229\n",
      "Epoch 105/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 979us/step - accuracy: 1.0000 - loss: 3.5023e-07 - val_accuracy: 0.0382 - val_loss: 24.6786\n",
      "Epoch 106/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 954us/step - accuracy: 1.0000 - loss: 3.1684e-07 - val_accuracy: 0.0382 - val_loss: 24.7334\n",
      "Epoch 107/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.8757e-07 - val_accuracy: 0.0382 - val_loss: 24.7840\n",
      "Epoch 108/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.6124e-07 - val_accuracy: 0.0382 - val_loss: 24.8260\n",
      "Epoch 109/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 949us/step - accuracy: 1.0000 - loss: 2.3872e-07 - val_accuracy: 0.0382 - val_loss: 24.8706\n",
      "Epoch 110/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 991us/step - accuracy: 1.0000 - loss: 2.1946e-07 - val_accuracy: 0.0382 - val_loss: 24.9090\n",
      "Epoch 111/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 1.0000 - loss: 2.0149e-07 - val_accuracy: 0.0382 - val_loss: 24.9420\n",
      "Epoch 112/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 937us/step - accuracy: 1.0000 - loss: 1.8635e-07 - val_accuracy: 0.0386 - val_loss: 24.9726\n",
      "Epoch 113/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 1.0000 - loss: 1.7241e-07 - val_accuracy: 0.0386 - val_loss: 24.9980\n",
      "Epoch 114/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 945us/step - accuracy: 1.0000 - loss: 1.6026e-07 - val_accuracy: 0.0386 - val_loss: 25.0241\n",
      "Epoch 115/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 930us/step - accuracy: 1.0000 - loss: 1.5011e-07 - val_accuracy: 0.0389 - val_loss: 25.0451\n",
      "Epoch 116/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - accuracy: 1.0000 - loss: 1.3954e-07 - val_accuracy: 0.0392 - val_loss: 25.0627\n",
      "Epoch 117/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - accuracy: 1.0000 - loss: 1.3185e-07 - val_accuracy: 0.0389 - val_loss: 25.0823\n",
      "Epoch 118/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 1.0000 - loss: 1.2394e-07 - val_accuracy: 0.0392 - val_loss: 25.0999\n",
      "Epoch 119/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - accuracy: 1.0000 - loss: 1.1630e-07 - val_accuracy: 0.0392 - val_loss: 25.1125\n",
      "Epoch 120/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - accuracy: 1.0000 - loss: 1.0959e-07 - val_accuracy: 0.0389 - val_loss: 25.1237\n",
      "Epoch 121/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867us/step - accuracy: 1.0000 - loss: 1.0368e-07 - val_accuracy: 0.0389 - val_loss: 25.1296\n",
      "Epoch 122/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 1.0000 - loss: 9.7810e-08 - val_accuracy: 0.0389 - val_loss: 25.1326\n",
      "Epoch 123/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 885us/step - accuracy: 1.0000 - loss: 9.2770e-08 - val_accuracy: 0.0389 - val_loss: 25.1355\n",
      "Epoch 124/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 1.0000 - loss: 8.8993e-08 - val_accuracy: 0.0389 - val_loss: 25.1414\n",
      "Epoch 125/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 872us/step - accuracy: 1.0000 - loss: 8.4255e-08 - val_accuracy: 0.0386 - val_loss: 25.1383\n",
      "Epoch 126/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 902us/step - accuracy: 1.0000 - loss: 8.0695e-08 - val_accuracy: 0.0389 - val_loss: 25.1358\n",
      "Epoch 127/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 1.0000 - loss: 7.7492e-08 - val_accuracy: 0.0392 - val_loss: 25.1336\n",
      "Epoch 128/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 917us/step - accuracy: 1.0000 - loss: 7.4128e-08 - val_accuracy: 0.0392 - val_loss: 25.1274\n",
      "Epoch 129/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 1.0000 - loss: 7.0699e-08 - val_accuracy: 0.0392 - val_loss: 25.1200\n",
      "Epoch 130/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 1.0000 - loss: 6.8092e-08 - val_accuracy: 0.0395 - val_loss: 25.1111\n",
      "Epoch 131/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 1.0000 - loss: 6.5540e-08 - val_accuracy: 0.0395 - val_loss: 25.1016\n",
      "Epoch 132/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 1.0000 - loss: 6.3175e-08 - val_accuracy: 0.0395 - val_loss: 25.0901\n",
      "Epoch 133/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 1.0000 - loss: 6.1161e-08 - val_accuracy: 0.0395 - val_loss: 25.0819\n",
      "Epoch 134/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 872us/step - accuracy: 1.0000 - loss: 5.8873e-08 - val_accuracy: 0.0395 - val_loss: 25.0718\n",
      "Epoch 135/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step - accuracy: 1.0000 - loss: 5.7029e-08 - val_accuracy: 0.0395 - val_loss: 25.0552\n",
      "Epoch 136/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - accuracy: 1.0000 - loss: 5.5071e-08 - val_accuracy: 0.0395 - val_loss: 25.0404\n",
      "Epoch 137/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 897us/step - accuracy: 1.0000 - loss: 5.3181e-08 - val_accuracy: 0.0395 - val_loss: 25.0300\n",
      "Epoch 138/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895us/step - accuracy: 1.0000 - loss: 5.1802e-08 - val_accuracy: 0.0392 - val_loss: 25.0134\n",
      "Epoch 139/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step - accuracy: 1.0000 - loss: 4.9775e-08 - val_accuracy: 0.0395 - val_loss: 24.9999\n",
      "Epoch 140/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 1.0000 - loss: 4.8808e-08 - val_accuracy: 0.0395 - val_loss: 24.9832\n",
      "Epoch 141/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 897us/step - accuracy: 1.0000 - loss: 4.7228e-08 - val_accuracy: 0.0395 - val_loss: 24.9669\n",
      "Epoch 142/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911us/step - accuracy: 1.0000 - loss: 4.5605e-08 - val_accuracy: 0.0395 - val_loss: 24.9537\n",
      "Epoch 143/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 1.0000 - loss: 4.4226e-08 - val_accuracy: 0.0395 - val_loss: 24.9317\n",
      "Epoch 144/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 900us/step - accuracy: 1.0000 - loss: 4.3785e-08 - val_accuracy: 0.0395 - val_loss: 24.9171\n",
      "Epoch 145/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 1.0000 - loss: 4.2163e-08 - val_accuracy: 0.0392 - val_loss: 24.8939\n",
      "Epoch 146/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - accuracy: 1.0000 - loss: 4.1214e-08 - val_accuracy: 0.0392 - val_loss: 24.8714\n",
      "Epoch 147/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - accuracy: 1.0000 - loss: 4.0284e-08 - val_accuracy: 0.0392 - val_loss: 24.8502\n",
      "Epoch 148/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 882us/step - accuracy: 1.0000 - loss: 3.9155e-08 - val_accuracy: 0.0392 - val_loss: 24.8265\n",
      "Epoch 149/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911us/step - accuracy: 1.0000 - loss: 3.8343e-08 - val_accuracy: 0.0392 - val_loss: 24.8003\n",
      "Epoch 150/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 1.0000 - loss: 3.7812e-08 - val_accuracy: 0.0392 - val_loss: 24.7804\n",
      "Epoch 151/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893us/step - accuracy: 1.0000 - loss: 3.6482e-08 - val_accuracy: 0.0395 - val_loss: 24.7538\n",
      "Epoch 152/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 1.0000 - loss: 3.5587e-08 - val_accuracy: 0.0398 - val_loss: 24.7278\n",
      "Epoch 153/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 885us/step - accuracy: 1.0000 - loss: 3.5306e-08 - val_accuracy: 0.0395 - val_loss: 24.7074\n",
      "Epoch 154/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - accuracy: 1.0000 - loss: 3.4079e-08 - val_accuracy: 0.0398 - val_loss: 24.6817\n",
      "Epoch 155/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 1.0000 - loss: 3.3251e-08 - val_accuracy: 0.0395 - val_loss: 24.6570\n",
      "Epoch 156/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 1.0000 - loss: 3.2982e-08 - val_accuracy: 0.0398 - val_loss: 24.6330\n",
      "Epoch 157/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 887us/step - accuracy: 1.0000 - loss: 3.2028e-08 - val_accuracy: 0.0398 - val_loss: 24.6105\n",
      "Epoch 158/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - accuracy: 1.0000 - loss: 3.1283e-08 - val_accuracy: 0.0392 - val_loss: 24.5801\n",
      "Epoch 159/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 936us/step - accuracy: 1.0000 - loss: 3.0934e-08 - val_accuracy: 0.0392 - val_loss: 24.5560\n",
      "Epoch 160/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899us/step - accuracy: 1.0000 - loss: 3.0202e-08 - val_accuracy: 0.0395 - val_loss: 24.5294\n",
      "Epoch 161/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 887us/step - accuracy: 1.0000 - loss: 3.0286e-08 - val_accuracy: 0.0395 - val_loss: 24.5054\n",
      "Epoch 162/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 902us/step - accuracy: 1.0000 - loss: 2.9382e-08 - val_accuracy: 0.0395 - val_loss: 24.4805\n",
      "Epoch 163/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 1.0000 - loss: 2.9061e-08 - val_accuracy: 0.0395 - val_loss: 24.4561\n",
      "Epoch 164/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - accuracy: 1.0000 - loss: 2.8147e-08 - val_accuracy: 0.0392 - val_loss: 24.4230\n",
      "Epoch 165/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - accuracy: 1.0000 - loss: 2.8041e-08 - val_accuracy: 0.0395 - val_loss: 24.3951\n",
      "Epoch 166/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 890us/step - accuracy: 1.0000 - loss: 2.6922e-08 - val_accuracy: 0.0395 - val_loss: 24.3710\n",
      "Epoch 167/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888us/step - accuracy: 1.0000 - loss: 2.6854e-08 - val_accuracy: 0.0392 - val_loss: 24.3390\n",
      "Epoch 168/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 882us/step - accuracy: 1.0000 - loss: 2.6942e-08 - val_accuracy: 0.0395 - val_loss: 24.3188\n",
      "Epoch 169/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911us/step - accuracy: 1.0000 - loss: 2.6426e-08 - val_accuracy: 0.0392 - val_loss: 24.2869\n",
      "Epoch 170/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step - accuracy: 1.0000 - loss: 2.5332e-08 - val_accuracy: 0.0395 - val_loss: 24.2572\n",
      "Epoch 171/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 882us/step - accuracy: 1.0000 - loss: 2.5482e-08 - val_accuracy: 0.0392 - val_loss: 24.2285\n",
      "Epoch 172/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - accuracy: 1.0000 - loss: 2.4938e-08 - val_accuracy: 0.0395 - val_loss: 24.1991\n",
      "Epoch 173/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899us/step - accuracy: 1.0000 - loss: 2.4740e-08 - val_accuracy: 0.0392 - val_loss: 24.1682\n",
      "Epoch 174/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - accuracy: 1.0000 - loss: 2.4605e-08 - val_accuracy: 0.0392 - val_loss: 24.1392\n",
      "Epoch 175/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - accuracy: 1.0000 - loss: 2.4343e-08 - val_accuracy: 0.0395 - val_loss: 24.1054\n",
      "Epoch 176/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 1.0000 - loss: 2.3542e-08 - val_accuracy: 0.0395 - val_loss: 24.0703\n",
      "Epoch 177/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - accuracy: 1.0000 - loss: 2.3400e-08 - val_accuracy: 0.0392 - val_loss: 24.0394\n",
      "Epoch 178/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934us/step - accuracy: 1.0000 - loss: 2.3202e-08 - val_accuracy: 0.0389 - val_loss: 24.0050\n",
      "Epoch 179/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 884us/step - accuracy: 1.0000 - loss: 2.2741e-08 - val_accuracy: 0.0392 - val_loss: 23.9772\n",
      "Epoch 180/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 1.0000 - loss: 2.2531e-08 - val_accuracy: 0.0392 - val_loss: 23.9454\n",
      "Epoch 181/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911us/step - accuracy: 1.0000 - loss: 2.1987e-08 - val_accuracy: 0.0392 - val_loss: 23.9090\n",
      "Epoch 182/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 881us/step - accuracy: 1.0000 - loss: 2.2643e-08 - val_accuracy: 0.0392 - val_loss: 23.8826\n",
      "Epoch 183/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 1.0000 - loss: 2.1540e-08 - val_accuracy: 0.0389 - val_loss: 23.8475\n",
      "Epoch 184/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 901us/step - accuracy: 1.0000 - loss: 2.1183e-08 - val_accuracy: 0.0392 - val_loss: 23.8145\n",
      "Epoch 185/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 1.0000 - loss: 2.1041e-08 - val_accuracy: 0.0389 - val_loss: 23.7788\n",
      "Epoch 186/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 884us/step - accuracy: 1.0000 - loss: 2.0785e-08 - val_accuracy: 0.0389 - val_loss: 23.7472\n",
      "Epoch 187/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 909us/step - accuracy: 1.0000 - loss: 2.0717e-08 - val_accuracy: 0.0389 - val_loss: 23.7107\n",
      "Epoch 188/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - accuracy: 1.0000 - loss: 2.0173e-08 - val_accuracy: 0.0392 - val_loss: 23.6738\n",
      "Epoch 189/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 876us/step - accuracy: 1.0000 - loss: 2.0578e-08 - val_accuracy: 0.0389 - val_loss: 23.6430\n",
      "Epoch 190/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - accuracy: 1.0000 - loss: 1.9681e-08 - val_accuracy: 0.0389 - val_loss: 23.6062\n",
      "Epoch 191/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 887us/step - accuracy: 1.0000 - loss: 1.9645e-08 - val_accuracy: 0.0389 - val_loss: 23.5749\n",
      "Epoch 192/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 1.0000 - loss: 1.9367e-08 - val_accuracy: 0.0389 - val_loss: 23.5387\n",
      "Epoch 193/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 882us/step - accuracy: 1.0000 - loss: 1.9160e-08 - val_accuracy: 0.0389 - val_loss: 23.5023\n",
      "Epoch 194/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - accuracy: 1.0000 - loss: 1.9300e-08 - val_accuracy: 0.0389 - val_loss: 23.4686\n",
      "Epoch 195/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 1.0000 - loss: 1.8952e-08 - val_accuracy: 0.0389 - val_loss: 23.4369\n",
      "Epoch 196/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - accuracy: 1.0000 - loss: 1.8467e-08 - val_accuracy: 0.0389 - val_loss: 23.3976\n",
      "Epoch 197/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 884us/step - accuracy: 1.0000 - loss: 1.8636e-08 - val_accuracy: 0.0389 - val_loss: 23.3587\n",
      "Epoch 198/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - accuracy: 1.0000 - loss: 1.8689e-08 - val_accuracy: 0.0389 - val_loss: 23.3305\n",
      "Epoch 199/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905us/step - accuracy: 1.0000 - loss: 1.8012e-08 - val_accuracy: 0.0389 - val_loss: 23.2922\n",
      "Epoch 200/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 1.0000 - loss: 1.7636e-08 - val_accuracy: 0.0389 - val_loss: 23.2536\n",
      "Epoch 201/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 908us/step - accuracy: 1.0000 - loss: 1.8081e-08 - val_accuracy: 0.0389 - val_loss: 23.2195\n",
      "Epoch 202/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 1.0000 - loss: 1.7489e-08 - val_accuracy: 0.0389 - val_loss: 23.1794\n",
      "Epoch 203/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - accuracy: 1.0000 - loss: 1.7603e-08 - val_accuracy: 0.0389 - val_loss: 23.1475\n",
      "Epoch 204/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 892us/step - accuracy: 1.0000 - loss: 1.7454e-08 - val_accuracy: 0.0389 - val_loss: 23.1071\n",
      "Epoch 205/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 1.0000 - loss: 1.7532e-08 - val_accuracy: 0.0389 - val_loss: 23.0731\n",
      "Epoch 206/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861us/step - accuracy: 1.0000 - loss: 1.7188e-08 - val_accuracy: 0.0389 - val_loss: 23.0358\n",
      "Epoch 207/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 887us/step - accuracy: 1.0000 - loss: 1.6928e-08 - val_accuracy: 0.0389 - val_loss: 22.9949\n",
      "Epoch 208/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step - accuracy: 1.0000 - loss: 1.6602e-08 - val_accuracy: 0.0389 - val_loss: 22.9588\n",
      "Epoch 209/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 892us/step - accuracy: 1.0000 - loss: 1.6785e-08 - val_accuracy: 0.0386 - val_loss: 22.9222\n",
      "Epoch 210/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895us/step - accuracy: 1.0000 - loss: 1.7002e-08 - val_accuracy: 0.0386 - val_loss: 22.8886\n",
      "Epoch 211/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 1.0000 - loss: 1.6255e-08 - val_accuracy: 0.0386 - val_loss: 22.8496\n",
      "Epoch 212/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888us/step - accuracy: 1.0000 - loss: 1.6268e-08 - val_accuracy: 0.0386 - val_loss: 22.8087\n",
      "Epoch 213/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905us/step - accuracy: 1.0000 - loss: 1.6455e-08 - val_accuracy: 0.0386 - val_loss: 22.7674\n",
      "Epoch 214/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864us/step - accuracy: 1.0000 - loss: 1.6021e-08 - val_accuracy: 0.0386 - val_loss: 22.7363\n",
      "Epoch 215/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - accuracy: 1.0000 - loss: 1.6170e-08 - val_accuracy: 0.0386 - val_loss: 22.6950\n",
      "Epoch 216/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 1.0000 - loss: 1.6012e-08 - val_accuracy: 0.0386 - val_loss: 22.6548\n",
      "Epoch 217/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 1.0000 - loss: 1.5807e-08 - val_accuracy: 0.0386 - val_loss: 22.6198\n",
      "Epoch 218/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861us/step - accuracy: 1.0000 - loss: 1.5610e-08 - val_accuracy: 0.0382 - val_loss: 22.5839\n",
      "Epoch 219/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 929us/step - accuracy: 1.0000 - loss: 1.5540e-08 - val_accuracy: 0.0386 - val_loss: 22.5427\n",
      "Epoch 220/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 1.0000 - loss: 1.5514e-08 - val_accuracy: 0.0382 - val_loss: 22.5022\n",
      "Epoch 221/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 882us/step - accuracy: 1.0000 - loss: 1.5839e-08 - val_accuracy: 0.0382 - val_loss: 22.4657\n",
      "Epoch 222/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 1.0000 - loss: 1.5350e-08 - val_accuracy: 0.0382 - val_loss: 22.4304\n",
      "Epoch 223/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - accuracy: 1.0000 - loss: 1.5068e-08 - val_accuracy: 0.0382 - val_loss: 22.3889\n",
      "Epoch 224/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 884us/step - accuracy: 1.0000 - loss: 1.5142e-08 - val_accuracy: 0.0386 - val_loss: 22.3534\n",
      "Epoch 225/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 908us/step - accuracy: 1.0000 - loss: 1.5008e-08 - val_accuracy: 0.0382 - val_loss: 22.3136\n",
      "Epoch 226/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 897us/step - accuracy: 1.0000 - loss: 1.4878e-08 - val_accuracy: 0.0379 - val_loss: 22.2738\n",
      "Epoch 227/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 960us/step - accuracy: 1.0000 - loss: 1.4926e-08 - val_accuracy: 0.0382 - val_loss: 22.2357\n",
      "Epoch 228/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - accuracy: 1.0000 - loss: 1.4972e-08 - val_accuracy: 0.0379 - val_loss: 22.2003\n",
      "Epoch 229/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step - accuracy: 1.0000 - loss: 1.4489e-08 - val_accuracy: 0.0379 - val_loss: 22.1605\n",
      "Epoch 230/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - accuracy: 1.0000 - loss: 1.4559e-08 - val_accuracy: 0.0379 - val_loss: 22.1231\n",
      "Epoch 231/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step - accuracy: 1.0000 - loss: 1.4545e-08 - val_accuracy: 0.0382 - val_loss: 22.0867\n",
      "Epoch 232/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 885us/step - accuracy: 1.0000 - loss: 1.4560e-08 - val_accuracy: 0.0379 - val_loss: 22.0507\n",
      "Epoch 233/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905us/step - accuracy: 1.0000 - loss: 1.4533e-08 - val_accuracy: 0.0386 - val_loss: 22.0108\n",
      "Epoch 234/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 887us/step - accuracy: 1.0000 - loss: 1.4143e-08 - val_accuracy: 0.0382 - val_loss: 21.9750\n",
      "Epoch 235/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895us/step - accuracy: 1.0000 - loss: 1.4432e-08 - val_accuracy: 0.0382 - val_loss: 21.9354\n",
      "Epoch 236/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 876us/step - accuracy: 1.0000 - loss: 1.4228e-08 - val_accuracy: 0.0382 - val_loss: 21.8997\n",
      "Epoch 237/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 881us/step - accuracy: 1.0000 - loss: 1.3844e-08 - val_accuracy: 0.0386 - val_loss: 21.8616\n",
      "Epoch 238/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 935us/step - accuracy: 1.0000 - loss: 1.4012e-08 - val_accuracy: 0.0386 - val_loss: 21.8194\n",
      "Epoch 239/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 1.0000 - loss: 1.4355e-08 - val_accuracy: 0.0382 - val_loss: 21.7854\n",
      "Epoch 240/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 885us/step - accuracy: 1.0000 - loss: 1.3516e-08 - val_accuracy: 0.0386 - val_loss: 21.7489\n",
      "Epoch 241/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 887us/step - accuracy: 1.0000 - loss: 1.3954e-08 - val_accuracy: 0.0386 - val_loss: 21.7107\n",
      "Epoch 242/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 1.0000 - loss: 1.3710e-08 - val_accuracy: 0.0386 - val_loss: 21.6719\n",
      "Epoch 243/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 904us/step - accuracy: 1.0000 - loss: 1.3512e-08 - val_accuracy: 0.0386 - val_loss: 21.6276\n",
      "Epoch 244/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - accuracy: 1.0000 - loss: 1.4053e-08 - val_accuracy: 0.0386 - val_loss: 21.5944\n",
      "Epoch 245/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 1.0000 - loss: 1.3818e-08 - val_accuracy: 0.0386 - val_loss: 21.5579\n",
      "Epoch 246/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 925us/step - accuracy: 1.0000 - loss: 1.3240e-08 - val_accuracy: 0.0386 - val_loss: 21.5175\n",
      "Epoch 247/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 902us/step - accuracy: 1.0000 - loss: 1.3515e-08 - val_accuracy: 0.0386 - val_loss: 21.4811\n",
      "Epoch 248/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 897us/step - accuracy: 1.0000 - loss: 1.3482e-08 - val_accuracy: 0.0386 - val_loss: 21.4451\n",
      "Epoch 249/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 1.0000 - loss: 1.3242e-08 - val_accuracy: 0.0386 - val_loss: 21.4047\n",
      "Epoch 250/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 1.0000 - loss: 1.3577e-08 - val_accuracy: 0.0386 - val_loss: 21.3655\n",
      "Epoch 251/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - accuracy: 1.0000 - loss: 1.3216e-08 - val_accuracy: 0.0386 - val_loss: 21.3302\n",
      "Epoch 252/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 872us/step - accuracy: 1.0000 - loss: 1.3397e-08 - val_accuracy: 0.0386 - val_loss: 21.2927\n",
      "Epoch 253/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 1.0000 - loss: 1.2948e-08 - val_accuracy: 0.0386 - val_loss: 21.2548\n",
      "Epoch 254/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 1.0000 - loss: 1.3342e-08 - val_accuracy: 0.0386 - val_loss: 21.2236\n",
      "Epoch 255/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 890us/step - accuracy: 1.0000 - loss: 1.3017e-08 - val_accuracy: 0.0386 - val_loss: 21.1785\n",
      "Epoch 256/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 1.0000 - loss: 1.3328e-08 - val_accuracy: 0.0386 - val_loss: 21.1461\n",
      "Epoch 257/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - accuracy: 1.0000 - loss: 1.3143e-08 - val_accuracy: 0.0386 - val_loss: 21.1147\n",
      "Epoch 258/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 1.0000 - loss: 1.2693e-08 - val_accuracy: 0.0386 - val_loss: 21.0693\n",
      "Epoch 259/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 887us/step - accuracy: 1.0000 - loss: 1.2910e-08 - val_accuracy: 0.0386 - val_loss: 21.0330\n",
      "Epoch 260/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - accuracy: 1.0000 - loss: 1.2940e-08 - val_accuracy: 0.0386 - val_loss: 21.0007\n",
      "Epoch 261/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 907us/step - accuracy: 1.0000 - loss: 1.2829e-08 - val_accuracy: 0.0386 - val_loss: 20.9629\n",
      "Epoch 262/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 1.0000 - loss: 1.2986e-08 - val_accuracy: 0.0386 - val_loss: 20.9322\n",
      "Epoch 263/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - accuracy: 1.0000 - loss: 1.2573e-08 - val_accuracy: 0.0386 - val_loss: 20.8875\n",
      "Epoch 264/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - accuracy: 1.0000 - loss: 1.2984e-08 - val_accuracy: 0.0386 - val_loss: 20.8584\n",
      "Epoch 265/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 1.0000 - loss: 1.2663e-08 - val_accuracy: 0.0386 - val_loss: 20.8201\n",
      "Epoch 266/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 1.0000 - loss: 1.2566e-08 - val_accuracy: 0.0386 - val_loss: 20.7910\n",
      "Epoch 267/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888us/step - accuracy: 1.0000 - loss: 1.2771e-08 - val_accuracy: 0.0386 - val_loss: 20.7465\n",
      "Epoch 268/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899us/step - accuracy: 1.0000 - loss: 1.2845e-08 - val_accuracy: 0.0386 - val_loss: 20.7189\n",
      "Epoch 269/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - accuracy: 1.0000 - loss: 1.2919e-08 - val_accuracy: 0.0382 - val_loss: 20.6863\n",
      "Epoch 270/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 882us/step - accuracy: 1.0000 - loss: 1.2222e-08 - val_accuracy: 0.0382 - val_loss: 20.6441\n",
      "Epoch 271/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 1.0000 - loss: 1.3016e-08 - val_accuracy: 0.0382 - val_loss: 20.6200\n",
      "Epoch 272/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 909us/step - accuracy: 1.0000 - loss: 1.2276e-08 - val_accuracy: 0.0382 - val_loss: 20.5824\n",
      "Epoch 273/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 902us/step - accuracy: 1.0000 - loss: 1.2169e-08 - val_accuracy: 0.0382 - val_loss: 20.5501\n",
      "Epoch 274/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 1.0000 - loss: 1.2017e-08 - val_accuracy: 0.0386 - val_loss: 20.5181\n",
      "Epoch 275/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 885us/step - accuracy: 1.0000 - loss: 1.2079e-08 - val_accuracy: 0.0386 - val_loss: 20.4787\n",
      "Epoch 276/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895us/step - accuracy: 1.0000 - loss: 1.2774e-08 - val_accuracy: 0.0386 - val_loss: 20.4482\n",
      "Epoch 277/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - accuracy: 1.0000 - loss: 1.2151e-08 - val_accuracy: 0.0382 - val_loss: 20.4172\n",
      "Epoch 278/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - accuracy: 1.0000 - loss: 1.2664e-08 - val_accuracy: 0.0386 - val_loss: 20.3850\n",
      "Epoch 279/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step - accuracy: 1.0000 - loss: 1.1885e-08 - val_accuracy: 0.0382 - val_loss: 20.3525\n",
      "Epoch 280/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 882us/step - accuracy: 1.0000 - loss: 1.2597e-08 - val_accuracy: 0.0382 - val_loss: 20.3188\n",
      "Epoch 281/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step - accuracy: 1.0000 - loss: 1.2321e-08 - val_accuracy: 0.0382 - val_loss: 20.2910\n",
      "Epoch 282/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - accuracy: 1.0000 - loss: 1.2359e-08 - val_accuracy: 0.0382 - val_loss: 20.2566\n",
      "Epoch 283/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 882us/step - accuracy: 1.0000 - loss: 1.2198e-08 - val_accuracy: 0.0382 - val_loss: 20.2290\n",
      "Epoch 284/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 1.0000 - loss: 1.2075e-08 - val_accuracy: 0.0379 - val_loss: 20.2003\n",
      "Epoch 285/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 960us/step - accuracy: 1.0000 - loss: 1.1896e-08 - val_accuracy: 0.0379 - val_loss: 20.1627\n",
      "Epoch 286/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 1.0000 - loss: 1.2239e-08 - val_accuracy: 0.0379 - val_loss: 20.1359\n",
      "Epoch 287/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 1.0000 - loss: 1.1764e-08 - val_accuracy: 0.0379 - val_loss: 20.1041\n",
      "Epoch 288/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - accuracy: 1.0000 - loss: 1.2431e-08 - val_accuracy: 0.0379 - val_loss: 20.0782\n",
      "Epoch 289/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895us/step - accuracy: 1.0000 - loss: 1.2098e-08 - val_accuracy: 0.0379 - val_loss: 20.0504\n",
      "Epoch 290/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 960us/step - accuracy: 1.0000 - loss: 1.2305e-08 - val_accuracy: 0.0379 - val_loss: 20.0188\n",
      "Epoch 291/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 1.0000 - loss: 1.1933e-08 - val_accuracy: 0.0379 - val_loss: 19.9879\n",
      "Epoch 292/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911us/step - accuracy: 1.0000 - loss: 1.2204e-08 - val_accuracy: 0.0379 - val_loss: 19.9630\n",
      "Epoch 293/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895us/step - accuracy: 1.0000 - loss: 1.1984e-08 - val_accuracy: 0.0379 - val_loss: 19.9366\n",
      "Epoch 294/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 890us/step - accuracy: 1.0000 - loss: 1.1768e-08 - val_accuracy: 0.0379 - val_loss: 19.9080\n",
      "Epoch 295/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 1.0000 - loss: 1.2147e-08 - val_accuracy: 0.0382 - val_loss: 19.8830\n",
      "Epoch 296/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 907us/step - accuracy: 1.0000 - loss: 1.1690e-08 - val_accuracy: 0.0379 - val_loss: 19.8606\n",
      "Epoch 297/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 954us/step - accuracy: 1.0000 - loss: 1.1691e-08 - val_accuracy: 0.0379 - val_loss: 19.8230\n",
      "Epoch 298/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 922us/step - accuracy: 1.0000 - loss: 1.1898e-08 - val_accuracy: 0.0379 - val_loss: 19.7969\n",
      "Epoch 299/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 1.0000 - loss: 1.1998e-08 - val_accuracy: 0.0382 - val_loss: 19.7716\n",
      "Epoch 300/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905us/step - accuracy: 1.0000 - loss: 1.2317e-08 - val_accuracy: 0.0382 - val_loss: 19.7504\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "prueba_2: \n",
      "Epoch 1/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2638 - loss: 2.5237 - val_accuracy: 0.0000e+00 - val_loss: 6.6570\n",
      "Epoch 2/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 945us/step - accuracy: 0.7839 - loss: 1.2478 - val_accuracy: 0.0000e+00 - val_loss: 7.8388\n",
      "Epoch 3/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - accuracy: 0.9096 - loss: 0.5791 - val_accuracy: 0.0000e+00 - val_loss: 8.5510\n",
      "Epoch 4/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - accuracy: 0.9434 - loss: 0.3296 - val_accuracy: 0.0016 - val_loss: 9.0456\n",
      "Epoch 5/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - accuracy: 0.9656 - loss: 0.2128 - val_accuracy: 0.0083 - val_loss: 9.4422\n",
      "Epoch 6/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 966us/step - accuracy: 0.9797 - loss: 0.1456 - val_accuracy: 0.0153 - val_loss: 9.7962\n",
      "Epoch 7/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - accuracy: 0.9875 - loss: 0.1027 - val_accuracy: 0.0223 - val_loss: 10.1261\n",
      "Epoch 8/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905us/step - accuracy: 0.9932 - loss: 0.0736 - val_accuracy: 0.0271 - val_loss: 10.4393\n",
      "Epoch 9/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 943us/step - accuracy: 0.9964 - loss: 0.0529 - val_accuracy: 0.0293 - val_loss: 10.7413\n",
      "Epoch 10/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 0.9986 - loss: 0.0380 - val_accuracy: 0.0312 - val_loss: 11.0354\n",
      "Epoch 11/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 932us/step - accuracy: 0.9995 - loss: 0.0270 - val_accuracy: 0.0335 - val_loss: 11.3232\n",
      "Epoch 12/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - accuracy: 0.9999 - loss: 0.0190 - val_accuracy: 0.0347 - val_loss: 11.6068\n",
      "Epoch 13/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 935us/step - accuracy: 1.0000 - loss: 0.0136 - val_accuracy: 0.0354 - val_loss: 11.8859\n",
      "Epoch 14/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.0354 - val_loss: 12.1597\n",
      "Epoch 15/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 927us/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.0363 - val_loss: 12.4287\n",
      "Epoch 16/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 945us/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.0370 - val_loss: 12.6935\n",
      "Epoch 17/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.0366 - val_loss: 12.9546\n",
      "Epoch 18/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 970us/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.0376 - val_loss: 13.2125\n",
      "Epoch 19/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 901us/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.0376 - val_loss: 13.4677\n",
      "Epoch 20/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 923us/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.0376 - val_loss: 13.7202\n",
      "Epoch 21/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 1.0000 - loss: 9.6446e-04 - val_accuracy: 0.0373 - val_loss: 13.9703\n",
      "Epoch 22/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 1.0000 - loss: 6.9321e-04 - val_accuracy: 0.0373 - val_loss: 14.2174\n",
      "Epoch 23/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 929us/step - accuracy: 1.0000 - loss: 4.9800e-04 - val_accuracy: 0.0373 - val_loss: 14.4613\n",
      "Epoch 24/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 3.5755e-04 - val_accuracy: 0.0376 - val_loss: 14.7012\n",
      "Epoch 25/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 942us/step - accuracy: 1.0000 - loss: 2.5657e-04 - val_accuracy: 0.0376 - val_loss: 14.9361\n",
      "Epoch 26/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 1.8401e-04 - val_accuracy: 0.0376 - val_loss: 15.1652\n",
      "Epoch 27/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 920us/step - accuracy: 1.0000 - loss: 1.3190e-04 - val_accuracy: 0.0376 - val_loss: 15.3873\n",
      "Epoch 28/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 901us/step - accuracy: 1.0000 - loss: 9.4512e-05 - val_accuracy: 0.0373 - val_loss: 15.6014\n",
      "Epoch 29/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 941us/step - accuracy: 1.0000 - loss: 6.7703e-05 - val_accuracy: 0.0373 - val_loss: 15.8066\n",
      "Epoch 30/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 925us/step - accuracy: 1.0000 - loss: 4.8490e-05 - val_accuracy: 0.0376 - val_loss: 16.0024\n",
      "Epoch 31/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 941us/step - accuracy: 1.0000 - loss: 3.4727e-05 - val_accuracy: 0.0376 - val_loss: 16.1885\n",
      "Epoch 32/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893us/step - accuracy: 1.0000 - loss: 2.4873e-05 - val_accuracy: 0.0373 - val_loss: 16.3650\n",
      "Epoch 33/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 920us/step - accuracy: 1.0000 - loss: 1.7821e-05 - val_accuracy: 0.0370 - val_loss: 16.5325\n",
      "Epoch 34/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 926us/step - accuracy: 1.0000 - loss: 1.2774e-05 - val_accuracy: 0.0373 - val_loss: 16.6915\n",
      "Epoch 35/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 1.0000 - loss: 9.1700e-06 - val_accuracy: 0.0373 - val_loss: 16.8431\n",
      "Epoch 36/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 6.5870e-06 - val_accuracy: 0.0373 - val_loss: 16.9878\n",
      "Epoch 37/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - accuracy: 1.0000 - loss: 4.7422e-06 - val_accuracy: 0.0376 - val_loss: 17.1262\n",
      "Epoch 38/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step - accuracy: 1.0000 - loss: 3.4248e-06 - val_accuracy: 0.0376 - val_loss: 17.2586\n",
      "Epoch 39/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - accuracy: 1.0000 - loss: 2.4829e-06 - val_accuracy: 0.0376 - val_loss: 17.3858\n",
      "Epoch 40/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 935us/step - accuracy: 1.0000 - loss: 1.8102e-06 - val_accuracy: 0.0379 - val_loss: 17.5065\n",
      "Epoch 41/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 1.0000 - loss: 1.3287e-06 - val_accuracy: 0.0376 - val_loss: 17.6226\n",
      "Epoch 42/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 937us/step - accuracy: 1.0000 - loss: 9.8121e-07 - val_accuracy: 0.0379 - val_loss: 17.7324\n",
      "Epoch 43/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 938us/step - accuracy: 1.0000 - loss: 7.3411e-07 - val_accuracy: 0.0382 - val_loss: 17.8346\n",
      "Epoch 44/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 946us/step - accuracy: 1.0000 - loss: 5.5466e-07 - val_accuracy: 0.0382 - val_loss: 17.9272\n",
      "Epoch 45/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 910us/step - accuracy: 1.0000 - loss: 4.2595e-07 - val_accuracy: 0.0379 - val_loss: 18.0106\n",
      "Epoch 46/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 1.0000 - loss: 3.3206e-07 - val_accuracy: 0.0376 - val_loss: 18.0815\n",
      "Epoch 47/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 942us/step - accuracy: 1.0000 - loss: 2.6304e-07 - val_accuracy: 0.0379 - val_loss: 18.1398\n",
      "Epoch 48/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 930us/step - accuracy: 1.0000 - loss: 2.1244e-07 - val_accuracy: 0.0376 - val_loss: 18.1928\n",
      "Epoch 49/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 927us/step - accuracy: 1.0000 - loss: 1.7357e-07 - val_accuracy: 0.0376 - val_loss: 18.2305\n",
      "Epoch 50/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 892us/step - accuracy: 1.0000 - loss: 1.4539e-07 - val_accuracy: 0.0376 - val_loss: 18.2605\n",
      "Epoch 51/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933us/step - accuracy: 1.0000 - loss: 1.2282e-07 - val_accuracy: 0.0373 - val_loss: 18.2811\n",
      "Epoch 52/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 908us/step - accuracy: 1.0000 - loss: 1.0626e-07 - val_accuracy: 0.0376 - val_loss: 18.2904\n",
      "Epoch 53/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 958us/step - accuracy: 1.0000 - loss: 9.1943e-08 - val_accuracy: 0.0376 - val_loss: 18.2804\n",
      "Epoch 54/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - accuracy: 1.0000 - loss: 8.1637e-08 - val_accuracy: 0.0373 - val_loss: 18.2709\n",
      "Epoch 55/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 1.0000 - loss: 7.1877e-08 - val_accuracy: 0.0376 - val_loss: 18.2501\n",
      "Epoch 56/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 909us/step - accuracy: 1.0000 - loss: 6.5063e-08 - val_accuracy: 0.0376 - val_loss: 18.2256\n",
      "Epoch 57/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 958us/step - accuracy: 1.0000 - loss: 5.8822e-08 - val_accuracy: 0.0382 - val_loss: 18.1932\n",
      "Epoch 58/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 927us/step - accuracy: 1.0000 - loss: 5.3944e-08 - val_accuracy: 0.0379 - val_loss: 18.1643\n",
      "Epoch 59/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 910us/step - accuracy: 1.0000 - loss: 4.9745e-08 - val_accuracy: 0.0379 - val_loss: 18.1302\n",
      "Epoch 60/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step - accuracy: 1.0000 - loss: 4.5460e-08 - val_accuracy: 0.0379 - val_loss: 18.0909\n",
      "Epoch 61/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step - accuracy: 1.0000 - loss: 4.2297e-08 - val_accuracy: 0.0382 - val_loss: 18.0481\n",
      "Epoch 62/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 900us/step - accuracy: 1.0000 - loss: 3.9163e-08 - val_accuracy: 0.0382 - val_loss: 18.0026\n",
      "Epoch 63/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - accuracy: 1.0000 - loss: 3.6480e-08 - val_accuracy: 0.0382 - val_loss: 17.9553\n",
      "Epoch 64/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 938us/step - accuracy: 1.0000 - loss: 3.4668e-08 - val_accuracy: 0.0386 - val_loss: 17.9024\n",
      "Epoch 65/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 922us/step - accuracy: 1.0000 - loss: 3.2729e-08 - val_accuracy: 0.0386 - val_loss: 17.8459\n",
      "Epoch 66/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - accuracy: 1.0000 - loss: 3.0758e-08 - val_accuracy: 0.0386 - val_loss: 17.7899\n",
      "Epoch 67/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 902us/step - accuracy: 1.0000 - loss: 2.9409e-08 - val_accuracy: 0.0386 - val_loss: 17.7306\n",
      "Epoch 68/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 948us/step - accuracy: 1.0000 - loss: 2.7685e-08 - val_accuracy: 0.0386 - val_loss: 17.6704\n",
      "Epoch 69/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - accuracy: 1.0000 - loss: 2.6122e-08 - val_accuracy: 0.0386 - val_loss: 17.6064\n",
      "Epoch 70/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 923us/step - accuracy: 1.0000 - loss: 2.4905e-08 - val_accuracy: 0.0386 - val_loss: 17.5448\n",
      "Epoch 71/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 900us/step - accuracy: 1.0000 - loss: 2.3728e-08 - val_accuracy: 0.0389 - val_loss: 17.4802\n",
      "Epoch 72/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step - accuracy: 1.0000 - loss: 2.2885e-08 - val_accuracy: 0.0389 - val_loss: 17.4158\n",
      "Epoch 73/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 917us/step - accuracy: 1.0000 - loss: 2.1689e-08 - val_accuracy: 0.0392 - val_loss: 17.3493\n",
      "Epoch 74/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 1.0000 - loss: 2.1054e-08 - val_accuracy: 0.0392 - val_loss: 17.2850\n",
      "Epoch 75/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 2.0411e-08 - val_accuracy: 0.0392 - val_loss: 17.2226\n",
      "Epoch 76/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 927us/step - accuracy: 1.0000 - loss: 1.9467e-08 - val_accuracy: 0.0395 - val_loss: 17.1570\n",
      "Epoch 77/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 939us/step - accuracy: 1.0000 - loss: 1.8817e-08 - val_accuracy: 0.0395 - val_loss: 17.0910\n",
      "Epoch 78/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 938us/step - accuracy: 1.0000 - loss: 1.8261e-08 - val_accuracy: 0.0395 - val_loss: 17.0265\n",
      "Epoch 79/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888us/step - accuracy: 1.0000 - loss: 1.7883e-08 - val_accuracy: 0.0398 - val_loss: 16.9633\n",
      "Epoch 80/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 942us/step - accuracy: 1.0000 - loss: 1.7378e-08 - val_accuracy: 0.0398 - val_loss: 16.9026\n",
      "Epoch 81/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 1.0000 - loss: 1.6674e-08 - val_accuracy: 0.0398 - val_loss: 16.8377\n",
      "Epoch 82/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 922us/step - accuracy: 1.0000 - loss: 1.6056e-08 - val_accuracy: 0.0402 - val_loss: 16.7704\n",
      "Epoch 83/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - accuracy: 1.0000 - loss: 1.5725e-08 - val_accuracy: 0.0405 - val_loss: 16.7066\n",
      "Epoch 84/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 908us/step - accuracy: 1.0000 - loss: 1.5173e-08 - val_accuracy: 0.0405 - val_loss: 16.6414\n",
      "Epoch 85/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step - accuracy: 1.0000 - loss: 1.5152e-08 - val_accuracy: 0.0408 - val_loss: 16.5800\n",
      "Epoch 86/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 929us/step - accuracy: 1.0000 - loss: 1.4685e-08 - val_accuracy: 0.0411 - val_loss: 16.5193\n",
      "Epoch 87/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 938us/step - accuracy: 1.0000 - loss: 1.4306e-08 - val_accuracy: 0.0411 - val_loss: 16.4569\n",
      "Epoch 88/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 920us/step - accuracy: 1.0000 - loss: 1.4199e-08 - val_accuracy: 0.0411 - val_loss: 16.3955\n",
      "Epoch 89/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 926us/step - accuracy: 1.0000 - loss: 1.3752e-08 - val_accuracy: 0.0414 - val_loss: 16.3350\n",
      "Epoch 90/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 926us/step - accuracy: 1.0000 - loss: 1.3562e-08 - val_accuracy: 0.0414 - val_loss: 16.2774\n",
      "Epoch 91/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step - accuracy: 1.0000 - loss: 1.3726e-08 - val_accuracy: 0.0414 - val_loss: 16.2245\n",
      "Epoch 92/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 926us/step - accuracy: 1.0000 - loss: 1.2933e-08 - val_accuracy: 0.0414 - val_loss: 16.1670\n",
      "Epoch 93/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 910us/step - accuracy: 1.0000 - loss: 1.2927e-08 - val_accuracy: 0.0414 - val_loss: 16.1104\n",
      "Epoch 94/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 938us/step - accuracy: 1.0000 - loss: 1.2887e-08 - val_accuracy: 0.0414 - val_loss: 16.0564\n",
      "Epoch 95/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 1.0000 - loss: 1.2589e-08 - val_accuracy: 0.0414 - val_loss: 16.0033\n",
      "Epoch 96/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 1.0000 - loss: 1.2272e-08 - val_accuracy: 0.0417 - val_loss: 15.9548\n",
      "Epoch 97/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911us/step - accuracy: 1.0000 - loss: 1.2379e-08 - val_accuracy: 0.0414 - val_loss: 15.9014\n",
      "Epoch 98/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 939us/step - accuracy: 1.0000 - loss: 1.2019e-08 - val_accuracy: 0.0417 - val_loss: 15.8553\n",
      "Epoch 99/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 923us/step - accuracy: 1.0000 - loss: 1.1882e-08 - val_accuracy: 0.0417 - val_loss: 15.8070\n",
      "Epoch 100/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934us/step - accuracy: 1.0000 - loss: 1.1804e-08 - val_accuracy: 0.0417 - val_loss: 15.7578\n",
      "Epoch 101/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 925us/step - accuracy: 1.0000 - loss: 1.1847e-08 - val_accuracy: 0.0421 - val_loss: 15.7158\n",
      "Epoch 102/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - accuracy: 1.0000 - loss: 1.1391e-08 - val_accuracy: 0.0421 - val_loss: 15.6727\n",
      "Epoch 103/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - accuracy: 1.0000 - loss: 1.1204e-08 - val_accuracy: 0.0421 - val_loss: 15.6281\n",
      "Epoch 104/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 945us/step - accuracy: 1.0000 - loss: 1.1746e-08 - val_accuracy: 0.0421 - val_loss: 15.5876\n",
      "Epoch 105/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 1.0000 - loss: 1.1214e-08 - val_accuracy: 0.0421 - val_loss: 15.5515\n",
      "Epoch 106/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 920us/step - accuracy: 1.0000 - loss: 1.1070e-08 - val_accuracy: 0.0421 - val_loss: 15.5101\n",
      "Epoch 107/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 900us/step - accuracy: 1.0000 - loss: 1.0971e-08 - val_accuracy: 0.0421 - val_loss: 15.4742\n",
      "Epoch 108/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 926us/step - accuracy: 1.0000 - loss: 1.1259e-08 - val_accuracy: 0.0421 - val_loss: 15.4392\n",
      "Epoch 109/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 904us/step - accuracy: 1.0000 - loss: 1.0940e-08 - val_accuracy: 0.0421 - val_loss: 15.4108\n",
      "Epoch 110/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 936us/step - accuracy: 1.0000 - loss: 1.0549e-08 - val_accuracy: 0.0421 - val_loss: 15.3728\n",
      "Epoch 111/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 923us/step - accuracy: 1.0000 - loss: 1.0755e-08 - val_accuracy: 0.0421 - val_loss: 15.3397\n",
      "Epoch 112/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 937us/step - accuracy: 1.0000 - loss: 1.0763e-08 - val_accuracy: 0.0421 - val_loss: 15.3098\n",
      "Epoch 113/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - accuracy: 1.0000 - loss: 1.0685e-08 - val_accuracy: 0.0421 - val_loss: 15.2838\n",
      "Epoch 114/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933us/step - accuracy: 1.0000 - loss: 1.0410e-08 - val_accuracy: 0.0421 - val_loss: 15.2527\n",
      "Epoch 115/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 1.0000 - loss: 1.0722e-08 - val_accuracy: 0.0421 - val_loss: 15.2291\n",
      "Epoch 116/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 923us/step - accuracy: 1.0000 - loss: 1.0375e-08 - val_accuracy: 0.0421 - val_loss: 15.2018\n",
      "Epoch 117/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 947us/step - accuracy: 1.0000 - loss: 1.0380e-08 - val_accuracy: 0.0421 - val_loss: 15.1792\n",
      "Epoch 118/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 907us/step - accuracy: 1.0000 - loss: 1.0264e-08 - val_accuracy: 0.0421 - val_loss: 15.1543\n",
      "Epoch 119/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 923us/step - accuracy: 1.0000 - loss: 1.0200e-08 - val_accuracy: 0.0421 - val_loss: 15.1360\n",
      "Epoch 120/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - accuracy: 1.0000 - loss: 9.8831e-09 - val_accuracy: 0.0421 - val_loss: 15.1075\n",
      "Epoch 121/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 961us/step - accuracy: 1.0000 - loss: 1.0396e-08 - val_accuracy: 0.0417 - val_loss: 15.0904\n",
      "Epoch 122/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - accuracy: 1.0000 - loss: 9.9864e-09 - val_accuracy: 0.0417 - val_loss: 15.0713\n",
      "Epoch 123/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - accuracy: 1.0000 - loss: 9.8937e-09 - val_accuracy: 0.0417 - val_loss: 15.0473\n",
      "Epoch 124/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899us/step - accuracy: 1.0000 - loss: 1.0025e-08 - val_accuracy: 0.0417 - val_loss: 15.0318\n",
      "Epoch 125/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 924us/step - accuracy: 1.0000 - loss: 9.8010e-09 - val_accuracy: 0.0417 - val_loss: 15.0135\n",
      "Epoch 126/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 1.0000 - loss: 9.9852e-09 - val_accuracy: 0.0417 - val_loss: 14.9937\n",
      "Epoch 127/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933us/step - accuracy: 1.0000 - loss: 9.8870e-09 - val_accuracy: 0.0417 - val_loss: 14.9799\n",
      "Epoch 128/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 902us/step - accuracy: 1.0000 - loss: 9.7079e-09 - val_accuracy: 0.0417 - val_loss: 14.9617\n",
      "Epoch 129/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 929us/step - accuracy: 1.0000 - loss: 9.8772e-09 - val_accuracy: 0.0417 - val_loss: 14.9477\n",
      "Epoch 130/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 887us/step - accuracy: 1.0000 - loss: 9.7127e-09 - val_accuracy: 0.0417 - val_loss: 14.9351\n",
      "Epoch 131/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 927us/step - accuracy: 1.0000 - loss: 9.5079e-09 - val_accuracy: 0.0417 - val_loss: 14.9196\n",
      "Epoch 132/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step - accuracy: 1.0000 - loss: 9.7866e-09 - val_accuracy: 0.0417 - val_loss: 14.9076\n",
      "Epoch 133/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 939us/step - accuracy: 1.0000 - loss: 9.6072e-09 - val_accuracy: 0.0417 - val_loss: 14.8915\n",
      "Epoch 134/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911us/step - accuracy: 1.0000 - loss: 9.4982e-09 - val_accuracy: 0.0417 - val_loss: 14.8804\n",
      "Epoch 135/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - accuracy: 1.0000 - loss: 9.6609e-09 - val_accuracy: 0.0417 - val_loss: 14.8652\n",
      "Epoch 136/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 902us/step - accuracy: 1.0000 - loss: 9.6784e-09 - val_accuracy: 0.0417 - val_loss: 14.8520\n",
      "Epoch 137/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 910us/step - accuracy: 1.0000 - loss: 9.5895e-09 - val_accuracy: 0.0417 - val_loss: 14.8475\n",
      "Epoch 138/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 9.3577e-09 - val_accuracy: 0.0417 - val_loss: 14.8347\n",
      "Epoch 139/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - accuracy: 1.0000 - loss: 9.3979e-09 - val_accuracy: 0.0417 - val_loss: 14.8213\n",
      "Epoch 140/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 892us/step - accuracy: 1.0000 - loss: 9.7938e-09 - val_accuracy: 0.0414 - val_loss: 14.8139\n",
      "Epoch 141/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 924us/step - accuracy: 1.0000 - loss: 9.3299e-09 - val_accuracy: 0.0411 - val_loss: 14.8046\n",
      "Epoch 142/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step - accuracy: 1.0000 - loss: 9.3818e-09 - val_accuracy: 0.0411 - val_loss: 14.7952\n",
      "Epoch 143/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 909us/step - accuracy: 1.0000 - loss: 9.3493e-09 - val_accuracy: 0.0411 - val_loss: 14.7842\n",
      "Epoch 144/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 949us/step - accuracy: 1.0000 - loss: 9.5603e-09 - val_accuracy: 0.0411 - val_loss: 14.7753\n",
      "Epoch 145/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 1.0000 - loss: 9.2106e-09 - val_accuracy: 0.0411 - val_loss: 14.7649\n",
      "Epoch 146/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - accuracy: 1.0000 - loss: 9.7921e-09 - val_accuracy: 0.0411 - val_loss: 14.7647\n",
      "Epoch 147/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 904us/step - accuracy: 1.0000 - loss: 9.1662e-09 - val_accuracy: 0.0411 - val_loss: 14.7542\n",
      "Epoch 148/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - accuracy: 1.0000 - loss: 9.3716e-09 - val_accuracy: 0.0411 - val_loss: 14.7474\n",
      "Epoch 149/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 892us/step - accuracy: 1.0000 - loss: 9.2960e-09 - val_accuracy: 0.0408 - val_loss: 14.7372\n",
      "Epoch 150/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - accuracy: 1.0000 - loss: 9.3741e-09 - val_accuracy: 0.0411 - val_loss: 14.7333\n",
      "Epoch 151/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 908us/step - accuracy: 1.0000 - loss: 9.2692e-09 - val_accuracy: 0.0411 - val_loss: 14.7273\n",
      "Epoch 152/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899us/step - accuracy: 1.0000 - loss: 9.4537e-09 - val_accuracy: 0.0411 - val_loss: 14.7242\n",
      "Epoch 153/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 1.0000 - loss: 9.4300e-09 - val_accuracy: 0.0408 - val_loss: 14.7137\n",
      "Epoch 154/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 1.0000 - loss: 9.6360e-09 - val_accuracy: 0.0408 - val_loss: 14.7142\n",
      "Epoch 155/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 920us/step - accuracy: 1.0000 - loss: 9.3379e-09 - val_accuracy: 0.0408 - val_loss: 14.7059\n",
      "Epoch 156/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 902us/step - accuracy: 1.0000 - loss: 9.3030e-09 - val_accuracy: 0.0408 - val_loss: 14.7028\n",
      "Epoch 157/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 1.0000 - loss: 9.2218e-09 - val_accuracy: 0.0408 - val_loss: 14.6966\n",
      "Epoch 158/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 876us/step - accuracy: 1.0000 - loss: 9.6532e-09 - val_accuracy: 0.0408 - val_loss: 14.6914\n",
      "Epoch 159/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 920us/step - accuracy: 1.0000 - loss: 9.3265e-09 - val_accuracy: 0.0408 - val_loss: 14.6849\n",
      "Epoch 160/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - accuracy: 1.0000 - loss: 9.4976e-09 - val_accuracy: 0.0408 - val_loss: 14.6790\n",
      "Epoch 161/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 910us/step - accuracy: 1.0000 - loss: 9.5868e-09 - val_accuracy: 0.0408 - val_loss: 14.6737\n",
      "Epoch 162/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 1.0000 - loss: 9.5181e-09 - val_accuracy: 0.0408 - val_loss: 14.6729\n",
      "Epoch 163/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 897us/step - accuracy: 1.0000 - loss: 9.4791e-09 - val_accuracy: 0.0408 - val_loss: 14.6717\n",
      "Epoch 164/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 946us/step - accuracy: 1.0000 - loss: 9.0923e-09 - val_accuracy: 0.0408 - val_loss: 14.6657\n",
      "Epoch 165/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 1.0000 - loss: 9.6051e-09 - val_accuracy: 0.0408 - val_loss: 14.6628\n",
      "Epoch 166/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 945us/step - accuracy: 1.0000 - loss: 9.3440e-09 - val_accuracy: 0.0408 - val_loss: 14.6580\n",
      "Epoch 167/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.3765e-09 - val_accuracy: 0.0408 - val_loss: 14.6559\n",
      "Epoch 168/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.4655e-09 - val_accuracy: 0.0408 - val_loss: 14.6546\n",
      "Epoch 169/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.3229e-09 - val_accuracy: 0.0408 - val_loss: 14.6524\n",
      "Epoch 170/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 989us/step - accuracy: 1.0000 - loss: 9.1936e-09 - val_accuracy: 0.0405 - val_loss: 14.6485\n",
      "Epoch 171/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.4255e-09 - val_accuracy: 0.0405 - val_loss: 14.6422\n",
      "Epoch 172/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 989us/step - accuracy: 1.0000 - loss: 9.4445e-09 - val_accuracy: 0.0405 - val_loss: 14.6446\n",
      "Epoch 173/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 908us/step - accuracy: 1.0000 - loss: 9.1310e-09 - val_accuracy: 0.0405 - val_loss: 14.6406\n",
      "Epoch 174/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 984us/step - accuracy: 1.0000 - loss: 9.2053e-09 - val_accuracy: 0.0405 - val_loss: 14.6361\n",
      "Epoch 175/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 920us/step - accuracy: 1.0000 - loss: 9.4499e-09 - val_accuracy: 0.0405 - val_loss: 14.6392\n",
      "Epoch 176/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 929us/step - accuracy: 1.0000 - loss: 9.0523e-09 - val_accuracy: 0.0405 - val_loss: 14.6288\n",
      "Epoch 177/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 935us/step - accuracy: 1.0000 - loss: 9.4864e-09 - val_accuracy: 0.0408 - val_loss: 14.6287\n",
      "Epoch 178/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 910us/step - accuracy: 1.0000 - loss: 9.3465e-09 - val_accuracy: 0.0408 - val_loss: 14.6259\n",
      "Epoch 179/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.2772e-09 - val_accuracy: 0.0408 - val_loss: 14.6216\n",
      "Epoch 180/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 997us/step - accuracy: 1.0000 - loss: 9.4903e-09 - val_accuracy: 0.0408 - val_loss: 14.6217\n",
      "Epoch 181/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 953us/step - accuracy: 1.0000 - loss: 9.3052e-09 - val_accuracy: 0.0405 - val_loss: 14.6210\n",
      "Epoch 182/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 901us/step - accuracy: 1.0000 - loss: 9.1092e-09 - val_accuracy: 0.0405 - val_loss: 14.6159\n",
      "Epoch 183/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888us/step - accuracy: 1.0000 - loss: 9.2909e-09 - val_accuracy: 0.0405 - val_loss: 14.6082\n",
      "Epoch 184/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 946us/step - accuracy: 1.0000 - loss: 9.7299e-09 - val_accuracy: 0.0405 - val_loss: 14.6060\n",
      "Epoch 185/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 917us/step - accuracy: 1.0000 - loss: 9.8438e-09 - val_accuracy: 0.0402 - val_loss: 14.6147\n",
      "Epoch 186/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 935us/step - accuracy: 1.0000 - loss: 9.1824e-09 - val_accuracy: 0.0402 - val_loss: 14.6098\n",
      "Epoch 187/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 954us/step - accuracy: 1.0000 - loss: 9.2695e-09 - val_accuracy: 0.0405 - val_loss: 14.6038\n",
      "Epoch 188/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 917us/step - accuracy: 1.0000 - loss: 9.3173e-09 - val_accuracy: 0.0405 - val_loss: 14.6000\n",
      "Epoch 189/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934us/step - accuracy: 1.0000 - loss: 9.6311e-09 - val_accuracy: 0.0405 - val_loss: 14.5995\n",
      "Epoch 190/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - accuracy: 1.0000 - loss: 9.5282e-09 - val_accuracy: 0.0405 - val_loss: 14.5987\n",
      "Epoch 191/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 9.3493e-09 - val_accuracy: 0.0405 - val_loss: 14.5923\n",
      "Epoch 192/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - accuracy: 1.0000 - loss: 9.7886e-09 - val_accuracy: 0.0405 - val_loss: 14.5936\n",
      "Epoch 193/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 904us/step - accuracy: 1.0000 - loss: 9.3660e-09 - val_accuracy: 0.0405 - val_loss: 14.5902\n",
      "Epoch 194/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 962us/step - accuracy: 1.0000 - loss: 9.4873e-09 - val_accuracy: 0.0405 - val_loss: 14.5816\n",
      "Epoch 195/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 936us/step - accuracy: 1.0000 - loss: 9.9344e-09 - val_accuracy: 0.0405 - val_loss: 14.5893\n",
      "Epoch 196/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 947us/step - accuracy: 1.0000 - loss: 9.1502e-09 - val_accuracy: 0.0405 - val_loss: 14.5873\n",
      "Epoch 197/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 9.3967e-09 - val_accuracy: 0.0405 - val_loss: 14.5789\n",
      "Epoch 198/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 1.0000 - loss: 9.6616e-09 - val_accuracy: 0.0405 - val_loss: 14.5785\n",
      "Epoch 199/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 922us/step - accuracy: 1.0000 - loss: 9.5934e-09 - val_accuracy: 0.0405 - val_loss: 14.5785\n",
      "Epoch 200/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - accuracy: 1.0000 - loss: 9.4913e-09 - val_accuracy: 0.0408 - val_loss: 14.5779\n",
      "Epoch 201/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934us/step - accuracy: 1.0000 - loss: 9.5660e-09 - val_accuracy: 0.0408 - val_loss: 14.5709\n",
      "Epoch 202/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 951us/step - accuracy: 1.0000 - loss: 9.7260e-09 - val_accuracy: 0.0405 - val_loss: 14.5711\n",
      "Epoch 203/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step - accuracy: 1.0000 - loss: 9.9815e-09 - val_accuracy: 0.0405 - val_loss: 14.5701\n",
      "Epoch 204/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933us/step - accuracy: 1.0000 - loss: 9.6894e-09 - val_accuracy: 0.0411 - val_loss: 14.5687\n",
      "Epoch 205/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 892us/step - accuracy: 1.0000 - loss: 9.7231e-09 - val_accuracy: 0.0414 - val_loss: 14.5650\n",
      "Epoch 206/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959us/step - accuracy: 1.0000 - loss: 9.7211e-09 - val_accuracy: 0.0411 - val_loss: 14.5668\n",
      "Epoch 207/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 967us/step - accuracy: 1.0000 - loss: 9.5559e-09 - val_accuracy: 0.0414 - val_loss: 14.5629\n",
      "Epoch 208/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - accuracy: 1.0000 - loss: 9.7193e-09 - val_accuracy: 0.0414 - val_loss: 14.5675\n",
      "Epoch 209/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 930us/step - accuracy: 1.0000 - loss: 9.5118e-09 - val_accuracy: 0.0414 - val_loss: 14.5572\n",
      "Epoch 210/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 929us/step - accuracy: 1.0000 - loss: 9.8224e-09 - val_accuracy: 0.0414 - val_loss: 14.5640\n",
      "Epoch 211/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - accuracy: 1.0000 - loss: 9.4596e-09 - val_accuracy: 0.0414 - val_loss: 14.5579\n",
      "Epoch 212/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 962us/step - accuracy: 1.0000 - loss: 9.7328e-09 - val_accuracy: 0.0414 - val_loss: 14.5514\n",
      "Epoch 213/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 942us/step - accuracy: 1.0000 - loss: 9.9283e-09 - val_accuracy: 0.0411 - val_loss: 14.5553\n",
      "Epoch 214/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - accuracy: 1.0000 - loss: 9.9748e-09 - val_accuracy: 0.0417 - val_loss: 14.5548\n",
      "Epoch 215/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 924us/step - accuracy: 1.0000 - loss: 9.5329e-09 - val_accuracy: 0.0414 - val_loss: 14.5495\n",
      "Epoch 216/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 1.0000 - loss: 1.0020e-08 - val_accuracy: 0.0414 - val_loss: 14.5465\n",
      "Epoch 217/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 943us/step - accuracy: 1.0000 - loss: 9.8260e-09 - val_accuracy: 0.0414 - val_loss: 14.5488\n",
      "Epoch 218/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step - accuracy: 1.0000 - loss: 9.7699e-09 - val_accuracy: 0.0414 - val_loss: 14.5500\n",
      "Epoch 219/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 925us/step - accuracy: 1.0000 - loss: 9.9004e-09 - val_accuracy: 0.0417 - val_loss: 14.5442\n",
      "Epoch 220/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 935us/step - accuracy: 1.0000 - loss: 1.0038e-08 - val_accuracy: 0.0417 - val_loss: 14.5421\n",
      "Epoch 221/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 9.9846e-09 - val_accuracy: 0.0417 - val_loss: 14.5415\n",
      "Epoch 222/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 1.0000 - loss: 9.9930e-09 - val_accuracy: 0.0417 - val_loss: 14.5443\n",
      "Epoch 223/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 962us/step - accuracy: 1.0000 - loss: 9.8500e-09 - val_accuracy: 0.0417 - val_loss: 14.5400\n",
      "Epoch 224/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 927us/step - accuracy: 1.0000 - loss: 9.7406e-09 - val_accuracy: 0.0417 - val_loss: 14.5343\n",
      "Epoch 225/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 969us/step - accuracy: 1.0000 - loss: 1.0044e-08 - val_accuracy: 0.0417 - val_loss: 14.5377\n",
      "Epoch 226/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934us/step - accuracy: 1.0000 - loss: 9.9083e-09 - val_accuracy: 0.0417 - val_loss: 14.5327\n",
      "Epoch 227/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 936us/step - accuracy: 1.0000 - loss: 1.0185e-08 - val_accuracy: 0.0417 - val_loss: 14.5363\n",
      "Epoch 228/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 929us/step - accuracy: 1.0000 - loss: 9.7781e-09 - val_accuracy: 0.0417 - val_loss: 14.5283\n",
      "Epoch 229/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 922us/step - accuracy: 1.0000 - loss: 1.0033e-08 - val_accuracy: 0.0417 - val_loss: 14.5329\n",
      "Epoch 230/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 956us/step - accuracy: 1.0000 - loss: 9.9591e-09 - val_accuracy: 0.0417 - val_loss: 14.5275\n",
      "Epoch 231/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 897us/step - accuracy: 1.0000 - loss: 9.9854e-09 - val_accuracy: 0.0417 - val_loss: 14.5270\n",
      "Epoch 232/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - accuracy: 1.0000 - loss: 9.8957e-09 - val_accuracy: 0.0417 - val_loss: 14.5343\n",
      "Epoch 233/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - accuracy: 1.0000 - loss: 9.9667e-09 - val_accuracy: 0.0417 - val_loss: 14.5366\n",
      "Epoch 234/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 9.6063e-09 - val_accuracy: 0.0421 - val_loss: 14.5279\n",
      "Epoch 235/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 1.0000 - loss: 1.0004e-08 - val_accuracy: 0.0417 - val_loss: 14.5249\n",
      "Epoch 236/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 924us/step - accuracy: 1.0000 - loss: 1.0042e-08 - val_accuracy: 0.0421 - val_loss: 14.5256\n",
      "Epoch 237/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933us/step - accuracy: 1.0000 - loss: 1.0272e-08 - val_accuracy: 0.0421 - val_loss: 14.5285\n",
      "Epoch 238/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 917us/step - accuracy: 1.0000 - loss: 9.8078e-09 - val_accuracy: 0.0421 - val_loss: 14.5276\n",
      "Epoch 239/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934us/step - accuracy: 1.0000 - loss: 9.8822e-09 - val_accuracy: 0.0421 - val_loss: 14.5296\n",
      "Epoch 240/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 941us/step - accuracy: 1.0000 - loss: 9.6351e-09 - val_accuracy: 0.0421 - val_loss: 14.5225\n",
      "Epoch 241/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 936us/step - accuracy: 1.0000 - loss: 1.0040e-08 - val_accuracy: 0.0424 - val_loss: 14.5243\n",
      "Epoch 242/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 925us/step - accuracy: 1.0000 - loss: 1.0014e-08 - val_accuracy: 0.0424 - val_loss: 14.5185\n",
      "Epoch 243/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 1.0000 - loss: 1.0137e-08 - val_accuracy: 0.0424 - val_loss: 14.5237\n",
      "Epoch 244/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905us/step - accuracy: 1.0000 - loss: 9.7830e-09 - val_accuracy: 0.0421 - val_loss: 14.5232\n",
      "Epoch 245/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 882us/step - accuracy: 1.0000 - loss: 9.8473e-09 - val_accuracy: 0.0424 - val_loss: 14.5218\n",
      "Epoch 246/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 901us/step - accuracy: 1.0000 - loss: 1.0075e-08 - val_accuracy: 0.0424 - val_loss: 14.5239\n",
      "Epoch 247/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 1.0000 - loss: 9.9424e-09 - val_accuracy: 0.0427 - val_loss: 14.5185\n",
      "Epoch 248/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 1.0000 - loss: 1.0193e-08 - val_accuracy: 0.0424 - val_loss: 14.5186\n",
      "Epoch 249/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 890us/step - accuracy: 1.0000 - loss: 1.0183e-08 - val_accuracy: 0.0424 - val_loss: 14.5172\n",
      "Epoch 250/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 946us/step - accuracy: 1.0000 - loss: 1.0061e-08 - val_accuracy: 0.0427 - val_loss: 14.5188\n",
      "Epoch 251/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 881us/step - accuracy: 1.0000 - loss: 1.0102e-08 - val_accuracy: 0.0427 - val_loss: 14.5164\n",
      "Epoch 252/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 1.0202e-08 - val_accuracy: 0.0424 - val_loss: 14.5140\n",
      "Epoch 253/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 981us/step - accuracy: 1.0000 - loss: 1.0393e-08 - val_accuracy: 0.0427 - val_loss: 14.5134\n",
      "Epoch 254/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - accuracy: 1.0000 - loss: 1.0196e-08 - val_accuracy: 0.0427 - val_loss: 14.5200\n",
      "Epoch 255/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 1.0000 - loss: 9.9656e-09 - val_accuracy: 0.0427 - val_loss: 14.5149\n",
      "Epoch 256/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 1.0000 - loss: 1.0060e-08 - val_accuracy: 0.0427 - val_loss: 14.5155\n",
      "Epoch 257/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 1.0000 - loss: 9.9540e-09 - val_accuracy: 0.0430 - val_loss: 14.5139\n",
      "Epoch 258/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - accuracy: 1.0000 - loss: 1.0161e-08 - val_accuracy: 0.0430 - val_loss: 14.5141\n",
      "Epoch 259/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 1.0000 - loss: 1.0056e-08 - val_accuracy: 0.0430 - val_loss: 14.5127\n",
      "Epoch 260/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 909us/step - accuracy: 1.0000 - loss: 1.0027e-08 - val_accuracy: 0.0427 - val_loss: 14.5152\n",
      "Epoch 261/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 1.0000 - loss: 1.0328e-08 - val_accuracy: 0.0430 - val_loss: 14.5168\n",
      "Epoch 262/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 1.0000 - loss: 9.8999e-09 - val_accuracy: 0.0427 - val_loss: 14.5128\n",
      "Epoch 263/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 1.0000 - loss: 1.0379e-08 - val_accuracy: 0.0427 - val_loss: 14.5073\n",
      "Epoch 264/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step - accuracy: 1.0000 - loss: 1.0502e-08 - val_accuracy: 0.0427 - val_loss: 14.5136\n",
      "Epoch 265/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 1.0000 - loss: 1.0187e-08 - val_accuracy: 0.0427 - val_loss: 14.5130\n",
      "Epoch 266/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959us/step - accuracy: 1.0000 - loss: 1.0150e-08 - val_accuracy: 0.0427 - val_loss: 14.5088\n",
      "Epoch 267/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.0326e-08 - val_accuracy: 0.0427 - val_loss: 14.5131\n",
      "Epoch 268/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 985us/step - accuracy: 1.0000 - loss: 1.0364e-08 - val_accuracy: 0.0427 - val_loss: 14.5083\n",
      "Epoch 269/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963us/step - accuracy: 1.0000 - loss: 1.0213e-08 - val_accuracy: 0.0427 - val_loss: 14.5072\n",
      "Epoch 270/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 962us/step - accuracy: 1.0000 - loss: 1.0432e-08 - val_accuracy: 0.0427 - val_loss: 14.5028\n",
      "Epoch 271/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - accuracy: 1.0000 - loss: 1.0447e-08 - val_accuracy: 0.0427 - val_loss: 14.5090\n",
      "Epoch 272/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step - accuracy: 1.0000 - loss: 1.0251e-08 - val_accuracy: 0.0427 - val_loss: 14.5046\n",
      "Epoch 273/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - accuracy: 1.0000 - loss: 1.0186e-08 - val_accuracy: 0.0427 - val_loss: 14.5075\n",
      "Epoch 274/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 965us/step - accuracy: 1.0000 - loss: 1.0186e-08 - val_accuracy: 0.0427 - val_loss: 14.5046\n",
      "Epoch 275/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 940us/step - accuracy: 1.0000 - loss: 1.0160e-08 - val_accuracy: 0.0427 - val_loss: 14.5061\n",
      "Epoch 276/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 995us/step - accuracy: 1.0000 - loss: 1.0375e-08 - val_accuracy: 0.0427 - val_loss: 14.4984\n",
      "Epoch 277/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 980us/step - accuracy: 1.0000 - loss: 1.0468e-08 - val_accuracy: 0.0427 - val_loss: 14.4994\n",
      "Epoch 278/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905us/step - accuracy: 1.0000 - loss: 1.0547e-08 - val_accuracy: 0.0430 - val_loss: 14.5048\n",
      "Epoch 279/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963us/step - accuracy: 1.0000 - loss: 1.0305e-08 - val_accuracy: 0.0430 - val_loss: 14.5038\n",
      "Epoch 280/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 993us/step - accuracy: 1.0000 - loss: 1.0076e-08 - val_accuracy: 0.0430 - val_loss: 14.5015\n",
      "Epoch 281/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 975us/step - accuracy: 1.0000 - loss: 1.0279e-08 - val_accuracy: 0.0433 - val_loss: 14.4920\n",
      "Epoch 282/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 942us/step - accuracy: 1.0000 - loss: 1.0773e-08 - val_accuracy: 0.0433 - val_loss: 14.4915\n",
      "Epoch 283/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 948us/step - accuracy: 1.0000 - loss: 1.0657e-08 - val_accuracy: 0.0433 - val_loss: 14.4935\n",
      "Epoch 284/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 998us/step - accuracy: 1.0000 - loss: 1.0428e-08 - val_accuracy: 0.0433 - val_loss: 14.4920\n",
      "Epoch 285/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 960us/step - accuracy: 1.0000 - loss: 1.0599e-08 - val_accuracy: 0.0433 - val_loss: 14.4959\n",
      "Epoch 286/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 969us/step - accuracy: 1.0000 - loss: 1.0370e-08 - val_accuracy: 0.0433 - val_loss: 14.4919\n",
      "Epoch 287/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 923us/step - accuracy: 1.0000 - loss: 1.0575e-08 - val_accuracy: 0.0433 - val_loss: 14.4865\n",
      "Epoch 288/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 943us/step - accuracy: 1.0000 - loss: 1.0788e-08 - val_accuracy: 0.0433 - val_loss: 14.4872\n",
      "Epoch 289/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911us/step - accuracy: 1.0000 - loss: 1.0885e-08 - val_accuracy: 0.0433 - val_loss: 14.4819\n",
      "Epoch 290/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 951us/step - accuracy: 1.0000 - loss: 1.0601e-08 - val_accuracy: 0.0430 - val_loss: 14.4839\n",
      "Epoch 291/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 981us/step - accuracy: 1.0000 - loss: 1.0624e-08 - val_accuracy: 0.0430 - val_loss: 14.4851\n",
      "Epoch 292/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 985us/step - accuracy: 1.0000 - loss: 1.0637e-08 - val_accuracy: 0.0430 - val_loss: 14.4734\n",
      "Epoch 293/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 941us/step - accuracy: 1.0000 - loss: 1.1132e-08 - val_accuracy: 0.0430 - val_loss: 14.4747\n",
      "Epoch 294/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911us/step - accuracy: 1.0000 - loss: 1.0953e-08 - val_accuracy: 0.0430 - val_loss: 14.4712\n",
      "Epoch 295/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 984us/step - accuracy: 1.0000 - loss: 1.0825e-08 - val_accuracy: 0.0430 - val_loss: 14.4734\n",
      "Epoch 296/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - accuracy: 1.0000 - loss: 1.0898e-08 - val_accuracy: 0.0430 - val_loss: 14.4760\n",
      "Epoch 297/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 982us/step - accuracy: 1.0000 - loss: 1.0899e-08 - val_accuracy: 0.0433 - val_loss: 14.4737\n",
      "Epoch 298/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 901us/step - accuracy: 1.0000 - loss: 1.0801e-08 - val_accuracy: 0.0430 - val_loss: 14.4675\n",
      "Epoch 299/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 1.0985e-08 - val_accuracy: 0.0433 - val_loss: 14.4717\n",
      "Epoch 300/300\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 961us/step - accuracy: 1.0000 - loss: 1.0946e-08 - val_accuracy: 0.0437 - val_loss: 14.4670\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "prueba_3: \n",
      "Epoch 1/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2306 - loss: 2.5959 - val_accuracy: 0.0000e+00 - val_loss: 6.2950\n",
      "Epoch 2/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 936us/step - accuracy: 0.7966 - loss: 1.3946 - val_accuracy: 0.0000e+00 - val_loss: 7.2785\n",
      "Epoch 3/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911us/step - accuracy: 0.8996 - loss: 0.6854 - val_accuracy: 0.0000e+00 - val_loss: 7.9306\n",
      "Epoch 4/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 922us/step - accuracy: 0.9366 - loss: 0.4128 - val_accuracy: 0.0000e+00 - val_loss: 8.3675\n",
      "Epoch 5/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 925us/step - accuracy: 0.9560 - loss: 0.2784 - val_accuracy: 0.0000e+00 - val_loss: 8.7037\n",
      "Epoch 6/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 988us/step - accuracy: 0.9697 - loss: 0.1972 - val_accuracy: 0.0022 - val_loss: 8.9954\n",
      "Epoch 7/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 985us/step - accuracy: 0.9778 - loss: 0.1426 - val_accuracy: 0.0051 - val_loss: 9.2798\n",
      "Epoch 8/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 949us/step - accuracy: 0.9871 - loss: 0.1043 - val_accuracy: 0.0108 - val_loss: 9.5707\n",
      "Epoch 9/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 953us/step - accuracy: 0.9943 - loss: 0.0769 - val_accuracy: 0.0127 - val_loss: 9.8632\n",
      "Epoch 10/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 939us/step - accuracy: 0.9961 - loss: 0.0571 - val_accuracy: 0.0140 - val_loss: 10.1495\n",
      "Epoch 11/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934us/step - accuracy: 0.9989 - loss: 0.0427 - val_accuracy: 0.0169 - val_loss: 10.4290\n",
      "Epoch 12/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 0.9991 - loss: 0.0320 - val_accuracy: 0.0175 - val_loss: 10.7035\n",
      "Epoch 13/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 968us/step - accuracy: 0.9998 - loss: 0.0239 - val_accuracy: 0.0188 - val_loss: 10.9746\n",
      "Epoch 14/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0178 - val_accuracy: 0.0207 - val_loss: 11.2438\n",
      "Epoch 15/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 927us/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 0.0214 - val_loss: 11.5115\n",
      "Epoch 16/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 924us/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 0.0217 - val_loss: 11.7780\n",
      "Epoch 17/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.0220 - val_loss: 12.0432\n",
      "Epoch 18/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 938us/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.0223 - val_loss: 12.3067\n",
      "Epoch 19/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 966us/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.0226 - val_loss: 12.5682\n",
      "Epoch 20/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.0223 - val_loss: 12.8273\n",
      "Epoch 21/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.0233 - val_loss: 13.0840\n",
      "Epoch 22/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 971us/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.0239 - val_loss: 13.3379\n",
      "Epoch 23/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.0249 - val_loss: 13.5887\n",
      "Epoch 24/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933us/step - accuracy: 1.0000 - loss: 9.3613e-04 - val_accuracy: 0.0264 - val_loss: 13.8359\n",
      "Epoch 25/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 900us/step - accuracy: 1.0000 - loss: 6.9267e-04 - val_accuracy: 0.0280 - val_loss: 14.0787\n",
      "Epoch 26/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934us/step - accuracy: 1.0000 - loss: 5.1193e-04 - val_accuracy: 0.0290 - val_loss: 14.3162\n",
      "Epoch 27/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 949us/step - accuracy: 1.0000 - loss: 3.7791e-04 - val_accuracy: 0.0293 - val_loss: 14.5471\n",
      "Epoch 28/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 890us/step - accuracy: 1.0000 - loss: 2.7868e-04 - val_accuracy: 0.0296 - val_loss: 14.7704\n",
      "Epoch 29/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 967us/step - accuracy: 1.0000 - loss: 2.0530e-04 - val_accuracy: 0.0303 - val_loss: 14.9849\n",
      "Epoch 30/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 923us/step - accuracy: 1.0000 - loss: 1.5110e-04 - val_accuracy: 0.0306 - val_loss: 15.1898\n",
      "Epoch 31/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 962us/step - accuracy: 1.0000 - loss: 1.1112e-04 - val_accuracy: 0.0312 - val_loss: 15.3845\n",
      "Epoch 32/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 1.0000 - loss: 8.1662e-05 - val_accuracy: 0.0325 - val_loss: 15.5688\n",
      "Epoch 33/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 1.0000 - loss: 5.9975e-05 - val_accuracy: 0.0335 - val_loss: 15.7431\n",
      "Epoch 34/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 966us/step - accuracy: 1.0000 - loss: 4.4025e-05 - val_accuracy: 0.0335 - val_loss: 15.9078\n",
      "Epoch 35/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 943us/step - accuracy: 1.0000 - loss: 3.2306e-05 - val_accuracy: 0.0344 - val_loss: 16.0637\n",
      "Epoch 36/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 952us/step - accuracy: 1.0000 - loss: 2.3700e-05 - val_accuracy: 0.0351 - val_loss: 16.2118\n",
      "Epoch 37/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 949us/step - accuracy: 1.0000 - loss: 1.7387e-05 - val_accuracy: 0.0351 - val_loss: 16.3530\n",
      "Epoch 38/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899us/step - accuracy: 1.0000 - loss: 1.2759e-05 - val_accuracy: 0.0351 - val_loss: 16.4882\n",
      "Epoch 39/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 949us/step - accuracy: 1.0000 - loss: 9.3713e-06 - val_accuracy: 0.0360 - val_loss: 16.6182\n",
      "Epoch 40/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 940us/step - accuracy: 1.0000 - loss: 6.8892e-06 - val_accuracy: 0.0360 - val_loss: 16.7437\n",
      "Epoch 41/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893us/step - accuracy: 1.0000 - loss: 5.0734e-06 - val_accuracy: 0.0363 - val_loss: 16.8655\n",
      "Epoch 42/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 953us/step - accuracy: 1.0000 - loss: 3.7431e-06 - val_accuracy: 0.0363 - val_loss: 16.9833\n",
      "Epoch 43/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 941us/step - accuracy: 1.0000 - loss: 2.7734e-06 - val_accuracy: 0.0370 - val_loss: 17.0978\n",
      "Epoch 44/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 972us/step - accuracy: 1.0000 - loss: 2.0645e-06 - val_accuracy: 0.0376 - val_loss: 17.2096\n",
      "Epoch 45/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 943us/step - accuracy: 1.0000 - loss: 1.5444e-06 - val_accuracy: 0.0379 - val_loss: 17.3174\n",
      "Epoch 46/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 941us/step - accuracy: 1.0000 - loss: 1.1647e-06 - val_accuracy: 0.0379 - val_loss: 17.4216\n",
      "Epoch 47/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 949us/step - accuracy: 1.0000 - loss: 8.8490e-07 - val_accuracy: 0.0382 - val_loss: 17.5205\n",
      "Epoch 48/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 909us/step - accuracy: 1.0000 - loss: 6.8101e-07 - val_accuracy: 0.0382 - val_loss: 17.6135\n",
      "Epoch 49/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 970us/step - accuracy: 1.0000 - loss: 5.2958e-07 - val_accuracy: 0.0386 - val_loss: 17.7002\n",
      "Epoch 50/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 977us/step - accuracy: 1.0000 - loss: 4.1664e-07 - val_accuracy: 0.0392 - val_loss: 17.7803\n",
      "Epoch 51/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 953us/step - accuracy: 1.0000 - loss: 3.3244e-07 - val_accuracy: 0.0392 - val_loss: 17.8510\n",
      "Epoch 52/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.7036e-07 - val_accuracy: 0.0395 - val_loss: 17.9139\n",
      "Epoch 53/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 985us/step - accuracy: 1.0000 - loss: 2.2218e-07 - val_accuracy: 0.0398 - val_loss: 17.9621\n",
      "Epoch 54/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - accuracy: 1.0000 - loss: 1.8581e-07 - val_accuracy: 0.0405 - val_loss: 18.0076\n",
      "Epoch 55/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step - accuracy: 1.0000 - loss: 1.5811e-07 - val_accuracy: 0.0405 - val_loss: 18.0402\n",
      "Epoch 56/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 976us/step - accuracy: 1.0000 - loss: 1.3595e-07 - val_accuracy: 0.0405 - val_loss: 18.0659\n",
      "Epoch 57/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 1.0000 - loss: 1.1733e-07 - val_accuracy: 0.0414 - val_loss: 18.0826\n",
      "Epoch 58/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 1.0000 - loss: 1.0290e-07 - val_accuracy: 0.0424 - val_loss: 18.0896\n",
      "Epoch 59/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959us/step - accuracy: 1.0000 - loss: 9.1217e-08 - val_accuracy: 0.0424 - val_loss: 18.0929\n",
      "Epoch 60/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 950us/step - accuracy: 1.0000 - loss: 8.2223e-08 - val_accuracy: 0.0427 - val_loss: 18.0899\n",
      "Epoch 61/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 989us/step - accuracy: 1.0000 - loss: 7.4812e-08 - val_accuracy: 0.0430 - val_loss: 18.0849\n",
      "Epoch 62/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 969us/step - accuracy: 1.0000 - loss: 6.8291e-08 - val_accuracy: 0.0433 - val_loss: 18.0753\n",
      "Epoch 63/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 910us/step - accuracy: 1.0000 - loss: 6.3112e-08 - val_accuracy: 0.0433 - val_loss: 18.0660\n",
      "Epoch 64/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 938us/step - accuracy: 1.0000 - loss: 5.8052e-08 - val_accuracy: 0.0440 - val_loss: 18.0515\n",
      "Epoch 65/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 952us/step - accuracy: 1.0000 - loss: 5.3510e-08 - val_accuracy: 0.0440 - val_loss: 18.0347\n",
      "Epoch 66/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 964us/step - accuracy: 1.0000 - loss: 4.9772e-08 - val_accuracy: 0.0437 - val_loss: 18.0169\n",
      "Epoch 67/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 4.6354e-08 - val_accuracy: 0.0440 - val_loss: 17.9909\n",
      "Epoch 68/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 948us/step - accuracy: 1.0000 - loss: 4.3440e-08 - val_accuracy: 0.0443 - val_loss: 17.9627\n",
      "Epoch 69/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 948us/step - accuracy: 1.0000 - loss: 4.1025e-08 - val_accuracy: 0.0443 - val_loss: 17.9365\n",
      "Epoch 70/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 964us/step - accuracy: 1.0000 - loss: 3.8945e-08 - val_accuracy: 0.0446 - val_loss: 17.9085\n",
      "Epoch 71/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959us/step - accuracy: 1.0000 - loss: 3.6885e-08 - val_accuracy: 0.0446 - val_loss: 17.8766\n",
      "Epoch 72/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963us/step - accuracy: 1.0000 - loss: 3.4908e-08 - val_accuracy: 0.0453 - val_loss: 17.8433\n",
      "Epoch 73/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 946us/step - accuracy: 1.0000 - loss: 3.3161e-08 - val_accuracy: 0.0459 - val_loss: 17.8072\n",
      "Epoch 74/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 945us/step - accuracy: 1.0000 - loss: 3.1605e-08 - val_accuracy: 0.0462 - val_loss: 17.7717\n",
      "Epoch 75/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 943us/step - accuracy: 1.0000 - loss: 2.9885e-08 - val_accuracy: 0.0465 - val_loss: 17.7365\n",
      "Epoch 76/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 958us/step - accuracy: 1.0000 - loss: 2.8411e-08 - val_accuracy: 0.0465 - val_loss: 17.7000\n",
      "Epoch 77/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 937us/step - accuracy: 1.0000 - loss: 2.6897e-08 - val_accuracy: 0.0468 - val_loss: 17.6582\n",
      "Epoch 78/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step - accuracy: 1.0000 - loss: 2.6134e-08 - val_accuracy: 0.0468 - val_loss: 17.6197\n",
      "Epoch 79/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 971us/step - accuracy: 1.0000 - loss: 2.5127e-08 - val_accuracy: 0.0468 - val_loss: 17.5774\n",
      "Epoch 80/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 992us/step - accuracy: 1.0000 - loss: 2.3900e-08 - val_accuracy: 0.0468 - val_loss: 17.5324\n",
      "Epoch 81/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 924us/step - accuracy: 1.0000 - loss: 2.2762e-08 - val_accuracy: 0.0468 - val_loss: 17.4862\n",
      "Epoch 82/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 929us/step - accuracy: 1.0000 - loss: 2.1994e-08 - val_accuracy: 0.0472 - val_loss: 17.4417\n",
      "Epoch 83/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step - accuracy: 1.0000 - loss: 2.1052e-08 - val_accuracy: 0.0472 - val_loss: 17.3934\n",
      "Epoch 84/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 940us/step - accuracy: 1.0000 - loss: 2.0331e-08 - val_accuracy: 0.0472 - val_loss: 17.3440\n",
      "Epoch 85/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 925us/step - accuracy: 1.0000 - loss: 1.9928e-08 - val_accuracy: 0.0472 - val_loss: 17.2954\n",
      "Epoch 86/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899us/step - accuracy: 1.0000 - loss: 1.9056e-08 - val_accuracy: 0.0475 - val_loss: 17.2466\n",
      "Epoch 87/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 956us/step - accuracy: 1.0000 - loss: 1.8494e-08 - val_accuracy: 0.0475 - val_loss: 17.1919\n",
      "Epoch 88/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 926us/step - accuracy: 1.0000 - loss: 1.8539e-08 - val_accuracy: 0.0475 - val_loss: 17.1433\n",
      "Epoch 89/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.7543e-08 - val_accuracy: 0.0475 - val_loss: 17.0890\n",
      "Epoch 90/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 957us/step - accuracy: 1.0000 - loss: 1.7507e-08 - val_accuracy: 0.0478 - val_loss: 17.0397\n",
      "Epoch 91/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.7018e-08 - val_accuracy: 0.0481 - val_loss: 16.9882\n",
      "Epoch 92/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 974us/step - accuracy: 1.0000 - loss: 1.6591e-08 - val_accuracy: 0.0481 - val_loss: 16.9364\n",
      "Epoch 93/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.6360e-08 - val_accuracy: 0.0481 - val_loss: 16.8820\n",
      "Epoch 94/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 1.0000 - loss: 1.5864e-08 - val_accuracy: 0.0481 - val_loss: 16.8294\n",
      "Epoch 95/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 938us/step - accuracy: 1.0000 - loss: 1.5674e-08 - val_accuracy: 0.0484 - val_loss: 16.7774\n",
      "Epoch 96/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.5147e-08 - val_accuracy: 0.0484 - val_loss: 16.7249\n",
      "Epoch 97/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 978us/step - accuracy: 1.0000 - loss: 1.4896e-08 - val_accuracy: 0.0488 - val_loss: 16.6723\n",
      "Epoch 98/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 954us/step - accuracy: 1.0000 - loss: 1.4978e-08 - val_accuracy: 0.0488 - val_loss: 16.6208\n",
      "Epoch 99/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 992us/step - accuracy: 1.0000 - loss: 1.4337e-08 - val_accuracy: 0.0488 - val_loss: 16.5630\n",
      "Epoch 100/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 996us/step - accuracy: 1.0000 - loss: 1.4384e-08 - val_accuracy: 0.0488 - val_loss: 16.5108\n",
      "Epoch 101/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 932us/step - accuracy: 1.0000 - loss: 1.3734e-08 - val_accuracy: 0.0488 - val_loss: 16.4565\n",
      "Epoch 102/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933us/step - accuracy: 1.0000 - loss: 1.3813e-08 - val_accuracy: 0.0488 - val_loss: 16.4062\n",
      "Epoch 103/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 929us/step - accuracy: 1.0000 - loss: 1.3402e-08 - val_accuracy: 0.0488 - val_loss: 16.3492\n",
      "Epoch 104/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933us/step - accuracy: 1.0000 - loss: 1.3215e-08 - val_accuracy: 0.0488 - val_loss: 16.2986\n",
      "Epoch 105/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 922us/step - accuracy: 1.0000 - loss: 1.2874e-08 - val_accuracy: 0.0488 - val_loss: 16.2428\n",
      "Epoch 106/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 945us/step - accuracy: 1.0000 - loss: 1.3440e-08 - val_accuracy: 0.0488 - val_loss: 16.1871\n",
      "Epoch 107/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 998us/step - accuracy: 1.0000 - loss: 1.3192e-08 - val_accuracy: 0.0484 - val_loss: 16.1393\n",
      "Epoch 108/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934us/step - accuracy: 1.0000 - loss: 1.2707e-08 - val_accuracy: 0.0484 - val_loss: 16.0869\n",
      "Epoch 109/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.2526e-08 - val_accuracy: 0.0484 - val_loss: 16.0349\n",
      "Epoch 110/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 926us/step - accuracy: 1.0000 - loss: 1.2722e-08 - val_accuracy: 0.0484 - val_loss: 15.9831\n",
      "Epoch 111/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 999us/step - accuracy: 1.0000 - loss: 1.2270e-08 - val_accuracy: 0.0484 - val_loss: 15.9284\n",
      "Epoch 112/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 958us/step - accuracy: 1.0000 - loss: 1.2366e-08 - val_accuracy: 0.0484 - val_loss: 15.8797\n",
      "Epoch 113/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 988us/step - accuracy: 1.0000 - loss: 1.2322e-08 - val_accuracy: 0.0484 - val_loss: 15.8306\n",
      "Epoch 114/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 981us/step - accuracy: 1.0000 - loss: 1.1959e-08 - val_accuracy: 0.0484 - val_loss: 15.7766\n",
      "Epoch 115/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.1978e-08 - val_accuracy: 0.0484 - val_loss: 15.7261\n",
      "Epoch 116/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 976us/step - accuracy: 1.0000 - loss: 1.1759e-08 - val_accuracy: 0.0488 - val_loss: 15.6767\n",
      "Epoch 117/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 1.0000 - loss: 1.1440e-08 - val_accuracy: 0.0488 - val_loss: 15.6245\n",
      "Epoch 118/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 980us/step - accuracy: 1.0000 - loss: 1.1767e-08 - val_accuracy: 0.0488 - val_loss: 15.5781\n",
      "Epoch 119/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 971us/step - accuracy: 1.0000 - loss: 1.1398e-08 - val_accuracy: 0.0488 - val_loss: 15.5322\n",
      "Epoch 120/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 930us/step - accuracy: 1.0000 - loss: 1.1706e-08 - val_accuracy: 0.0488 - val_loss: 15.4835\n",
      "Epoch 121/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 949us/step - accuracy: 1.0000 - loss: 1.1354e-08 - val_accuracy: 0.0488 - val_loss: 15.4391\n",
      "Epoch 122/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 969us/step - accuracy: 1.0000 - loss: 1.1565e-08 - val_accuracy: 0.0491 - val_loss: 15.3937\n",
      "Epoch 123/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 923us/step - accuracy: 1.0000 - loss: 1.1469e-08 - val_accuracy: 0.0488 - val_loss: 15.3536\n",
      "Epoch 124/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.1393e-08 - val_accuracy: 0.0491 - val_loss: 15.3109\n",
      "Epoch 125/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 953us/step - accuracy: 1.0000 - loss: 1.1073e-08 - val_accuracy: 0.0488 - val_loss: 15.2703\n",
      "Epoch 126/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 978us/step - accuracy: 1.0000 - loss: 1.1020e-08 - val_accuracy: 0.0488 - val_loss: 15.2268\n",
      "Epoch 127/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 942us/step - accuracy: 1.0000 - loss: 1.1317e-08 - val_accuracy: 0.0488 - val_loss: 15.1891\n",
      "Epoch 128/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step - accuracy: 1.0000 - loss: 1.0409e-08 - val_accuracy: 0.0488 - val_loss: 15.1452\n",
      "Epoch 129/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - accuracy: 1.0000 - loss: 1.1004e-08 - val_accuracy: 0.0488 - val_loss: 15.1076\n",
      "Epoch 130/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 965us/step - accuracy: 1.0000 - loss: 1.0616e-08 - val_accuracy: 0.0488 - val_loss: 15.0724\n",
      "Epoch 131/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.0819e-08 - val_accuracy: 0.0488 - val_loss: 15.0345\n",
      "Epoch 132/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 929us/step - accuracy: 1.0000 - loss: 1.0984e-08 - val_accuracy: 0.0488 - val_loss: 15.0021\n",
      "Epoch 133/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 939us/step - accuracy: 1.0000 - loss: 1.0460e-08 - val_accuracy: 0.0488 - val_loss: 14.9644\n",
      "Epoch 134/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 961us/step - accuracy: 1.0000 - loss: 1.0443e-08 - val_accuracy: 0.0488 - val_loss: 14.9290\n",
      "Epoch 135/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 968us/step - accuracy: 1.0000 - loss: 1.0751e-08 - val_accuracy: 0.0491 - val_loss: 14.8952\n",
      "Epoch 136/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 930us/step - accuracy: 1.0000 - loss: 1.0317e-08 - val_accuracy: 0.0491 - val_loss: 14.8628\n",
      "Epoch 137/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 938us/step - accuracy: 1.0000 - loss: 1.0307e-08 - val_accuracy: 0.0491 - val_loss: 14.8319\n",
      "Epoch 138/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 945us/step - accuracy: 1.0000 - loss: 1.0414e-08 - val_accuracy: 0.0491 - val_loss: 14.8016\n",
      "Epoch 139/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 945us/step - accuracy: 1.0000 - loss: 1.0142e-08 - val_accuracy: 0.0491 - val_loss: 14.7729\n",
      "Epoch 140/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 946us/step - accuracy: 1.0000 - loss: 1.0252e-08 - val_accuracy: 0.0491 - val_loss: 14.7405\n",
      "Epoch 141/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 971us/step - accuracy: 1.0000 - loss: 1.0502e-08 - val_accuracy: 0.0491 - val_loss: 14.7156\n",
      "Epoch 142/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 988us/step - accuracy: 1.0000 - loss: 1.0206e-08 - val_accuracy: 0.0494 - val_loss: 14.6829\n",
      "Epoch 143/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 982us/step - accuracy: 1.0000 - loss: 1.0398e-08 - val_accuracy: 0.0497 - val_loss: 14.6596\n",
      "Epoch 144/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - accuracy: 1.0000 - loss: 1.0128e-08 - val_accuracy: 0.0497 - val_loss: 14.6337\n",
      "Epoch 145/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 908us/step - accuracy: 1.0000 - loss: 1.0303e-08 - val_accuracy: 0.0497 - val_loss: 14.6083\n",
      "Epoch 146/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 990us/step - accuracy: 1.0000 - loss: 1.0340e-08 - val_accuracy: 0.0497 - val_loss: 14.5839\n",
      "Epoch 147/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 960us/step - accuracy: 1.0000 - loss: 1.0151e-08 - val_accuracy: 0.0497 - val_loss: 14.5671\n",
      "Epoch 148/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - accuracy: 1.0000 - loss: 1.0016e-08 - val_accuracy: 0.0497 - val_loss: 14.5412\n",
      "Epoch 149/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 922us/step - accuracy: 1.0000 - loss: 1.0255e-08 - val_accuracy: 0.0497 - val_loss: 14.5221\n",
      "Epoch 150/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 929us/step - accuracy: 1.0000 - loss: 1.0110e-08 - val_accuracy: 0.0500 - val_loss: 14.4993\n",
      "Epoch 151/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 897us/step - accuracy: 1.0000 - loss: 1.0224e-08 - val_accuracy: 0.0500 - val_loss: 14.4827\n",
      "Epoch 152/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 952us/step - accuracy: 1.0000 - loss: 1.0063e-08 - val_accuracy: 0.0497 - val_loss: 14.4624\n",
      "Epoch 153/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933us/step - accuracy: 1.0000 - loss: 1.0163e-08 - val_accuracy: 0.0500 - val_loss: 14.4431\n",
      "Epoch 154/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step - accuracy: 1.0000 - loss: 1.0247e-08 - val_accuracy: 0.0500 - val_loss: 14.4279\n",
      "Epoch 155/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905us/step - accuracy: 1.0000 - loss: 9.9708e-09 - val_accuracy: 0.0500 - val_loss: 14.4078\n",
      "Epoch 156/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 924us/step - accuracy: 1.0000 - loss: 9.8643e-09 - val_accuracy: 0.0504 - val_loss: 14.3903\n",
      "Epoch 157/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 902us/step - accuracy: 1.0000 - loss: 1.0105e-08 - val_accuracy: 0.0504 - val_loss: 14.3788\n",
      "Epoch 158/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - accuracy: 1.0000 - loss: 9.7691e-09 - val_accuracy: 0.0504 - val_loss: 14.3604\n",
      "Epoch 159/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step - accuracy: 1.0000 - loss: 1.0055e-08 - val_accuracy: 0.0504 - val_loss: 14.3455\n",
      "Epoch 160/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905us/step - accuracy: 1.0000 - loss: 1.0207e-08 - val_accuracy: 0.0504 - val_loss: 14.3321\n",
      "Epoch 161/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 1.0000 - loss: 1.0240e-08 - val_accuracy: 0.0504 - val_loss: 14.3154\n",
      "Epoch 162/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 1.0000e-08 - val_accuracy: 0.0504 - val_loss: 14.3067\n",
      "Epoch 163/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 1.0000 - loss: 9.8107e-09 - val_accuracy: 0.0504 - val_loss: 14.2941\n",
      "Epoch 164/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step - accuracy: 1.0000 - loss: 1.0247e-08 - val_accuracy: 0.0504 - val_loss: 14.2855\n",
      "Epoch 165/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 947us/step - accuracy: 1.0000 - loss: 9.5700e-09 - val_accuracy: 0.0504 - val_loss: 14.2668\n",
      "Epoch 166/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 956us/step - accuracy: 1.0000 - loss: 1.0265e-08 - val_accuracy: 0.0507 - val_loss: 14.2582\n",
      "Epoch 167/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step - accuracy: 1.0000 - loss: 9.8392e-09 - val_accuracy: 0.0500 - val_loss: 14.2467\n",
      "Epoch 168/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 941us/step - accuracy: 1.0000 - loss: 9.8692e-09 - val_accuracy: 0.0500 - val_loss: 14.2358\n",
      "Epoch 169/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 991us/step - accuracy: 1.0000 - loss: 1.0178e-08 - val_accuracy: 0.0504 - val_loss: 14.2268\n",
      "Epoch 170/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.7549e-09 - val_accuracy: 0.0504 - val_loss: 14.2194\n",
      "Epoch 171/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 907us/step - accuracy: 1.0000 - loss: 9.7239e-09 - val_accuracy: 0.0510 - val_loss: 14.2089\n",
      "Epoch 172/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 988us/step - accuracy: 1.0000 - loss: 9.9584e-09 - val_accuracy: 0.0507 - val_loss: 14.2004\n",
      "Epoch 173/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 985us/step - accuracy: 1.0000 - loss: 9.9221e-09 - val_accuracy: 0.0513 - val_loss: 14.1917\n",
      "Epoch 174/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 962us/step - accuracy: 1.0000 - loss: 9.9233e-09 - val_accuracy: 0.0510 - val_loss: 14.1859\n",
      "Epoch 175/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 938us/step - accuracy: 1.0000 - loss: 9.4730e-09 - val_accuracy: 0.0510 - val_loss: 14.1780\n",
      "Epoch 176/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.6123e-09 - val_accuracy: 0.0510 - val_loss: 14.1692\n",
      "Epoch 177/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 1.0000 - loss: 9.9312e-09 - val_accuracy: 0.0510 - val_loss: 14.1637\n",
      "Epoch 178/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 950us/step - accuracy: 1.0000 - loss: 1.0047e-08 - val_accuracy: 0.0513 - val_loss: 14.1570\n",
      "Epoch 179/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step - accuracy: 1.0000 - loss: 9.8057e-09 - val_accuracy: 0.0516 - val_loss: 14.1525\n",
      "Epoch 180/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 969us/step - accuracy: 1.0000 - loss: 9.6307e-09 - val_accuracy: 0.0513 - val_loss: 14.1430\n",
      "Epoch 181/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 966us/step - accuracy: 1.0000 - loss: 9.8313e-09 - val_accuracy: 0.0516 - val_loss: 14.1387\n",
      "Epoch 182/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 923us/step - accuracy: 1.0000 - loss: 9.8366e-09 - val_accuracy: 0.0510 - val_loss: 14.1349\n",
      "Epoch 183/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 946us/step - accuracy: 1.0000 - loss: 9.3115e-09 - val_accuracy: 0.0510 - val_loss: 14.1299\n",
      "Epoch 184/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933us/step - accuracy: 1.0000 - loss: 9.5197e-09 - val_accuracy: 0.0510 - val_loss: 14.1205\n",
      "Epoch 185/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - accuracy: 1.0000 - loss: 9.7710e-09 - val_accuracy: 0.0507 - val_loss: 14.1166\n",
      "Epoch 186/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 940us/step - accuracy: 1.0000 - loss: 9.7419e-09 - val_accuracy: 0.0507 - val_loss: 14.1118\n",
      "Epoch 187/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 924us/step - accuracy: 1.0000 - loss: 9.8856e-09 - val_accuracy: 0.0510 - val_loss: 14.1052\n",
      "Epoch 188/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 908us/step - accuracy: 1.0000 - loss: 9.6530e-09 - val_accuracy: 0.0510 - val_loss: 14.1030\n",
      "Epoch 189/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 943us/step - accuracy: 1.0000 - loss: 9.5130e-09 - val_accuracy: 0.0507 - val_loss: 14.0991\n",
      "Epoch 190/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 9.8198e-09 - val_accuracy: 0.0510 - val_loss: 14.0956\n",
      "Epoch 191/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 1.0000 - loss: 9.4486e-09 - val_accuracy: 0.0507 - val_loss: 14.0895\n",
      "Epoch 192/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - accuracy: 1.0000 - loss: 9.7459e-09 - val_accuracy: 0.0507 - val_loss: 14.0865\n",
      "Epoch 193/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 1.0000 - loss: 9.6902e-09 - val_accuracy: 0.0507 - val_loss: 14.0826\n",
      "Epoch 194/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905us/step - accuracy: 1.0000 - loss: 9.7975e-09 - val_accuracy: 0.0507 - val_loss: 14.0829\n",
      "Epoch 195/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 965us/step - accuracy: 1.0000 - loss: 9.4686e-09 - val_accuracy: 0.0507 - val_loss: 14.0787\n",
      "Epoch 196/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.4703e-09 - val_accuracy: 0.0507 - val_loss: 14.0750\n",
      "Epoch 197/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step - accuracy: 1.0000 - loss: 9.7452e-09 - val_accuracy: 0.0507 - val_loss: 14.0696\n",
      "Epoch 198/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 972us/step - accuracy: 1.0000 - loss: 9.7461e-09 - val_accuracy: 0.0507 - val_loss: 14.0662\n",
      "Epoch 199/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933us/step - accuracy: 1.0000 - loss: 9.7197e-09 - val_accuracy: 0.0507 - val_loss: 14.0640\n",
      "Epoch 200/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 1.0000 - loss: 9.7900e-09 - val_accuracy: 0.0507 - val_loss: 14.0586\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "prueba_4: \n",
      "Epoch 1/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2250 - loss: 2.5247 - val_accuracy: 0.0000e+00 - val_loss: 6.6196\n",
      "Epoch 2/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 0.7361 - loss: 1.4652 - val_accuracy: 0.0000e+00 - val_loss: 7.6745\n",
      "Epoch 3/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 0.8562 - loss: 0.7947 - val_accuracy: 0.0000e+00 - val_loss: 8.2966\n",
      "Epoch 4/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 989us/step - accuracy: 0.9020 - loss: 0.5065 - val_accuracy: 0.0000e+00 - val_loss: 8.7385\n",
      "Epoch 5/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 958us/step - accuracy: 0.9329 - loss: 0.3547 - val_accuracy: 3.1867e-04 - val_loss: 9.1016\n",
      "Epoch 6/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 909us/step - accuracy: 0.9494 - loss: 0.2596 - val_accuracy: 0.0096 - val_loss: 9.4342\n",
      "Epoch 7/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 977us/step - accuracy: 0.9683 - loss: 0.1951 - val_accuracy: 0.0143 - val_loss: 9.7541\n",
      "Epoch 8/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959us/step - accuracy: 0.9795 - loss: 0.1491 - val_accuracy: 0.0185 - val_loss: 10.0655\n",
      "Epoch 9/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - accuracy: 0.9863 - loss: 0.1150 - val_accuracy: 0.0226 - val_loss: 10.3682\n",
      "Epoch 10/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 969us/step - accuracy: 0.9918 - loss: 0.0892 - val_accuracy: 0.0242 - val_loss: 10.6636\n",
      "Epoch 11/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 955us/step - accuracy: 0.9952 - loss: 0.0692 - val_accuracy: 0.0268 - val_loss: 10.9547\n",
      "Epoch 12/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 940us/step - accuracy: 0.9967 - loss: 0.0537 - val_accuracy: 0.0293 - val_loss: 11.2434\n",
      "Epoch 13/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 950us/step - accuracy: 0.9972 - loss: 0.0414 - val_accuracy: 0.0312 - val_loss: 11.5298\n",
      "Epoch 14/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9980 - loss: 0.0318 - val_accuracy: 0.0328 - val_loss: 11.8115\n",
      "Epoch 15/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 952us/step - accuracy: 0.9992 - loss: 0.0243 - val_accuracy: 0.0335 - val_loss: 12.0878\n",
      "Epoch 16/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 974us/step - accuracy: 0.9997 - loss: 0.0185 - val_accuracy: 0.0347 - val_loss: 12.3582\n",
      "Epoch 17/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 0.9997 - loss: 0.0140 - val_accuracy: 0.0351 - val_loss: 12.6232\n",
      "Epoch 18/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 937us/step - accuracy: 1.0000 - loss: 0.0106 - val_accuracy: 0.0354 - val_loss: 12.8833\n",
      "Epoch 19/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 986us/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.0366 - val_loss: 13.1395\n",
      "Epoch 20/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 979us/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.0366 - val_loss: 13.3922\n",
      "Epoch 21/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 901us/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.0370 - val_loss: 13.6414\n",
      "Epoch 22/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 949us/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.0373 - val_loss: 13.8869\n",
      "Epoch 23/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963us/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.0373 - val_loss: 14.1285\n",
      "Epoch 24/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 920us/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.0370 - val_loss: 14.3656\n",
      "Epoch 25/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 955us/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.0376 - val_loss: 14.5973\n",
      "Epoch 26/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 978us/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.0386 - val_loss: 14.8226\n",
      "Epoch 27/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934us/step - accuracy: 1.0000 - loss: 8.0344e-04 - val_accuracy: 0.0392 - val_loss: 15.0403\n",
      "Epoch 28/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 942us/step - accuracy: 1.0000 - loss: 5.9842e-04 - val_accuracy: 0.0392 - val_loss: 15.2492\n",
      "Epoch 29/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 1.0000 - loss: 4.4508e-04 - val_accuracy: 0.0395 - val_loss: 15.4483\n",
      "Epoch 30/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - accuracy: 1.0000 - loss: 3.3058e-04 - val_accuracy: 0.0398 - val_loss: 15.6368\n",
      "Epoch 31/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - accuracy: 1.0000 - loss: 2.4522e-04 - val_accuracy: 0.0398 - val_loss: 15.8145\n",
      "Epoch 32/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 901us/step - accuracy: 1.0000 - loss: 1.8168e-04 - val_accuracy: 0.0402 - val_loss: 15.9817\n",
      "Epoch 33/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899us/step - accuracy: 1.0000 - loss: 1.3445e-04 - val_accuracy: 0.0398 - val_loss: 16.1389\n",
      "Epoch 34/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934us/step - accuracy: 1.0000 - loss: 9.9400e-05 - val_accuracy: 0.0398 - val_loss: 16.2870\n",
      "Epoch 35/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 935us/step - accuracy: 1.0000 - loss: 7.3419e-05 - val_accuracy: 0.0398 - val_loss: 16.4271\n",
      "Epoch 36/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 966us/step - accuracy: 1.0000 - loss: 5.4195e-05 - val_accuracy: 0.0398 - val_loss: 16.5604\n",
      "Epoch 37/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 943us/step - accuracy: 1.0000 - loss: 3.9980e-05 - val_accuracy: 0.0398 - val_loss: 16.6879\n",
      "Epoch 38/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 1.0000 - loss: 2.9480e-05 - val_accuracy: 0.0398 - val_loss: 16.8105\n",
      "Epoch 39/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 930us/step - accuracy: 1.0000 - loss: 2.1737e-05 - val_accuracy: 0.0398 - val_loss: 16.9290\n",
      "Epoch 40/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 907us/step - accuracy: 1.0000 - loss: 1.6031e-05 - val_accuracy: 0.0402 - val_loss: 17.0442\n",
      "Epoch 41/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 897us/step - accuracy: 1.0000 - loss: 1.1827e-05 - val_accuracy: 0.0398 - val_loss: 17.1566\n",
      "Epoch 42/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 917us/step - accuracy: 1.0000 - loss: 8.7332e-06 - val_accuracy: 0.0398 - val_loss: 17.2666\n",
      "Epoch 43/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 923us/step - accuracy: 1.0000 - loss: 6.4592e-06 - val_accuracy: 0.0398 - val_loss: 17.3743\n",
      "Epoch 44/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895us/step - accuracy: 1.0000 - loss: 4.7845e-06 - val_accuracy: 0.0398 - val_loss: 17.4800\n",
      "Epoch 45/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 1.0000 - loss: 3.5548e-06 - val_accuracy: 0.0402 - val_loss: 17.5841\n",
      "Epoch 46/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 937us/step - accuracy: 1.0000 - loss: 2.6506e-06 - val_accuracy: 0.0405 - val_loss: 17.6861\n",
      "Epoch 47/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step - accuracy: 1.0000 - loss: 1.9875e-06 - val_accuracy: 0.0405 - val_loss: 17.7863\n",
      "Epoch 48/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 943us/step - accuracy: 1.0000 - loss: 1.4982e-06 - val_accuracy: 0.0408 - val_loss: 17.8841\n",
      "Epoch 49/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 1.0000 - loss: 1.1383e-06 - val_accuracy: 0.0408 - val_loss: 17.9796\n",
      "Epoch 50/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 943us/step - accuracy: 1.0000 - loss: 8.7300e-07 - val_accuracy: 0.0408 - val_loss: 18.0718\n",
      "Epoch 51/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 972us/step - accuracy: 1.0000 - loss: 6.7613e-07 - val_accuracy: 0.0408 - val_loss: 18.1586\n",
      "Epoch 52/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 949us/step - accuracy: 1.0000 - loss: 5.3129e-07 - val_accuracy: 0.0408 - val_loss: 18.2421\n",
      "Epoch 53/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 927us/step - accuracy: 1.0000 - loss: 4.2389e-07 - val_accuracy: 0.0408 - val_loss: 18.3200\n",
      "Epoch 54/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 908us/step - accuracy: 1.0000 - loss: 3.4176e-07 - val_accuracy: 0.0408 - val_loss: 18.3894\n",
      "Epoch 55/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963us/step - accuracy: 1.0000 - loss: 2.8056e-07 - val_accuracy: 0.0411 - val_loss: 18.4523\n",
      "Epoch 56/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 1.0000 - loss: 2.3156e-07 - val_accuracy: 0.0408 - val_loss: 18.5065\n",
      "Epoch 57/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step - accuracy: 1.0000 - loss: 1.9565e-07 - val_accuracy: 0.0408 - val_loss: 18.5518\n",
      "Epoch 58/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 967us/step - accuracy: 1.0000 - loss: 1.6696e-07 - val_accuracy: 0.0408 - val_loss: 18.5883\n",
      "Epoch 59/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - accuracy: 1.0000 - loss: 1.4455e-07 - val_accuracy: 0.0408 - val_loss: 18.6181\n",
      "Epoch 60/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 884us/step - accuracy: 1.0000 - loss: 1.2663e-07 - val_accuracy: 0.0408 - val_loss: 18.6396\n",
      "Epoch 61/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 1.0000 - loss: 1.1274e-07 - val_accuracy: 0.0408 - val_loss: 18.6581\n",
      "Epoch 62/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963us/step - accuracy: 1.0000 - loss: 1.0049e-07 - val_accuracy: 0.0408 - val_loss: 18.6677\n",
      "Epoch 63/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 902us/step - accuracy: 1.0000 - loss: 9.0433e-08 - val_accuracy: 0.0408 - val_loss: 18.6656\n",
      "Epoch 64/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 976us/step - accuracy: 1.0000 - loss: 8.2090e-08 - val_accuracy: 0.0408 - val_loss: 18.6591\n",
      "Epoch 65/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 966us/step - accuracy: 1.0000 - loss: 7.4564e-08 - val_accuracy: 0.0408 - val_loss: 18.6483\n",
      "Epoch 66/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 935us/step - accuracy: 1.0000 - loss: 6.8604e-08 - val_accuracy: 0.0405 - val_loss: 18.6354\n",
      "Epoch 67/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - accuracy: 1.0000 - loss: 6.3753e-08 - val_accuracy: 0.0405 - val_loss: 18.6215\n",
      "Epoch 68/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 930us/step - accuracy: 1.0000 - loss: 5.9069e-08 - val_accuracy: 0.0405 - val_loss: 18.5999\n",
      "Epoch 69/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - accuracy: 1.0000 - loss: 5.4417e-08 - val_accuracy: 0.0402 - val_loss: 18.5766\n",
      "Epoch 70/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 5.1261e-08 - val_accuracy: 0.0402 - val_loss: 18.5494\n",
      "Epoch 71/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 945us/step - accuracy: 1.0000 - loss: 4.8523e-08 - val_accuracy: 0.0402 - val_loss: 18.5229\n",
      "Epoch 72/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 969us/step - accuracy: 1.0000 - loss: 4.5421e-08 - val_accuracy: 0.0402 - val_loss: 18.4905\n",
      "Epoch 73/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 953us/step - accuracy: 1.0000 - loss: 4.3042e-08 - val_accuracy: 0.0402 - val_loss: 18.4592\n",
      "Epoch 74/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 961us/step - accuracy: 1.0000 - loss: 4.0654e-08 - val_accuracy: 0.0402 - val_loss: 18.4241\n",
      "Epoch 75/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905us/step - accuracy: 1.0000 - loss: 3.8862e-08 - val_accuracy: 0.0405 - val_loss: 18.3883\n",
      "Epoch 76/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 974us/step - accuracy: 1.0000 - loss: 3.7019e-08 - val_accuracy: 0.0402 - val_loss: 18.3534\n",
      "Epoch 77/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 956us/step - accuracy: 1.0000 - loss: 3.5149e-08 - val_accuracy: 0.0402 - val_loss: 18.3146\n",
      "Epoch 78/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.4116e-08 - val_accuracy: 0.0402 - val_loss: 18.2762\n",
      "Epoch 79/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 926us/step - accuracy: 1.0000 - loss: 3.2425e-08 - val_accuracy: 0.0402 - val_loss: 18.2355\n",
      "Epoch 80/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 945us/step - accuracy: 1.0000 - loss: 3.1713e-08 - val_accuracy: 0.0402 - val_loss: 18.1952\n",
      "Epoch 81/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 929us/step - accuracy: 1.0000 - loss: 2.9956e-08 - val_accuracy: 0.0402 - val_loss: 18.1539\n",
      "Epoch 82/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - accuracy: 1.0000 - loss: 2.8902e-08 - val_accuracy: 0.0402 - val_loss: 18.1087\n",
      "Epoch 83/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 948us/step - accuracy: 1.0000 - loss: 2.8281e-08 - val_accuracy: 0.0402 - val_loss: 18.0648\n",
      "Epoch 84/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 940us/step - accuracy: 1.0000 - loss: 2.7135e-08 - val_accuracy: 0.0402 - val_loss: 18.0158\n",
      "Epoch 85/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 992us/step - accuracy: 1.0000 - loss: 2.6444e-08 - val_accuracy: 0.0402 - val_loss: 17.9660\n",
      "Epoch 86/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 1.0000 - loss: 2.5623e-08 - val_accuracy: 0.0405 - val_loss: 17.9191\n",
      "Epoch 87/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 974us/step - accuracy: 1.0000 - loss: 2.4645e-08 - val_accuracy: 0.0405 - val_loss: 17.8659\n",
      "Epoch 88/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 1.0000 - loss: 2.4316e-08 - val_accuracy: 0.0405 - val_loss: 17.8169\n",
      "Epoch 89/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 945us/step - accuracy: 1.0000 - loss: 2.3652e-08 - val_accuracy: 0.0405 - val_loss: 17.7672\n",
      "Epoch 90/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 922us/step - accuracy: 1.0000 - loss: 2.2197e-08 - val_accuracy: 0.0405 - val_loss: 17.7116\n",
      "Epoch 91/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911us/step - accuracy: 1.0000 - loss: 2.2095e-08 - val_accuracy: 0.0408 - val_loss: 17.6597\n",
      "Epoch 92/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 946us/step - accuracy: 1.0000 - loss: 2.1647e-08 - val_accuracy: 0.0408 - val_loss: 17.6094\n",
      "Epoch 93/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 940us/step - accuracy: 1.0000 - loss: 2.0664e-08 - val_accuracy: 0.0408 - val_loss: 17.5502\n",
      "Epoch 94/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933us/step - accuracy: 1.0000 - loss: 2.0723e-08 - val_accuracy: 0.0408 - val_loss: 17.4984\n",
      "Epoch 95/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 948us/step - accuracy: 1.0000 - loss: 2.0340e-08 - val_accuracy: 0.0408 - val_loss: 17.4415\n",
      "Epoch 96/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959us/step - accuracy: 1.0000 - loss: 1.9979e-08 - val_accuracy: 0.0408 - val_loss: 17.3866\n",
      "Epoch 97/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 994us/step - accuracy: 1.0000 - loss: 1.9089e-08 - val_accuracy: 0.0408 - val_loss: 17.3259\n",
      "Epoch 98/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step - accuracy: 1.0000 - loss: 1.9167e-08 - val_accuracy: 0.0408 - val_loss: 17.2693\n",
      "Epoch 99/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 939us/step - accuracy: 1.0000 - loss: 1.8716e-08 - val_accuracy: 0.0408 - val_loss: 17.2126\n",
      "Epoch 100/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 936us/step - accuracy: 1.0000 - loss: 1.8177e-08 - val_accuracy: 0.0408 - val_loss: 17.1569\n",
      "Epoch 101/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 902us/step - accuracy: 1.0000 - loss: 1.7720e-08 - val_accuracy: 0.0408 - val_loss: 17.0980\n",
      "Epoch 102/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step - accuracy: 1.0000 - loss: 1.7447e-08 - val_accuracy: 0.0408 - val_loss: 17.0372\n",
      "Epoch 103/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 955us/step - accuracy: 1.0000 - loss: 1.7446e-08 - val_accuracy: 0.0405 - val_loss: 16.9789\n",
      "Epoch 104/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 966us/step - accuracy: 1.0000 - loss: 1.6973e-08 - val_accuracy: 0.0408 - val_loss: 16.9202\n",
      "Epoch 105/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 984us/step - accuracy: 1.0000 - loss: 1.6512e-08 - val_accuracy: 0.0405 - val_loss: 16.8590\n",
      "Epoch 106/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.6672e-08 - val_accuracy: 0.0405 - val_loss: 16.7980\n",
      "Epoch 107/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.6476e-08 - val_accuracy: 0.0405 - val_loss: 16.7399\n",
      "Epoch 108/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 920us/step - accuracy: 1.0000 - loss: 1.6197e-08 - val_accuracy: 0.0402 - val_loss: 16.6791\n",
      "Epoch 109/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 986us/step - accuracy: 1.0000 - loss: 1.6011e-08 - val_accuracy: 0.0402 - val_loss: 16.6168\n",
      "Epoch 110/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 953us/step - accuracy: 1.0000 - loss: 1.6572e-08 - val_accuracy: 0.0402 - val_loss: 16.5611\n",
      "Epoch 111/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 1.0000 - loss: 1.5410e-08 - val_accuracy: 0.0402 - val_loss: 16.4984\n",
      "Epoch 112/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 960us/step - accuracy: 1.0000 - loss: 1.5612e-08 - val_accuracy: 0.0402 - val_loss: 16.4387\n",
      "Epoch 113/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 994us/step - accuracy: 1.0000 - loss: 1.5127e-08 - val_accuracy: 0.0398 - val_loss: 16.3809\n",
      "Epoch 114/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 950us/step - accuracy: 1.0000 - loss: 1.5242e-08 - val_accuracy: 0.0398 - val_loss: 16.3205\n",
      "Epoch 115/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.5418e-08 - val_accuracy: 0.0398 - val_loss: 16.2620\n",
      "Epoch 116/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 958us/step - accuracy: 1.0000 - loss: 1.4953e-08 - val_accuracy: 0.0398 - val_loss: 16.2048\n",
      "Epoch 117/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 949us/step - accuracy: 1.0000 - loss: 1.4550e-08 - val_accuracy: 0.0398 - val_loss: 16.1450\n",
      "Epoch 118/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 920us/step - accuracy: 1.0000 - loss: 1.5001e-08 - val_accuracy: 0.0398 - val_loss: 16.0889\n",
      "Epoch 119/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 943us/step - accuracy: 1.0000 - loss: 1.4472e-08 - val_accuracy: 0.0398 - val_loss: 16.0332\n",
      "Epoch 120/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 999us/step - accuracy: 1.0000 - loss: 1.4218e-08 - val_accuracy: 0.0398 - val_loss: 15.9750\n",
      "Epoch 121/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 980us/step - accuracy: 1.0000 - loss: 1.4425e-08 - val_accuracy: 0.0398 - val_loss: 15.9216\n",
      "Epoch 122/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 929us/step - accuracy: 1.0000 - loss: 1.4193e-08 - val_accuracy: 0.0395 - val_loss: 15.8640\n",
      "Epoch 123/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 922us/step - accuracy: 1.0000 - loss: 1.4414e-08 - val_accuracy: 0.0398 - val_loss: 15.8084\n",
      "Epoch 124/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 965us/step - accuracy: 1.0000 - loss: 1.4390e-08 - val_accuracy: 0.0402 - val_loss: 15.7546\n",
      "Epoch 125/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 930us/step - accuracy: 1.0000 - loss: 1.3991e-08 - val_accuracy: 0.0402 - val_loss: 15.6982\n",
      "Epoch 126/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 942us/step - accuracy: 1.0000 - loss: 1.4368e-08 - val_accuracy: 0.0398 - val_loss: 15.6471\n",
      "Epoch 127/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 948us/step - accuracy: 1.0000 - loss: 1.4342e-08 - val_accuracy: 0.0395 - val_loss: 15.5974\n",
      "Epoch 128/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 965us/step - accuracy: 1.0000 - loss: 1.4098e-08 - val_accuracy: 0.0398 - val_loss: 15.5488\n",
      "Epoch 129/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 973us/step - accuracy: 1.0000 - loss: 1.3885e-08 - val_accuracy: 0.0398 - val_loss: 15.4998\n",
      "Epoch 130/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 920us/step - accuracy: 1.0000 - loss: 1.4063e-08 - val_accuracy: 0.0395 - val_loss: 15.4498\n",
      "Epoch 131/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 969us/step - accuracy: 1.0000 - loss: 1.3615e-08 - val_accuracy: 0.0398 - val_loss: 15.4011\n",
      "Epoch 132/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911us/step - accuracy: 1.0000 - loss: 1.3869e-08 - val_accuracy: 0.0395 - val_loss: 15.3583\n",
      "Epoch 133/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934us/step - accuracy: 1.0000 - loss: 1.4156e-08 - val_accuracy: 0.0395 - val_loss: 15.3146\n",
      "Epoch 134/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 967us/step - accuracy: 1.0000 - loss: 1.3187e-08 - val_accuracy: 0.0395 - val_loss: 15.2664\n",
      "Epoch 135/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 945us/step - accuracy: 1.0000 - loss: 1.4310e-08 - val_accuracy: 0.0395 - val_loss: 15.2265\n",
      "Epoch 136/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 947us/step - accuracy: 1.0000 - loss: 1.3627e-08 - val_accuracy: 0.0395 - val_loss: 15.1850\n",
      "Epoch 137/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 935us/step - accuracy: 1.0000 - loss: 1.3973e-08 - val_accuracy: 0.0395 - val_loss: 15.1481\n",
      "Epoch 138/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 957us/step - accuracy: 1.0000 - loss: 1.3544e-08 - val_accuracy: 0.0395 - val_loss: 15.1056\n",
      "Epoch 139/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 925us/step - accuracy: 1.0000 - loss: 1.3757e-08 - val_accuracy: 0.0395 - val_loss: 15.0696\n",
      "Epoch 140/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 974us/step - accuracy: 1.0000 - loss: 1.3811e-08 - val_accuracy: 0.0395 - val_loss: 15.0322\n",
      "Epoch 141/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 900us/step - accuracy: 1.0000 - loss: 1.3625e-08 - val_accuracy: 0.0395 - val_loss: 15.0000\n",
      "Epoch 142/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 1.0000 - loss: 1.3755e-08 - val_accuracy: 0.0395 - val_loss: 14.9640\n",
      "Epoch 143/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 929us/step - accuracy: 1.0000 - loss: 1.3804e-08 - val_accuracy: 0.0392 - val_loss: 14.9351\n",
      "Epoch 144/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 938us/step - accuracy: 1.0000 - loss: 1.3615e-08 - val_accuracy: 0.0392 - val_loss: 14.9074\n",
      "Epoch 145/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.3393e-08 - val_accuracy: 0.0389 - val_loss: 14.8792\n",
      "Epoch 146/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - accuracy: 1.0000 - loss: 1.3348e-08 - val_accuracy: 0.0389 - val_loss: 14.8493\n",
      "Epoch 147/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 956us/step - accuracy: 1.0000 - loss: 1.3873e-08 - val_accuracy: 0.0389 - val_loss: 14.8249\n",
      "Epoch 148/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 972us/step - accuracy: 1.0000 - loss: 1.3279e-08 - val_accuracy: 0.0386 - val_loss: 14.7962\n",
      "Epoch 149/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963us/step - accuracy: 1.0000 - loss: 1.3753e-08 - val_accuracy: 0.0386 - val_loss: 14.7738\n",
      "Epoch 150/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 996us/step - accuracy: 1.0000 - loss: 1.3738e-08 - val_accuracy: 0.0386 - val_loss: 14.7524\n",
      "Epoch 151/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 953us/step - accuracy: 1.0000 - loss: 1.3244e-08 - val_accuracy: 0.0386 - val_loss: 14.7308\n",
      "Epoch 152/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step - accuracy: 1.0000 - loss: 1.3640e-08 - val_accuracy: 0.0386 - val_loss: 14.7113\n",
      "Epoch 153/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 952us/step - accuracy: 1.0000 - loss: 1.3280e-08 - val_accuracy: 0.0386 - val_loss: 14.6867\n",
      "Epoch 154/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 939us/step - accuracy: 1.0000 - loss: 1.3475e-08 - val_accuracy: 0.0386 - val_loss: 14.6728\n",
      "Epoch 155/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 948us/step - accuracy: 1.0000 - loss: 1.3323e-08 - val_accuracy: 0.0386 - val_loss: 14.6533\n",
      "Epoch 156/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 980us/step - accuracy: 1.0000 - loss: 1.3281e-08 - val_accuracy: 0.0386 - val_loss: 14.6328\n",
      "Epoch 157/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 938us/step - accuracy: 1.0000 - loss: 1.3817e-08 - val_accuracy: 0.0386 - val_loss: 14.6212\n",
      "Epoch 158/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 946us/step - accuracy: 1.0000 - loss: 1.3110e-08 - val_accuracy: 0.0386 - val_loss: 14.6062\n",
      "Epoch 159/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 994us/step - accuracy: 1.0000 - loss: 1.3273e-08 - val_accuracy: 0.0386 - val_loss: 14.5931\n",
      "Epoch 160/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 976us/step - accuracy: 1.0000 - loss: 1.3384e-08 - val_accuracy: 0.0386 - val_loss: 14.5768\n",
      "Epoch 161/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 940us/step - accuracy: 1.0000 - loss: 1.3246e-08 - val_accuracy: 0.0386 - val_loss: 14.5659\n",
      "Epoch 162/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933us/step - accuracy: 1.0000 - loss: 1.3401e-08 - val_accuracy: 0.0386 - val_loss: 14.5541\n",
      "Epoch 163/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 975us/step - accuracy: 1.0000 - loss: 1.3343e-08 - val_accuracy: 0.0386 - val_loss: 14.5437\n",
      "Epoch 164/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step - accuracy: 1.0000 - loss: 1.3154e-08 - val_accuracy: 0.0386 - val_loss: 14.5358\n",
      "Epoch 165/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 961us/step - accuracy: 1.0000 - loss: 1.2756e-08 - val_accuracy: 0.0386 - val_loss: 14.5210\n",
      "Epoch 166/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 996us/step - accuracy: 1.0000 - loss: 1.3216e-08 - val_accuracy: 0.0386 - val_loss: 14.5117\n",
      "Epoch 167/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 940us/step - accuracy: 1.0000 - loss: 1.3637e-08 - val_accuracy: 0.0386 - val_loss: 14.5032\n",
      "Epoch 168/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934us/step - accuracy: 1.0000 - loss: 1.3256e-08 - val_accuracy: 0.0386 - val_loss: 14.4937\n",
      "Epoch 169/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.3244e-08 - val_accuracy: 0.0386 - val_loss: 14.4916\n",
      "Epoch 170/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 927us/step - accuracy: 1.0000 - loss: 1.3015e-08 - val_accuracy: 0.0386 - val_loss: 14.4837\n",
      "Epoch 171/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 939us/step - accuracy: 1.0000 - loss: 1.2892e-08 - val_accuracy: 0.0386 - val_loss: 14.4776\n",
      "Epoch 172/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934us/step - accuracy: 1.0000 - loss: 1.2883e-08 - val_accuracy: 0.0386 - val_loss: 14.4686\n",
      "Epoch 173/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.3474e-08 - val_accuracy: 0.0386 - val_loss: 14.4639\n",
      "Epoch 174/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.3011e-08 - val_accuracy: 0.0386 - val_loss: 14.4563\n",
      "Epoch 175/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 947us/step - accuracy: 1.0000 - loss: 1.3440e-08 - val_accuracy: 0.0386 - val_loss: 14.4520\n",
      "Epoch 176/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 977us/step - accuracy: 1.0000 - loss: 1.2979e-08 - val_accuracy: 0.0382 - val_loss: 14.4454\n",
      "Epoch 177/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 987us/step - accuracy: 1.0000 - loss: 1.3489e-08 - val_accuracy: 0.0382 - val_loss: 14.4461\n",
      "Epoch 178/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - accuracy: 1.0000 - loss: 1.3162e-08 - val_accuracy: 0.0382 - val_loss: 14.4407\n",
      "Epoch 179/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 957us/step - accuracy: 1.0000 - loss: 1.3282e-08 - val_accuracy: 0.0382 - val_loss: 14.4385\n",
      "Epoch 180/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 935us/step - accuracy: 1.0000 - loss: 1.3122e-08 - val_accuracy: 0.0382 - val_loss: 14.4367\n",
      "Epoch 181/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step - accuracy: 1.0000 - loss: 1.2638e-08 - val_accuracy: 0.0382 - val_loss: 14.4319\n",
      "Epoch 182/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 970us/step - accuracy: 1.0000 - loss: 1.2631e-08 - val_accuracy: 0.0382 - val_loss: 14.4251\n",
      "Epoch 183/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 943us/step - accuracy: 1.0000 - loss: 1.3324e-08 - val_accuracy: 0.0382 - val_loss: 14.4237\n",
      "Epoch 184/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 975us/step - accuracy: 1.0000 - loss: 1.3134e-08 - val_accuracy: 0.0382 - val_loss: 14.4251\n",
      "Epoch 185/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.2807e-08 - val_accuracy: 0.0382 - val_loss: 14.4250\n",
      "Epoch 186/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 938us/step - accuracy: 1.0000 - loss: 1.2821e-08 - val_accuracy: 0.0382 - val_loss: 14.4214\n",
      "Epoch 187/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 957us/step - accuracy: 1.0000 - loss: 1.2712e-08 - val_accuracy: 0.0382 - val_loss: 14.4153\n",
      "Epoch 188/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 997us/step - accuracy: 1.0000 - loss: 1.2798e-08 - val_accuracy: 0.0382 - val_loss: 14.4117\n",
      "Epoch 189/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 997us/step - accuracy: 1.0000 - loss: 1.3244e-08 - val_accuracy: 0.0382 - val_loss: 14.4118\n",
      "Epoch 190/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 945us/step - accuracy: 1.0000 - loss: 1.2993e-08 - val_accuracy: 0.0379 - val_loss: 14.4112\n",
      "Epoch 191/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.2867e-08 - val_accuracy: 0.0379 - val_loss: 14.4117\n",
      "Epoch 192/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 923us/step - accuracy: 1.0000 - loss: 1.2710e-08 - val_accuracy: 0.0379 - val_loss: 14.4135\n",
      "Epoch 193/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 966us/step - accuracy: 1.0000 - loss: 1.2644e-08 - val_accuracy: 0.0382 - val_loss: 14.4106\n",
      "Epoch 194/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step - accuracy: 1.0000 - loss: 1.3013e-08 - val_accuracy: 0.0382 - val_loss: 14.4073\n",
      "Epoch 195/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 978us/step - accuracy: 1.0000 - loss: 1.3282e-08 - val_accuracy: 0.0382 - val_loss: 14.4128\n",
      "Epoch 196/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 990us/step - accuracy: 1.0000 - loss: 1.2493e-08 - val_accuracy: 0.0382 - val_loss: 14.4097\n",
      "Epoch 197/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step - accuracy: 1.0000 - loss: 1.3003e-08 - val_accuracy: 0.0382 - val_loss: 14.4049\n",
      "Epoch 198/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 973us/step - accuracy: 1.0000 - loss: 1.3133e-08 - val_accuracy: 0.0382 - val_loss: 14.4090\n",
      "Epoch 199/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 974us/step - accuracy: 1.0000 - loss: 1.2803e-08 - val_accuracy: 0.0379 - val_loss: 14.4042\n",
      "Epoch 200/200\n",
      "\u001b[1m733/733\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 991us/step - accuracy: 1.0000 - loss: 1.3138e-08 - val_accuracy: 0.0379 - val_loss: 14.4104\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prueba_1': 0.4666666666666667,\n",
       " 'prueba_2': 0.6,\n",
       " 'prueba_3': 0.7,\n",
       " 'prueba_4': 0.5333333333333333}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resutados = {}\n",
    "modelos = {}\n",
    "for prueba, params in pruebas.items():\n",
    "    print(f\"{prueba}: \")\n",
    "    resultado, modelo = run_keras_model(n_pca=params.get('n_pca'), \n",
    "                    excl_n_prim_comp=params.get('excl_n_prim_comp'), \n",
    "                    nueronas_layer_1=params.get('nueronas_layer_1'),\n",
    "                    nueronas_layer_2=params.get('nueronas_layer_2'),\n",
    "                    n_epochs=params.get('n_epochs'),\n",
    "                    imagenes=imagenes_all,\n",
    "                    nombres=nombres_all,\n",
    "                    nuevas_imagenes=new_images,\n",
    "                    nuevos_nombres=nombres_new\n",
    "                    )\n",
    "    resutados[prueba]=resultado\n",
    "    modelos[prueba]=modelo\n",
    "resutados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segundo testeo del modelo con nuevas imagenes del equipo \"Grupo 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 900)\n",
      "(6,)\n"
     ]
    }
   ],
   "source": [
    "data_dir = (\"02_probar_nuevas_fotos/fotos_prueba_recortadas\")\n",
    "nombres = []\n",
    "imagenes = []\n",
    "\n",
    "# Cargar imágenes y etiquetas\n",
    "dir = os.path.join(current_dir,data_dir)\n",
    "for archivo in os.listdir(dir):\n",
    "    if archivo.endswith('.jpeg') or archivo.endswith('.jpg'):\n",
    "        nombre = archivo.split('_')[0].replace(\".jpg\",\"\").replace(\".jpeg\",\"\")\n",
    "        nombre = re.sub(r\"\\d+\", \"\", nombre)\n",
    "        ruta_imagen = os.path.join(dir, archivo)\n",
    "        imagen = Image.open(ruta_imagen)\n",
    "        imagen = np.array(imagen.resize((dim_imagenes, dim_imagenes)))  # Redimensionar imágenes para un tamaño uniforme\n",
    "        if len(imagen.shape) == 3 and imagen.shape[2] == 3:\n",
    "            imagen = cv2.cvtColor(imagen, cv2.COLOR_RGB2GRAY)  # Convertir a escala de grises si es necesario\n",
    "        imagenes.append(imagen.flatten())\n",
    "        nombres.append(nombre)\n",
    "\n",
    "new_images = np.array(imagenes)\n",
    "nombres_new = np.array(nombres)\n",
    "\n",
    "# estand\n",
    "new_images = new_images/255.0\n",
    "print(new_images.shape)\n",
    "print(nombres_new.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nombres_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define funcion para las predicciones\n",
    "def get_preds_predict2(model, n_pca, excl_n_prim_comp, imagenes, nombres, nuevas_imagenes, nuevos_nombres):\n",
    "    \n",
    "    # Dividir en entrenamiento y prueba\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(imagenes, nombres, test_size=0.05, random_state=42, stratify=nombres)\n",
    "    X_train = imagenes#np.array(imagenes)\n",
    "    y_train = nombres#np.array(nombres)\n",
    "\n",
    "    # Aplicar PCA\n",
    "    pca = PCA(n_components=n_pca, random_state=12)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    #X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    # Escalar los datos \n",
    "    scaler = StandardScaler()\n",
    "    #scaler = MinMaxScaler()\n",
    "    X_train_pca_scaled = scaler.fit_transform(X_train_pca)\n",
    "    #X_test_pca_scaled = scaler.transform(X_test_pca)\n",
    "    \n",
    "    \n",
    "    # Codificar las etiquetas\n",
    "    encoder = LabelEncoder()\n",
    "    y_train_encoded = encoder.fit_transform(y_train)\n",
    "    #y_test_encoded = encoder.transform(y_test)\n",
    "    #y_train_categorical = to_categorical(y_train_encoded, num_classes=19)\n",
    "    #y_test_categorical = to_categorical(y_test_encoded, num_classes=18)\n",
    "    \n",
    "    \n",
    "    # Definir la red neuronal\n",
    "    #entreno_con = X_train_pca_scaled[:,excl_n_prim_comp:]\n",
    "    #testeo_con = X_test_pca_scaled[:,excl_n_prim_comp:]    \n",
    "    \n",
    "    # PREDICCIONES\n",
    "    # 2. Aplicar PCA\n",
    "    new_images_pca = pca.transform(nuevas_imagenes)\n",
    "    new_images_pca_scaled = scaler.transform(new_images_pca)\n",
    "    evaluo_con = new_images_pca_scaled[:,excl_n_prim_comp:]\n",
    "\n",
    "    # 3. Hacer predicciones\n",
    "    predictions = model.predict(evaluo_con)\n",
    "\n",
    "    # Obtener los nombres correspondientes a las clases predichas\n",
    "    predicted_names = encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
    "\n",
    "    # Imprimir las predicciones\n",
    "    total_predict = len(nuevos_nombres)\n",
    "    total_correcto = 0\n",
    "    for real, pred in zip(nuevos_nombres, predicted_names):\n",
    "        if real == pred:\n",
    "            total_correcto += 1\n",
    "         \n",
    "    # df predicciones        \n",
    "    df_preds = pd.DataFrame(predictions.round(2))\n",
    "    class_names = encoder.classes_\n",
    "    df_preds.columns = class_names\n",
    "    \n",
    "    # devuelve resultado corrida\n",
    "    resultado = total_correcto/total_predict\n",
    "    return resultado, df_preds, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000019F167BD580> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
     ]
    }
   ],
   "source": [
    "# SOLO SE MODIFICA MANUALMENTE EL MODELO SELECCIONADO!\n",
    "prueba_seleccionada = \"prueba_1\"\n",
    "\n",
    "modelo_seleccionado = modelos[prueba_seleccionada]\n",
    "\n",
    "# Obtener resultados\n",
    "n_pca_modelo_seleccionado = pruebas[prueba_seleccionada].get(\"n_pca\")\n",
    "excl_n_prim_comp_modelo_seleccionado = pruebas[prueba_seleccionada].get(\"excl_n_prim_comp\")\n",
    "resultado, df_preds, predicted_names = get_preds_predict2(\n",
    "    model=modelo_seleccionado, \n",
    "    n_pca=n_pca_modelo_seleccionado, \n",
    "    excl_n_prim_comp=excl_n_prim_comp_modelo_seleccionado, \n",
    "    imagenes=imagenes_all, \n",
    "    nombres=nombres_all, \n",
    "    nuevas_imagenes=new_images, \n",
    "    nuevos_nombres=nombres_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proporción de aciertos:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proporción de aciertos\n",
    "print(\"Proporción de aciertos:\")\n",
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones (cada fila es una foto):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abel</th>\n",
       "      <th>carlos</th>\n",
       "      <th>federicoG</th>\n",
       "      <th>federicoR</th>\n",
       "      <th>florencia</th>\n",
       "      <th>francoA</th>\n",
       "      <th>francoS</th>\n",
       "      <th>gerard</th>\n",
       "      <th>gustavo</th>\n",
       "      <th>joaquin</th>\n",
       "      <th>juan</th>\n",
       "      <th>lautaro</th>\n",
       "      <th>lisandro</th>\n",
       "      <th>marco</th>\n",
       "      <th>matias</th>\n",
       "      <th>natalia</th>\n",
       "      <th>noelia</th>\n",
       "      <th>paola</th>\n",
       "      <th>victorio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lautaro</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lautaro</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lautaro</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lautaro</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paola</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paola</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         abel  carlos  federicoG  federicoR  florencia  francoA  francoS  \\\n",
       "lautaro   0.0     0.0        0.0        0.0        0.0      0.0      0.0   \n",
       "lautaro   0.0     0.0        0.0        0.0        0.0      0.0      0.0   \n",
       "lautaro   0.0     0.0        0.0        0.0        0.0      0.0      0.0   \n",
       "lautaro   0.0     0.0        0.0        0.0        0.0      0.0      0.0   \n",
       "paola     0.0     0.0        0.0        0.0        0.0      0.0      0.0   \n",
       "paola     0.0     0.0        1.0        0.0        0.0      0.0      0.0   \n",
       "\n",
       "         gerard  gustavo  joaquin  juan  lautaro  lisandro  marco  matias  \\\n",
       "lautaro     0.0      0.0      0.0   0.0      1.0       0.0    0.0     0.0   \n",
       "lautaro     0.0      0.0      0.0   0.0      1.0       0.0    0.0     0.0   \n",
       "lautaro     0.0      0.0      0.0   0.0      1.0       0.0    0.0     0.0   \n",
       "lautaro     0.0      0.0      0.0   0.0      0.0       1.0    0.0     0.0   \n",
       "paola       0.0      0.0      0.0   0.0      1.0       0.0    0.0     0.0   \n",
       "paola       0.0      0.0      0.0   0.0      0.0       0.0    0.0     0.0   \n",
       "\n",
       "         natalia  noelia  paola  victorio  \n",
       "lautaro      0.0     0.0    0.0       0.0  \n",
       "lautaro      0.0     0.0    0.0       0.0  \n",
       "lautaro      0.0     0.0    0.0       0.0  \n",
       "lautaro      0.0     0.0    0.0       0.0  \n",
       "paola        0.0     0.0    0.0       0.0  \n",
       "paola        0.0     0.0    0.0       0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicciones\n",
    "print(\"Predicciones (cada fila es una foto):\")\n",
    "df_preds.index = nombres_new\n",
    "df_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nuestras_caras_grupo_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

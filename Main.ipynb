{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuestras Caras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código implementa una técnica de reconocimiento facial conocida como \"Eigenfaces\". \n",
    "\n",
    "La idea básica detrás de Eigenfaces es representar las caras de un conjunto de datos de entrenamiento en un espacio de características de dimensionalidad reducida utilizando el análisis de componentes principales (PCA). \n",
    "\n",
    "Luego, las nuevas caras se proyectan en este espacio de características y se comparan con las caras de entrenamiento para reconocerlas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEPENDENCIAS NECESARIAS:\n",
    "\n",
    "Previo a ejecutar la notebook deben ser instaladas las siguientes dependencias:\n",
    "* pip install opencv-python\n",
    "* pip install pandas\n",
    "* pip install matplotlib\n",
    "* pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from photo_30x30 import cortar_imagenes     # Función para recortar imagenes y pasar a grises\n",
    "from pixels import intensidad_pixels    # Función para obtener la intensidad de los pixeles\n",
    "import perceptrones as per        # Script con backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************************************************************\n",
    "#                    CORTE DE LAS FOTOS Y CAMBIO DE ESCALA DE GRISES MEDIANTE PHOTO_30X30.PY\n",
    "#********************************************************************************************************************\n",
    "# Definimos donde se encuentran las fotos crudas y donde iran las grises 30x30\n",
    "#current_directory = os.getcwd()\n",
    "folder_name_raw = \"input\"\n",
    "folder_name_output = \"output\"\n",
    "\n",
    "# current_directory\n",
    "# os.chdir(os.path.join(current_directory, \"NuestrasCaras\"))\n",
    "\n",
    "\n",
    "# Cortar las fotos y cambiar a escala de grises\n",
    "# cortar_imagenes(folder_name_raw, folder_name_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************************************************************\n",
    "#                    OBTENCION DE LOS VALORES DE LOS PIXELES DE LAS FOTOS MEDIANTE PIXELS.PY\n",
    "#********************************************************************************************************************\n",
    "# Guardo la info de las fotos en un dataframe\n",
    "folder_path_output = os.path.join(os.getcwd(), folder_name_output)\n",
    "data_fotos = intensidad_pixels(folder_path_output)\n",
    "\n",
    "# Get the file names\n",
    "file_names = data_fotos.iloc[:, 0]\n",
    "\n",
    "# Tomo los nombres de cada persona\n",
    "people_names = [name.split(\"-\")[0] for name in file_names]\n",
    "# Transformo los nombres a números (0-1) usando label binarizer\n",
    "nombres = LabelBinarizer().fit_transform(people_names)\n",
    "print(people_names)\n",
    "print(nombres)\n",
    "\n",
    "# Get the greyscale values\n",
    "greyscale_values = data_fotos.iloc[:, 1:].values/255.0\n",
    "\n",
    "#********************************************************************************************************************\n",
    "# Separamos los data sets en training y test\n",
    "#********************************************************************************************************************\n",
    "X_train, X_test, y_train, y_test = train_test_split(greyscale_values, nombres, test_size=0.2, random_state=42)\n",
    "\n",
    "#********************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensiones del array\n",
    "people_names = np.array(people_names)\n",
    "people_names.shape\n",
    "\n",
    "greyscale_values = np.array(greyscale_values)\n",
    "greyscale_values.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtiene y mustra la cara promedio\n",
    "cara_promedio = np.mean(greyscale_values, axis=0)\n",
    "cara_promedio.shape\n",
    "plt.figure(figsize=(3, 2))\n",
    "plt.imshow(cara_promedio.reshape(30,30),cmap=\"gray\")\n",
    "plt.title('Cara Promedio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************************************************************\n",
    "#                    PCA\n",
    "#********************************************************************************************************************\n",
    "# Se aplica PCA a las imagenes\n",
    "# IMPORTANTE! al aumentar el nro de componentes tambien aumenta la precision en la comparacion de imagenes para la clasificacion al final de la notebook!\n",
    "# Tiene sentido porque aumento el porcentaje de variabilidad explicada por las componentes, acercandome mas a la realidad\n",
    "n_pca = 60\n",
    "pca = PCA(n_components=n_pca).fit(greyscale_values)\n",
    "\n",
    "eigenfaces = pca.components_\n",
    "varianza_explicada = pca.explained_variance_ratio_\n",
    "\n",
    "# plot explained variance (grafico continuo)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(np.cumsum(varianza_explicada))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.title('Explained variance vs number of components')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que con aproximadamente 40 CP explicamos el 80% de la varianza. Y con 60 CP, nos acercamos al 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************************************************************\n",
    "#                    GRAFICO DE LAS PRIMERAS 15 EIGENFACES\n",
    "#********************************************************************************************************************\n",
    "\n",
    "fig, ax = plt.subplots(4, 4, figsize=(7, 7))\n",
    "\n",
    "ax[0, 0].imshow(cara_promedio.reshape(30,30), cmap=\"gray\")\n",
    "ax[0, 0].set_title(\"Cara promedio\")\n",
    "\n",
    "for i in range(0,15): # primeras 15 pca\n",
    "    ax[(i+1) // 4, (i+1) % 4].imshow(eigenfaces[i].reshape(30,30), cmap=\"gray\")\n",
    "    ax[(i+1) // 4, (i+1) % 4].set_title(f\"Eigenface {i+1}\")\n",
    "\n",
    "#plot dimensions\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de la red neuronal con backpropagation\n",
    "Comienza inicializando las matrices de pesos de manera aleatoria y realizando la propagación hacia adelante para obtener las salidas de la red. Luego, se calcula el error promedio y se inicia un bucle de entrenamiento que continúa hasta que se cumpla un criterio de convergencia o se alcance el límite de épocas. En cada iteración, se realiza la propagación hacia adelante y hacia atrás para ajustar los pesos mediante la corrección de errores. El proceso se repite hasta que se alcance la convergencia o el límite de épocas, mostrando el número de época y el valor del error en cada iteración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************************************************************************************************************\n",
    "# AHORA TENEMOS QUE USAR EL BACKPROPAGATION \n",
    "#********************************************************************************************************************\n",
    "\n",
    "# Tomo los valores del data set de entrenamiento\n",
    "X = pca.fit_transform(X_train)\n",
    "\n",
    "# Tomo los nombres de las personas del data set de entrenamiento\n",
    "Y = y_train\n",
    "\n",
    "# PRIMERA PRUEBA\n",
    "# Entrenamiento de la red neuronal utilizando el perceptron backpropagation\n",
    "# Aleatoriamente tomo esta cantidad de neuronas en la primera y segunda capa\n",
    "n_neuronas_capa_1 = 19\n",
    "n_neuronas_capa_2 = 7\n",
    "red_neuronal = per.backpropagation_2_capas(X, Y, n_neuronas_capa_1, n_neuronas_capa_2, 2000, 1.0e-6, 0.3)\n",
    "\n",
    "# Tomo los pesos de la red entrenada\n",
    "pesos = red_neuronal[:6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos cara\n",
    "\n",
    "# Tomo una foto de prueba\n",
    "import random\n",
    "n = random.randint(0, len(greyscale_values))\n",
    "foto_prueba = greyscale_values[n]\n",
    "print(nombres[n])\n",
    "print(people_names[n])\n",
    "foto_prueba_pca = pca.transform(foto_prueba.reshape(1, -1))\n",
    "\n",
    "# Prediccion\n",
    "prediccion = per.predecir_clase_2_capas(pesos, foto_prueba_pca)\n",
    "\n",
    "print(prediccion[-1])   # La prediccion arroja varios valores, el mas alto es el correspondiente a la que tiene mas probabilidad de ser\n",
    "print(people_names[prediccion[-1]])  # La persona que es\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos la mejor combinacion de neuronas en las capas ocultas 1 y 2 (DEMORA MUCHO!)\n",
    "\n",
    "# Creo una lista vacia para ir guardando los resultados\n",
    "resultados = []\n",
    "\n",
    "# Creo tres loops: \n",
    "# uno para la cantidad de neuronas en la capa 1, \n",
    "# otro para la cantidad de neuronas en la capa 2,\n",
    "# y otro para la cantidad de fotos del test set\n",
    "\n",
    "import time\n",
    "\n",
    "for i in range(1,36):\n",
    "    for j in range(1,36):\n",
    "        start_time = time.time()\n",
    "        red_neuronal = per.backpropagation_2_capas(X, Y, i, j, 2000, 1.0e-6, 0.3)\n",
    "        pesos = red_neuronal[:6]\n",
    "        aciertos = 0\n",
    "        # tiempo de ejecucion\n",
    "        tiempo = time.time() - start_time\n",
    "        # epoch y error\n",
    "        epoch = red_neuronal[-1]\n",
    "        error = red_neuronal[-2]\n",
    "        # Recorro las fotos del test set\n",
    "        for k in range(0, len(y_test)):\n",
    "            foto_prueba = X_test[k]\n",
    "            foto_prueba_pca = pca.transform(foto_prueba.reshape(1, -1))\n",
    "            prediccion = per.predecir_clase_2_capas(pesos, foto_prueba_pca)\n",
    "            # Si la prediccion es correcta, suma 1 en aciertos\n",
    "            if prediccion[-1] == np.where(y_test[k]==1)[0][0]:\n",
    "                aciertos += 1\n",
    "        # Imprime combinacion de neuronas y aciertos\n",
    "        print(f\"*** Neuronas en primera capa: {i} *** Neuronas en segunda capa: {j} >>> Aciertos: {aciertos} ({round(aciertos/len(y_test)*100,2)}%)\")\n",
    "        print('')\n",
    "        # Guarda los resultados de esta combinacion en la lista\n",
    "        resultados.append((i, j, tiempo, epoch, error, aciertos))\n",
    "\n",
    "\n",
    "\n",
    "#********************************************************************************************************************\n",
    "# Tarda tanto en correr que guardo los resultados en un archivo externo\n",
    "\n",
    "# Guardo los resultados en un dataframe\n",
    "resultados_df = pd.DataFrame(resultados, columns=[\"Neuronas 1\", \"Neuronas 2\", \"Tiempo\", \"Epoch\", \"Error\", \"Aciertos\"])\n",
    "\n",
    "# Guardo el dataframe en un archivo csv\n",
    "resultados_df.to_csv(\"test_backpropagation.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados de la evaluacion de las neuronas en las capas ocultas\n",
    "\n",
    "resultados = np.array(resultados)\n",
    "\n",
    "# Paso los aciertos a porcentaje\n",
    "resultados_pct = resultados[:,2]\n",
    "\n",
    "# Ploteo en un grafico 2D\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(resultados[:,0], resultados[:,1], c=resultados_pct, cmap='viridis', s=100)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Neuronas en capa 1')\n",
    "plt.ylabel('Neuronas en capa 2')\n",
    "plt.title('Aciertos en funcion de las neuronas en las capas ocultas')\n",
    "plt.show()\n",
    "\n",
    "# Ploteo en un grafico 3D\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(resultados[:,0], resultados[:,1], resultados_pct, c=resultados_pct, cmap='viridis')\n",
    "ax.set_xlabel('Neuronas en capa 1')\n",
    "ax.set_ylabel('Neuronas en capa 2')\n",
    "ax.set_zlabel('Aciertos (%)')\n",
    "plt.title('Aciertos en funcion de las neuronas en las capas ocultas')\n",
    "plt.show()\n",
    "\n",
    "#********************************************************************************************************************\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armo un ranking de las 15 mejores combinaciones segun el porcentaje de aciertos\n",
    "resultados[:,2] = resultados_pct\n",
    "ranking = resultados[np.argsort(resultados_pct)[::-1]]\n",
    "print(ranking[:15])\n",
    "\n",
    "# Nos quedamos con la mejor combinacion de neuronas en las capas ocultas\n",
    "# (19, 19) es la mejor combinacion\n",
    "# Pero (12, 8) es casi igual y tiene mucha menor cantidad\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

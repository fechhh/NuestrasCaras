{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuestras Caras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código implementa una técnica de reconocimiento facial conocida como \"Eigenfaces\". \n",
    "\n",
    "La idea básica detrás de Eigenfaces es representar las caras de un conjunto de datos de entrenamiento en un espacio de características de dimensionalidad reducida utilizando el análisis de componentes principales (PCA). \n",
    "\n",
    "Luego, las nuevas caras se proyectan en este espacio de características y se comparan con las caras de entrenamiento para reconocerlas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEPENDENCIAS NECESARIAS:\n",
    "\n",
    "Previo a ejecutar la notebook deben ser instaladas las siguientes dependencias:\n",
    "* pip install opencv-python\n",
    "* pip install pandas\n",
    "* pip install matplotlib\n",
    "* pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.decomposition import PCA\n",
    "from photo_30x30 import cortar_imagenes\n",
    "from pixels import intensidad_pixels\n",
    "import perceptrones as perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def limpiar_string(string, limpiar=True):\n",
    "    if limpiar:\n",
    "        # Eliminar números seguidos de '.jpg'\n",
    "        string = re.sub(r'\\d+\\.jpg', '', string)\n",
    "        # Eliminar números seguidos de 'jpeg'\n",
    "        string = re.sub(r'\\d+\\.jpeg', '', string)\n",
    "        return string\n",
    "    else:\n",
    "        return string\n",
    "    \n",
    "def es_imagen_1(string):\n",
    "    # Utilizar expresión regular para buscar '1.jp' sin otro '1' precediéndolo\n",
    "    return bool(re.search(r'(?<!1)1\\.jp', string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m folder_path_output \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), folder_name_output)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Cortar las fotos y cambiar a escala de grises\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[43mcortar_imagenes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_name_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder_name_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#********************************************************************************************************************\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#                    OBTENCION DE LOS VALORES DE LOS PIXELES DE LAS FOTOS MEDIANTE PIXELS.PY\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#********************************************************************************************************************\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Guardo la info de las fotos en un dataframe\u001b[39;00m\n\u001b[0;32m     22\u001b[0m data_fotos \u001b[38;5;241m=\u001b[39m intensidad_pixels(folder_path_output)\n",
      "File \u001b[1;32mc:\\Users\\fgrijalba\\Desktop\\MCD\\Data Mining Avanzado\\NuestrasCaras\\NuestrasCaras\\photo_30x30.py:17\u001b[0m, in \u001b[0;36mcortar_imagenes\u001b[1;34m(input_dir, output_dir)\u001b[0m\n\u001b[0;32m     14\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(input_path)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Detectamos el rostro en la imagen\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m face_locations \u001b[38;5;241m=\u001b[39m \u001b[43mface_recognition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Numero de imagen\u001b[39;00m\n\u001b[0;32m     20\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\fgrijalba\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\face_recognition\\api.py:121\u001b[0m, in \u001b[0;36mface_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face\u001b[38;5;241m.\u001b[39mrect), img\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m _raw_face_locations(img, number_of_times_to_upsample, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face), img\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_raw_face_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[1;32mc:\\Users\\fgrijalba\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\face_recognition\\api.py:105\u001b[0m, in \u001b[0;36m_raw_face_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cnn_face_detector(img, number_of_times_to_upsample)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mface_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#********************************************************************************************************************\n",
    "#                    CORTE DE LAS FOTOS Y CAMBIO DE ESCALA DE GRISES MEDIANTE PHOTO_30X30.PY\n",
    "#********************************************************************************************************************\n",
    "# Define the folder path\n",
    "# Get the current working directory\n",
    "#current_directory = os.getcwd()\n",
    "folder_name_raw = \"fotos_crudas\"\n",
    "folder_name_output = \"fotos_output\"\n",
    "\n",
    "# current_directory\n",
    "# os.chdir(os.path.join(current_directory, \"NuestrasCaras\"))\n",
    "\n",
    "folder_path_output = os.path.join(os.getcwd(), folder_name_output)\n",
    "\n",
    "# Cortar las fotos y cambiar a escala de grises\n",
    "cortar_imagenes(folder_name_raw, folder_name_output)\n",
    "\n",
    "#********************************************************************************************************************\n",
    "#                    OBTENCION DE LOS VALORES DE LOS PIXELES DE LAS FOTOS MEDIANTE PIXELS.PY\n",
    "#********************************************************************************************************************\n",
    "# Guardo la info de las fotos en un dataframe\n",
    "data_fotos = intensidad_pixels(folder_path_output)\n",
    "\n",
    "# Get the file names\n",
    "file_names = data_fotos.iloc[:, 0]\n",
    "\n",
    "# Tomo los nombres de cada persona\n",
    "people_names = [name.split(\"-\")[0] for name in file_names]\n",
    "\n",
    "# Get the greyscale values\n",
    "greyscale_values = data_fotos.iloc[:, 1:].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

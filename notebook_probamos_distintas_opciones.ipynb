{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import re    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametros notebook\n",
    "DIM = 30\n",
    "seed = 42\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# planteamos distintas pruebas\n",
    "\n",
    "#n_pca: cantidad de componentes principales a considerar\n",
    "#excl_n_prim_comp: excluir las primeras excl_n_prim_comp componenetes principales (0 no se excluye ninguna)\n",
    "#nueronas_layer_1: neuronas capa oculta 1\n",
    "#nueronas_layer_2: neuronas capa oculta 2\n",
    "#n_epochs: cantidad de epochs... NO SE TOMA EN CUENTA... SE HARDCODEA MÁS ABAJO!!!\n",
    "\n",
    "# PARA LA ULTIMA PARTE DE LA NOTEBOOK ES IMPORTANTE TENER A MANO LOS PARAMETROS\n",
    "# \"n_pca\" y \"excl_n_prim_comp\" del modelo seleccionado!!!\n",
    "\n",
    "pruebas = {\n",
    "    #\"prueba_1\": {\"n_pca\":100, \"excl_n_prim_comp\":5, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_2\": {\"n_pca\":150, \"excl_n_prim_comp\":5, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_3\": {\"n_pca\":170, \"excl_n_prim_comp\":5, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_4\": {\"n_pca\":50, \"excl_n_prim_comp\":5, \"nueronas_layer_1\":36, \"nueronas_layer_2\":22, \"n_epochs\":100},\n",
    "    \"prueba_1\": {\"n_pca\":100, \"excl_n_prim_comp\":5, \"nueronas_layer_1\":40, \"nueronas_layer_2\":25, \"n_epochs\":100},\n",
    "    #\"prueba_4_2\": {\"n_pca\":40, \"excl_n_prim_comp\":3, \"nueronas_layer_1\":32, \"nueronas_layer_2\":22, \"n_epochs\":100},\n",
    "    #\"prueba_5\": {\"n_pca\":100, \"excl_n_prim_comp\":4, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_6\": {\"n_pca\":100, \"excl_n_prim_comp\":3, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_7\": {\"n_pca\":100, \"excl_n_prim_comp\":2, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_8\": {\"n_pca\":100, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_9\": {\"n_pca\":100, \"excl_n_prim_comp\":5, \"nueronas_layer_1\":60, \"nueronas_layer_2\":40, \"n_epochs\":100},\n",
    "    #\"prueba_10\": {\"n_pca\":100, \"excl_n_prim_comp\":5, \"nueronas_layer_1\":60, \"nueronas_layer_2\":20, \"n_epochs\":100},\n",
    "    #\"prueba_11\": {\"n_pca\":100, \"excl_n_prim_comp\":5, \"nueronas_layer_1\":50, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_12\": {\"n_pca\":100, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_13\": {\"n_pca\":100, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":45, \"nueronas_layer_2\":26, \"n_epochs\":100},\n",
    "    #\"prueba_14\": {\"n_pca\":100, \"excl_n_prim_comp\":3, \"nueronas_layer_1\":45, \"nueronas_layer_2\":26, \"n_epochs\":100},\n",
    "    #\"prueba_14\": {\"n_pca\":60, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":40, \"nueronas_layer_2\":25, \"n_epochs\":100},\n",
    "    #\"prueba_15\": {\"n_pca\":60, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":36, \"nueronas_layer_2\":22, \"n_epochs\":100},\n",
    "    #\"prueba_16\": {\"n_pca\":40, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_17\": {\"n_pca\":100, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_18\": {\"n_pca\":100, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCIONES DE LA NOTEBOOK (podrian ir en un script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defino funciones utiles\n",
    "def eliminar_numeros(texto):\n",
    "    return re.sub(r'\\d+', '', texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defino funcion para cortar caras de una imagen\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import face_recognition\n",
    "from PIL import Image\n",
    "\n",
    "def cortar_imagenes(input_dir, output_dir, dim=DIM):\n",
    "    # Cargamos el detector de rostros de la libreria face_recognition\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    i = 0\n",
    "    # Para cada archivo del directorio de imput comenzamos el loop\n",
    "    for filename in os.listdir(input_dir):\n",
    "        i += 1\n",
    "        # Cargamos la imagen\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        img = cv2.imread(input_path)\n",
    "\n",
    "        # Detectamos el rostro en la imagen\n",
    "        face_locations = face_recognition.face_locations(img)\n",
    "        \n",
    "        # Cortamos y cambiamos a escala de grises\n",
    "        for (top, right, bottom, left) in face_locations:\n",
    "            face = img[top:bottom, left:right]\n",
    "            face = cv2.resize(face, (dim, dim))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Guardamos el proceso en la carpeta de salida\n",
    "            output_path = os.path.join(output_dir, f\"{filename}\")\n",
    "            cv2.imwrite(output_path, face)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defino funcion para generar nuevas caras\n",
    "# Generar imagenes aleatorias a partir de imagenes existentes\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "def gen_new_image(folder_path, prefix, cantidad_imagenes):\n",
    "\n",
    "    # obtiene nombre de los archivos con las imagenes\n",
    "    file_names = os.listdir(folder_path)\n",
    "\n",
    "    # itera sobre los archivos\n",
    "    for file_name in file_names:\n",
    "        # arma ruta a la imagen\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # carga la imagen\n",
    "        img = image.load_img(file_path)\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "\n",
    "        # crea un generador de datos con aumentos\n",
    "        datagen = ImageDataGenerator(\n",
    "            rotation_range=3,\n",
    "            width_shift_range=0.025,\n",
    "            height_shift_range=0.025,\n",
    "            shear_range=0.025,\n",
    "            zoom_range=0.025,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode=\"nearest\",\n",
    "        )\n",
    "\n",
    "        # separa nombre archivo y extension (a usar en el nombre de la nueva imagen generada)\n",
    "        name, ext = os.path.splitext(file_name)\n",
    "\n",
    "        # inicializa el bucle para las 'cantidad_imagenes' a generar\n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, batch_size=1):\n",
    "            # define nombre de la nueva imagen generada segun prefijo\n",
    "            new_filename = f\"{name}_{prefix}_{i}{ext}\"\n",
    "\n",
    "            # guarda la imagen aumentada\n",
    "            new_file_path = os.path.join(folder_path, new_filename)\n",
    "            img_augmented = image.array_to_img(batch[0])\n",
    "            img_augmented.save(new_file_path)\n",
    "            i += 1\n",
    "            if i >= cantidad_imagenes:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defino funcion para entrenar \n",
    "def run_keras_model(n_pca, excl_n_prim_comp, nueronas_layer_1, nueronas_layer_2, n_epochs, imagenes, nombres, nuevas_imagenes, nuevos_nombres):\n",
    "    \n",
    "    # Dividir en entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(imagenes, nombres, test_size=0.05, random_state=42, stratify=nombres)\n",
    "\n",
    "    # Aplicar PCA\n",
    "    pca = PCA(n_components=n_pca, random_state=seed)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    #X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    # Escalar los datos \n",
    "    scaler = StandardScaler()\n",
    "    #scaler = MinMaxScaler()\n",
    "    X_train_pca_scaled = scaler.fit_transform(X_train_pca)\n",
    "    #X_test_pca_scaled = scaler.transform(X_test_pca)\n",
    "    \n",
    "    \n",
    "    # Codificar las etiquetas\n",
    "    encoder = LabelEncoder()\n",
    "    y_train_encoded = encoder.fit_transform(y_train)\n",
    "    #y_test_encoded = encoder.transform(y_test)\n",
    "    y_train_categorical = to_categorical(y_train_encoded, num_classes=18)\n",
    "    #y_test_categorical = to_categorical(y_test_encoded, num_classes=18)\n",
    "    \n",
    "    \n",
    "    # Definir la red neuronal\n",
    "    entreno_con = X_train_pca_scaled[:,excl_n_prim_comp:]\n",
    "    #testeo_con = X_test_pca_scaled[:,excl_n_prim_comp:]\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=entreno_con.shape[1:]))  # Definir la entrada del modelo\n",
    "    model.add(Dense(nueronas_layer_1, activation='sigmoid'))\n",
    "    model.add(Dense(nueronas_layer_2, activation='sigmoid'))\n",
    "    model.add(Dense(y_train_categorical.shape[1], activation='softmax'))\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    model.fit(entreno_con, y_train_categorical, epochs=n_epochs, batch_size=10, validation_split=0.3)\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    #loss, accuracy = model.evaluate(testeo_con, y_test_categorical)\n",
    "    #print(f'Precisión en el conjunto de prueba: {accuracy * 100:.2f}%')\n",
    "    \n",
    "    \n",
    "    # PREDICCIONES\n",
    "    # 2. Aplicar PCA\n",
    "    new_images_pca = pca.transform(nuevas_imagenes)\n",
    "    new_images_pca_scaled = scaler.transform(new_images_pca)\n",
    "    evaluo_con = new_images_pca_scaled[:,excl_n_prim_comp:]\n",
    "\n",
    "    # 3. Hacer predicciones\n",
    "    predictions = model.predict(evaluo_con)\n",
    "\n",
    "    # Obtener los nombres correspondientes a las clases predichas\n",
    "    predicted_names = encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
    "\n",
    "    # Imprimir las predicciones\n",
    "    total_predict = len(nuevos_nombres)\n",
    "    total_correcto = 0\n",
    "    for real, pred in zip(nuevos_nombres, predicted_names):\n",
    "        if real == pred:\n",
    "            total_correcto += 1\n",
    "    \n",
    "    # devuelve resultado corrida\n",
    "    resultado = total_correcto/total_predict\n",
    "    return resultado, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo de uso\n",
    "#cortar_imagenes(input_dir=\"fotos_probamos_distintas_opciones/input\", output_dir=\"fotos_probamos_distintas_opciones/output\")\n",
    "#gen_new_image(folder_path=\"fotos_probamos_distintas_opciones/output\", prefix=\"gen_aut\", cantidad_imagenes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEER IMAGENES PARA ENTRENAMIENTO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración inicial\n",
    "dim_imagenes = DIM\n",
    "data_dir = \"fotos_probamos_distintas_opciones/entrenamiento\"\n",
    "nombres = []\n",
    "imagenes = []\n",
    "\n",
    "# Cargar imágenes y etiquetas\n",
    "for archivo in os.listdir(data_dir):\n",
    "    if archivo.endswith('.jpeg') or archivo.endswith('.jpg'):\n",
    "        nombre = archivo.split('_')[0].replace(\".jpg\",\"\").replace(\".jpeg\",\"\")\n",
    "        nombre = eliminar_numeros(nombre)\n",
    "        ruta_imagen = os.path.join(data_dir, archivo)\n",
    "        imagen = Image.open(ruta_imagen)\n",
    "        imagen = np.array(imagen.resize((dim_imagenes, dim_imagenes)))  # Redimensionar imágenes para un tamaño uniforme\n",
    "        if len(imagen.shape) == 3 and imagen.shape[2] == 3:\n",
    "            imagen = cv2.cvtColor(imagen, cv2.COLOR_RGB2GRAY)  # Convertir a escala de grises si es necesario\n",
    "        imagenes.append(imagen.flatten())\n",
    "        nombres.append(nombre)\n",
    "\n",
    "imagenes_all = np.array(imagenes)\n",
    "nombres_all = np.array(nombres)\n",
    "\n",
    "# estand\n",
    "imagenes_all = imagenes_all/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10459, 900)\n",
      "(10459,)\n"
     ]
    }
   ],
   "source": [
    "print(imagenes_all.shape)\n",
    "print(nombres_all.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEER IMAGENES PARA PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración inicial\n",
    "data_dir = (\"fotos_probamos_distintas_opciones/predict\")  # Cambia esto a la ruta de tu directorio de imágenes\n",
    "nombres = []\n",
    "imagenes = []\n",
    "\n",
    "# Cargar imágenes y etiquetas\n",
    "for archivo in os.listdir(data_dir):\n",
    "    if archivo.endswith('.jpeg') or archivo.endswith('.jpg'):\n",
    "        nombre = archivo.split('_')[0].replace(\".jpg\",\"\").replace(\".jpeg\",\"\")\n",
    "        nombre = eliminar_numeros(nombre)\n",
    "        ruta_imagen = os.path.join(data_dir, archivo)\n",
    "        imagen = Image.open(ruta_imagen)\n",
    "        imagen = np.array(imagen.resize((dim_imagenes, dim_imagenes)))  # Redimensionar imágenes para un tamaño uniforme\n",
    "        if len(imagen.shape) == 3 and imagen.shape[2] == 3:\n",
    "            imagen = cv2.cvtColor(imagen, cv2.COLOR_RGB2GRAY)  # Convertir a escala de grises si es necesario\n",
    "        imagenes.append(imagen.flatten())\n",
    "        nombres.append(nombre)\n",
    "\n",
    "new_images = np.array(imagenes)\n",
    "nombres_new = np.array(nombres)\n",
    "\n",
    "# estand\n",
    "new_images = new_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 900)\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "print(new_images.shape)\n",
    "print(nombres_new.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prueba_1: \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 18 is out of bounds for axis 1 with size 18",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prueba, params \u001b[38;5;129;01min\u001b[39;00m pruebas\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprueba\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     resultado, modelo \u001b[38;5;241m=\u001b[39m \u001b[43mrun_keras_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_pca\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_pca\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mexcl_n_prim_comp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexcl_n_prim_comp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnueronas_layer_1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnueronas_layer_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnueronas_layer_2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnueronas_layer_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# NO TOMA EL QUE DEFINIMOS EN PRUEBAS\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mimagenes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimagenes_all\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnombres\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnombres_all\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnuevas_imagenes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnuevos_nombres\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnombres_new\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     resutados[prueba]\u001b[38;5;241m=\u001b[39mresultado\n\u001b[0;32m     17\u001b[0m     modelos_500[prueba]\u001b[38;5;241m=\u001b[39mmodelo\n",
      "Cell \u001b[1;32mIn[7], line 23\u001b[0m, in \u001b[0;36mrun_keras_model\u001b[1;34m(n_pca, excl_n_prim_comp, nueronas_layer_1, nueronas_layer_2, n_epochs, imagenes, nombres, nuevas_imagenes, nuevos_nombres)\u001b[0m\n\u001b[0;32m     21\u001b[0m y_train_encoded \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mfit_transform(y_train)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#y_test_encoded = encoder.transform(y_test)\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m y_train_categorical \u001b[38;5;241m=\u001b[39m \u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m18\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#y_test_categorical = to_categorical(y_test_encoded, num_classes=18)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Definir la red neuronal\u001b[39;00m\n\u001b[0;32m     28\u001b[0m entreno_con \u001b[38;5;241m=\u001b[39m X_train_pca_scaled[:,excl_n_prim_comp:]\n",
      "File \u001b[1;32mc:\\Users\\lauta\\miniconda3\\envs\\nuestras_caras_grupo_1\\Lib\\site-packages\\keras\\src\\utils\\numerical_utils.py:89\u001b[0m, in \u001b[0;36mto_categorical\u001b[1;34m(x, num_classes)\u001b[0m\n\u001b[0;32m     87\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     88\u001b[0m categorical \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((batch_size, num_classes))\n\u001b[1;32m---> 89\u001b[0m \u001b[43mcategorical\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     90\u001b[0m output_shape \u001b[38;5;241m=\u001b[39m input_shape \u001b[38;5;241m+\u001b[39m (num_classes,)\n\u001b[0;32m     91\u001b[0m categorical \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(categorical, output_shape)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 18 is out of bounds for axis 1 with size 18"
     ]
    }
   ],
   "source": [
    "# PRUEBAS CON epochs 500 # SI TARDA MUCHO PROBAR CON 250...\n",
    "resutados = {}\n",
    "modelos_500 = {}\n",
    "for prueba, params in pruebas.items():\n",
    "    print(f\"{prueba}: \")\n",
    "    resultado, modelo = run_keras_model(n_pca=params.get('n_pca'), \n",
    "                    excl_n_prim_comp=params.get('excl_n_prim_comp'), \n",
    "                    nueronas_layer_1=params.get('nueronas_layer_1'),\n",
    "                    nueronas_layer_2=params.get('nueronas_layer_2'),\n",
    "                    n_epochs=10, # NO TOMA EL QUE DEFINIMOS EN PRUEBAS\n",
    "                    imagenes=imagenes_all,\n",
    "                    nombres=nombres_all,\n",
    "                    nuevas_imagenes=new_images,\n",
    "                    nuevos_nombres=nombres_new\n",
    "                    )\n",
    "    resutados[prueba]=resultado\n",
    "    modelos_500[prueba]=modelo\n",
    "resutados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRUEBAS CON epochs 200\n",
    "resutados = {}\n",
    "modelos_200 = {}\n",
    "for prueba, params in pruebas.items():\n",
    "    print(f\"{prueba}: \")\n",
    "    resultado, modelo = run_keras_model(n_pca=params.get('n_pca'), \n",
    "                    excl_n_prim_comp=params.get('excl_n_prim_comp'), \n",
    "                    nueronas_layer_1=params.get('nueronas_layer_1'),\n",
    "                    nueronas_layer_2=params.get('nueronas_layer_2'),\n",
    "                    n_epochs=10, # NO TOMA EL QUE DEFINIMOS EN PRUEBAS\n",
    "                    imagenes=imagenes_all,\n",
    "                    nombres=nombres_all,\n",
    "                    nuevas_imagenes=new_images,\n",
    "                    nuevos_nombres=nombres_new\n",
    "                    )\n",
    "    resutados[prueba]=resultado\n",
    "    modelos_200[prueba]=modelo\n",
    "resutados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebo predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si cargo nuevas fotos es importante correr esta parte (con True en lugar de False)\n",
    "# hacer check manual que TOME BIEN LAS CARAS (puede pasar que recorte algo que NO es una cara)\n",
    "if False:\n",
    "    cortar_imagenes(input_dir=\"fotos_probamos_distintas_opciones/probar_nuevas_fotos_input\", output_dir=\"fotos_probamos_distintas_opciones/probar_nuevas_fotos_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 900)\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "# importo imagenes predict 2\n",
    "data_dir = (\"fotos_probamos_distintas_opciones/probar_nuevas_fotos_output\")  # Cambia esto a la ruta de tu directorio de imágenes\n",
    "nombres = []\n",
    "imagenes = []\n",
    "\n",
    "# Cargar imágenes y etiquetas\n",
    "for archivo in os.listdir(data_dir):\n",
    "    if archivo.endswith('.jpeg') or archivo.endswith('.jpg'):\n",
    "        nombre = archivo.split('_')[0].replace(\".jpg\",\"\").replace(\".jpeg\",\"\")\n",
    "        nombre = eliminar_numeros(nombre)\n",
    "        ruta_imagen = os.path.join(data_dir, archivo)\n",
    "        imagen = Image.open(ruta_imagen)\n",
    "        imagen = np.array(imagen.resize((dim_imagenes, dim_imagenes)))  # Redimensionar imágenes para un tamaño uniforme\n",
    "        if len(imagen.shape) == 3 and imagen.shape[2] == 3:\n",
    "            imagen = cv2.cvtColor(imagen, cv2.COLOR_RGB2GRAY)  # Convertir a escala de grises si es necesario\n",
    "        imagenes.append(imagen.flatten())\n",
    "        nombres.append(nombre)\n",
    "\n",
    "new_images = np.array(imagenes)\n",
    "nombres_new = np.array(nombres)\n",
    "\n",
    "# estand\n",
    "new_images = new_images/255.0\n",
    "print(new_images.shape)\n",
    "print(nombres_new.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nombres_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_predict2(model, n_pca, excl_n_prim_comp, imagenes, nombres, nuevas_imagenes, nuevos_nombres):\n",
    "    \n",
    "    # Dividir en entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(imagenes, nombres, test_size=0.05, random_state=42, stratify=nombres)\n",
    "\n",
    "    # Aplicar PCA\n",
    "    pca = PCA(n_components=n_pca, random_state=12)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    #X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    # Escalar los datos \n",
    "    scaler = StandardScaler()\n",
    "    #scaler = MinMaxScaler()\n",
    "    X_train_pca_scaled = scaler.fit_transform(X_train_pca)\n",
    "    #X_test_pca_scaled = scaler.transform(X_test_pca)\n",
    "    \n",
    "    \n",
    "    # Codificar las etiquetas\n",
    "    encoder = LabelEncoder()\n",
    "    y_train_encoded = encoder.fit_transform(y_train)\n",
    "    #y_test_encoded = encoder.transform(y_test)\n",
    "    y_train_categorical = to_categorical(y_train_encoded, num_classes=18)\n",
    "    #y_test_categorical = to_categorical(y_test_encoded, num_classes=18)\n",
    "    \n",
    "    \n",
    "    # Definir la red neuronal\n",
    "    entreno_con = X_train_pca_scaled[:,excl_n_prim_comp:]\n",
    "    #testeo_con = X_test_pca_scaled[:,excl_n_prim_comp:]    \n",
    "    \n",
    "    # PREDICCIONES\n",
    "    # 2. Aplicar PCA\n",
    "    new_images_pca = pca.transform(nuevas_imagenes)\n",
    "    new_images_pca_scaled = scaler.transform(new_images_pca)\n",
    "    evaluo_con = new_images_pca_scaled[:,excl_n_prim_comp:]\n",
    "\n",
    "    # 3. Hacer predicciones\n",
    "    predictions = model.predict(evaluo_con)\n",
    "\n",
    "    # Obtener los nombres correspondientes a las clases predichas\n",
    "    predicted_names = encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
    "\n",
    "    # Imprimir las predicciones\n",
    "    total_predict = len(nuevos_nombres)\n",
    "    total_correcto = 0\n",
    "    for real, pred in zip(nuevos_nombres, predicted_names):\n",
    "        if real == pred:\n",
    "            total_correcto += 1\n",
    "         \n",
    "    # df predicciones        \n",
    "    df_preds = pd.DataFrame(predictions.round(2))\n",
    "    class_names = encoder.classes_\n",
    "    df_preds.columns = class_names\n",
    "    \n",
    "    # devuelve resultado corrida\n",
    "    resultado = total_correcto/total_predict\n",
    "    return resultado, df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000017AC9257420> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n"
     ]
    }
   ],
   "source": [
    "resultado13, df_preds13 = get_preds_predict2(\n",
    "    model=modelos_500[\"prueba_13\"], \n",
    "    n_pca=100, \n",
    "    excl_n_prim_comp=0, \n",
    "    imagenes=imagenes_all, \n",
    "    nombres=nombres_all, \n",
    "    nuevas_imagenes=new_images, \n",
    "    nuevos_nombres=nombres_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carlos</th>\n",
       "      <th>federicoG</th>\n",
       "      <th>federicoR</th>\n",
       "      <th>florencia</th>\n",
       "      <th>francoA</th>\n",
       "      <th>francoS</th>\n",
       "      <th>gerard</th>\n",
       "      <th>gustavo</th>\n",
       "      <th>joaquin</th>\n",
       "      <th>juan</th>\n",
       "      <th>lautaro</th>\n",
       "      <th>lisandro</th>\n",
       "      <th>marco</th>\n",
       "      <th>matias</th>\n",
       "      <th>natalia</th>\n",
       "      <th>noelia</th>\n",
       "      <th>paola</th>\n",
       "      <th>victorio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carlos  federicoG  federicoR  florencia  francoA  francoS  gerard  gustavo  \\\n",
       "0    0.89        0.0        0.0        0.0      0.0      0.0    0.01      0.0   \n",
       "1    0.01        0.0        0.0        0.0      0.0      0.0    0.00      0.0   \n",
       "2    0.00        0.0        0.0        0.0      0.0      0.0    0.01      0.0   \n",
       "3    0.00        0.0        0.0        0.0      0.0      0.0    0.00      0.3   \n",
       "\n",
       "   joaquin  juan  lautaro  lisandro  marco  matias  natalia  noelia  paola  \\\n",
       "0      0.0   0.0     0.07      0.00   0.02    0.00      0.0    0.00    0.0   \n",
       "1      0.0   0.0     0.95      0.00   0.00    0.00      0.0    0.04    0.0   \n",
       "2      0.0   0.0     0.99      0.00   0.00    0.00      0.0    0.00    0.0   \n",
       "3      0.0   0.0     0.01      0.46   0.20    0.01      0.0    0.00    0.0   \n",
       "\n",
       "   victorio  \n",
       "0      0.01  \n",
       "1      0.00  \n",
       "2      0.00  \n",
       "3      0.02  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
     ]
    }
   ],
   "source": [
    "resultado14, df_preds14 = get_preds_predict2(\n",
    "    model=modelos_500[\"prueba_14\"], \n",
    "    n_pca=100, \n",
    "    excl_n_prim_comp=3, \n",
    "    imagenes=imagenes_all, \n",
    "    nombres=nombres_all, \n",
    "    nuevas_imagenes=new_images, \n",
    "    nuevos_nombres=nombres_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carlos</th>\n",
       "      <th>federicoG</th>\n",
       "      <th>federicoR</th>\n",
       "      <th>florencia</th>\n",
       "      <th>francoA</th>\n",
       "      <th>francoS</th>\n",
       "      <th>gerard</th>\n",
       "      <th>gustavo</th>\n",
       "      <th>joaquin</th>\n",
       "      <th>juan</th>\n",
       "      <th>lautaro</th>\n",
       "      <th>lisandro</th>\n",
       "      <th>marco</th>\n",
       "      <th>matias</th>\n",
       "      <th>natalia</th>\n",
       "      <th>noelia</th>\n",
       "      <th>paola</th>\n",
       "      <th>victorio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carlos  federicoG  federicoR  florencia  francoA  francoS  gerard  gustavo  \\\n",
       "0     0.0        0.0        0.0        0.0      0.0      0.0    0.00      0.0   \n",
       "1     0.0        0.0        0.0        0.0      0.0      0.0    0.00      0.0   \n",
       "2     0.0        0.0        0.0        0.0      0.0      0.0    0.99      0.0   \n",
       "3     0.0        0.0        0.0        0.0      0.0      0.0    0.00      0.0   \n",
       "\n",
       "   joaquin  juan  lautaro  lisandro  marco  matias  natalia  noelia  paola  \\\n",
       "0      0.0   0.0     1.00      0.00    0.0    0.00      0.0     0.0   0.00   \n",
       "1      0.0   0.0     0.86      0.00    0.0    0.09      0.0     0.0   0.00   \n",
       "2      0.0   0.0     0.01      0.00    0.0    0.00      0.0     0.0   0.00   \n",
       "3      0.0   0.0     0.01      0.67    0.3    0.00      0.0     0.0   0.01   \n",
       "\n",
       "   victorio  \n",
       "0      0.00  \n",
       "1      0.05  \n",
       "2      0.00  \n",
       "3      0.00  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds14"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nuestras_caras_grupo_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

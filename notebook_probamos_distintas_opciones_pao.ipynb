{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import re    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametros notebook\n",
    "DIM = 30\n",
    "seed = 42\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# planteamos distintas pruebas\n",
    "\n",
    "#n_pca: cantidad de componentes principales a considerar\n",
    "#excl_n_prim_comp: excluir las primeras excl_n_prim_comp componenetes principales (0 no se excluye ninguna)\n",
    "#nueronas_layer_1: neuronas capa oculta 1\n",
    "#nueronas_layer_2: neuronas capa oculta 2\n",
    "#n_epochs: cantidad de epochs... NO SE TOMA EN CUENTA... SE HARDCODEA MÁS ABAJO!!!\n",
    "\n",
    "# PARA LA ULTIMA PARTE DE LA NOTEBOOK ES IMPORTANTE TENER A MANO LOS PARAMETROS\n",
    "# \"n_pca\" y \"excl_n_prim_comp\" del modelo seleccionado!!!\n",
    "\n",
    "pruebas = {\n",
    "    #\"prueba_1\": {\"n_pca\":100, \"excl_n_prim_comp\":5, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_2\": {\"n_pca\":150, \"excl_n_prim_comp\":5, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_3\": {\"n_pca\":170, \"excl_n_prim_comp\":5, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_4\": {\"n_pca\":50, \"excl_n_prim_comp\":5, \"nueronas_layer_1\":36, \"nueronas_layer_2\":22, \"n_epochs\":100},\n",
    "    \"prueba_4_1\": {\"n_pca\":60, \"excl_n_prim_comp\":5, \"nueronas_layer_1\":40, \"nueronas_layer_2\":25, \"n_epochs\":100},\n",
    "    #\"prueba_4_2\": {\"n_pca\":40, \"excl_n_prim_comp\":3, \"nueronas_layer_1\":32, \"nueronas_layer_2\":22, \"n_epochs\":100},\n",
    "    #\"prueba_5\": {\"n_pca\":100, \"excl_n_prim_comp\":4, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_6\": {\"n_pca\":100, \"excl_n_prim_comp\":3, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_7\": {\"n_pca\":100, \"excl_n_prim_comp\":2, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_8\": {\"n_pca\":100, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_9\": {\"n_pca\":100, \"excl_n_prim_comp\":5, \"nueronas_layer_1\":60, \"nueronas_layer_2\":40, \"n_epochs\":100},\n",
    "    #\"prueba_10\": {\"n_pca\":100, \"excl_n_prim_comp\":5, \"nueronas_layer_1\":60, \"nueronas_layer_2\":20, \"n_epochs\":100},\n",
    "    #\"prueba_11\": {\"n_pca\":100, \"excl_n_prim_comp\":5, \"nueronas_layer_1\":50, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    \"prueba_12\": {\"n_pca\":100, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    \"prueba_13\": {\"n_pca\":100, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":45, \"nueronas_layer_2\":26, \"n_epochs\":100},\n",
    "    \"prueba_14\": {\"n_pca\":100, \"excl_n_prim_comp\":3, \"nueronas_layer_1\":45, \"nueronas_layer_2\":26, \"n_epochs\":100},\n",
    "    #\"prueba_14\": {\"n_pca\":60, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":40, \"nueronas_layer_2\":25, \"n_epochs\":100},\n",
    "    #\"prueba_15\": {\"n_pca\":60, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":36, \"nueronas_layer_2\":22, \"n_epochs\":100},\n",
    "    #\"prueba_16\": {\"n_pca\":40, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_17\": {\"n_pca\":100, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    #\"prueba_18\": {\"n_pca\":100, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    \"prueba_19\": {\"n_pca\":100, \"excl_n_prim_comp\":0, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "    \"prueba_20\": {\"n_pca\":100, \"excl_n_prim_comp\":3, \"nueronas_layer_1\":60, \"nueronas_layer_2\":30, \"n_epochs\":100},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCIONES DE LA NOTEBOOK (podrian ir en un script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defino funciones utiles\n",
    "def eliminar_numeros(texto):\n",
    "    return re.sub(r'\\d+', '', texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'face_recognition'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mface_recognition\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcortar_imagenes\u001b[39m(input_dir, output_dir, dim\u001b[38;5;241m=\u001b[39mDIM):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Cargamos el detector de rostros de la libreria face_recognition\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'face_recognition'"
     ]
    }
   ],
   "source": [
    "## defino funcion para cortar caras de una imagen\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import face_recognition\n",
    "from PIL import Image\n",
    "\n",
    "def cortar_imagenes(input_dir, output_dir, dim=DIM):\n",
    "    # Cargamos el detector de rostros de la libreria face_recognition\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    i = 0\n",
    "    # Para cada archivo del directorio de imput comenzamos el loop\n",
    "    for filename in os.listdir(input_dir):\n",
    "        i += 1\n",
    "        # Cargamos la imagen\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        img = cv2.imread(input_path)\n",
    "\n",
    "        # Detectamos el rostro en la imagen\n",
    "        face_locations = face_recognition.face_locations(img)\n",
    "        \n",
    "        # Cortamos y cambiamos a escala de grises\n",
    "        for (top, right, bottom, left) in face_locations:\n",
    "            face = img[top:bottom, left:right]\n",
    "            face = cv2.resize(face, (dim, dim))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Guardamos el proceso en la carpeta de salida\n",
    "            output_path = os.path.join(output_dir, f\"{filename}\")\n",
    "            cv2.imwrite(output_path, face)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defino funcion para generar nuevas caras\n",
    "# Generar imagenes aleatorias a partir de imagenes existentes\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "def gen_new_image(folder_path, prefix, cantidad_imagenes):\n",
    "\n",
    "    # obtiene nombre de los archivos con las imagenes\n",
    "    file_names = os.listdir(folder_path)\n",
    "\n",
    "    # itera sobre los archivos\n",
    "    for file_name in file_names:\n",
    "        # arma ruta a la imagen\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # carga la imagen\n",
    "        img = image.load_img(file_path)\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "\n",
    "        # crea un generador de datos con aumentos\n",
    "        datagen = ImageDataGenerator(\n",
    "            rotation_range=3,\n",
    "            width_shift_range=0.025,\n",
    "            height_shift_range=0.025,\n",
    "            shear_range=0.025,\n",
    "            zoom_range=0.025,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode=\"nearest\",\n",
    "        )\n",
    "\n",
    "        # separa nombre archivo y extension (a usar en el nombre de la nueva imagen generada)\n",
    "        name, ext = os.path.splitext(file_name)\n",
    "\n",
    "        # inicializa el bucle para las 'cantidad_imagenes' a generar\n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, batch_size=1):\n",
    "            # define nombre de la nueva imagen generada segun prefijo\n",
    "            new_filename = f\"{name}_{prefix}_{i}{ext}\"\n",
    "\n",
    "            # guarda la imagen aumentada\n",
    "            new_file_path = os.path.join(folder_path, new_filename)\n",
    "            img_augmented = image.array_to_img(batch[0])\n",
    "            img_augmented.save(new_file_path)\n",
    "            i += 1\n",
    "            if i >= cantidad_imagenes:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defino funcion para entrenar \n",
    "def run_keras_model(n_pca, excl_n_prim_comp, nueronas_layer_1, nueronas_layer_2, n_epochs, imagenes, nombres, nuevas_imagenes, nuevos_nombres):\n",
    "    \n",
    "    # Dividir en entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(imagenes, nombres, test_size=0.05, random_state=42, stratify=nombres)\n",
    "\n",
    "    # Aplicar PCA\n",
    "    pca = PCA(n_components=n_pca, random_state=seed)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    #X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    # Escalar los datos \n",
    "    scaler = StandardScaler()\n",
    "    #scaler = MinMaxScaler()\n",
    "    X_train_pca_scaled = scaler.fit_transform(X_train_pca)\n",
    "    #X_test_pca_scaled = scaler.transform(X_test_pca)\n",
    "    \n",
    "    \n",
    "    # Codificar las etiquetas\n",
    "    encoder = LabelEncoder()\n",
    "    y_train_encoded = encoder.fit_transform(y_train)\n",
    "    #y_test_encoded = encoder.transform(y_test)\n",
    "    y_train_categorical = to_categorical(y_train_encoded, num_classes=18)\n",
    "    #y_test_categorical = to_categorical(y_test_encoded, num_classes=18)\n",
    "    \n",
    "    \n",
    "    # Definir la red neuronal\n",
    "    entreno_con = X_train_pca_scaled[:,excl_n_prim_comp:]\n",
    "    #testeo_con = X_test_pca_scaled[:,excl_n_prim_comp:]\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=entreno_con.shape[1:]))  # Definir la entrada del modelo\n",
    "    model.add(Dense(nueronas_layer_1, activation='sigmoid'))\n",
    "    model.add(Dense(nueronas_layer_2, activation='sigmoid'))\n",
    "    model.add(Dense(y_train_categorical.shape[1], activation='softmax'))\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    model.fit(entreno_con, y_train_categorical, epochs=n_epochs, batch_size=10, validation_split=0.3)\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    #loss, accuracy = model.evaluate(testeo_con, y_test_categorical)\n",
    "    #print(f'Precisión en el conjunto de prueba: {accuracy * 100:.2f}%')\n",
    "    \n",
    "    \n",
    "    # PREDICCIONES\n",
    "    # 2. Aplicar PCA\n",
    "    new_images_pca = pca.transform(nuevas_imagenes)\n",
    "    new_images_pca_scaled = scaler.transform(new_images_pca)\n",
    "    evaluo_con = new_images_pca_scaled[:,excl_n_prim_comp:]\n",
    "\n",
    "    # 3. Hacer predicciones\n",
    "    predictions = model.predict(evaluo_con)\n",
    "\n",
    "    # Obtener los nombres correspondientes a las clases predichas\n",
    "    predicted_names = encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
    "\n",
    "    # Imprimir las predicciones\n",
    "    total_predict = len(nuevos_nombres)\n",
    "    total_correcto = 0\n",
    "    for real, pred in zip(nuevos_nombres, predicted_names):\n",
    "        if real == pred:\n",
    "            total_correcto += 1\n",
    "    \n",
    "    # devuelve resultado corrida\n",
    "    resultado = total_correcto/total_predict\n",
    "    return resultado, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo de uso\n",
    "#cortar_imagenes(input_dir=\"fotos/Recorte manual\", output_dir=\"fotos/Recorte manual otutput 35\")\n",
    "# esta gen_new_imagen usarla sobre la carpeta de salida de cortar_imagenes\n",
    "#gen_new_image(folder_path=\"fotos/Recorte manual otutput 35\", prefix=\"gen_aut\", cantidad_imagenes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEER IMAGENES PARA ENTRENAMIENTO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración inicial\n",
    "dim_imagenes = DIM\n",
    "data_dir = \"fotos_probamos_distintas_opciones/entrenamiento\"\n",
    "nombres = []\n",
    "imagenes = []\n",
    "\n",
    "# Cargar imágenes y etiquetas\n",
    "for archivo in os.listdir(data_dir):\n",
    "    if archivo.endswith('.jpeg') or archivo.endswith('.jpg'):\n",
    "        nombre = archivo.split('_')[0].replace(\".jpg\",\"\").replace(\".jpeg\",\"\")\n",
    "        nombre = eliminar_numeros(nombre)\n",
    "        ruta_imagen = os.path.join(data_dir, archivo)\n",
    "        imagen = Image.open(ruta_imagen)\n",
    "        imagen = np.array(imagen.resize((dim_imagenes, dim_imagenes)))  # Redimensionar imágenes para un tamaño uniforme\n",
    "        if len(imagen.shape) == 3 and imagen.shape[2] == 3:\n",
    "            imagen = cv2.cvtColor(imagen, cv2.COLOR_RGB2GRAY)  # Convertir a escala de grises si es necesario\n",
    "        imagenes.append(imagen.flatten())\n",
    "        nombres.append(nombre)\n",
    "\n",
    "imagenes_all = np.array(imagenes)\n",
    "nombres_all = np.array(nombres)\n",
    "\n",
    "# estand\n",
    "imagenes_all = imagenes_all/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10261, 900)\n",
      "(10261,)\n"
     ]
    }
   ],
   "source": [
    "print(imagenes_all.shape)\n",
    "print(nombres_all.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEER IMAGENES PARA PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración inicial\n",
    "data_dir = (\"fotos_probamos_distintas_opciones/predict\")  # Cambia esto a la ruta de tu directorio de imágenes\n",
    "nombres = []\n",
    "imagenes = []\n",
    "\n",
    "# Cargar imágenes y etiquetas\n",
    "for archivo in os.listdir(data_dir):\n",
    "    if archivo.endswith('.jpeg') or archivo.endswith('.jpg'):\n",
    "        nombre = archivo.split('_')[0].replace(\".jpg\",\"\").replace(\".jpeg\",\"\")\n",
    "        nombre = eliminar_numeros(nombre)\n",
    "        ruta_imagen = os.path.join(data_dir, archivo)\n",
    "        imagen = Image.open(ruta_imagen)\n",
    "        imagen = np.array(imagen.resize((dim_imagenes, dim_imagenes)))  # Redimensionar imágenes para un tamaño uniforme\n",
    "        if len(imagen.shape) == 3 and imagen.shape[2] == 3:\n",
    "            imagen = cv2.cvtColor(imagen, cv2.COLOR_RGB2GRAY)  # Convertir a escala de grises si es necesario\n",
    "        imagenes.append(imagen.flatten())\n",
    "        nombres.append(nombre)\n",
    "\n",
    "new_images = np.array(imagenes)\n",
    "nombres_new = np.array(nombres)\n",
    "\n",
    "# estand\n",
    "new_images = new_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 900)\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "print(new_images.shape)\n",
    "print(nombres_new.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prueba_4_1: \n",
      "Epoch 1/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1246 - loss: 2.8398 - val_accuracy: 0.2885 - val_loss: 2.5135\n",
      "Epoch 2/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3262 - loss: 2.3686 - val_accuracy: 0.4291 - val_loss: 1.9988\n",
      "Epoch 3/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4859 - loss: 1.8752 - val_accuracy: 0.5768 - val_loss: 1.6011\n",
      "Epoch 4/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6262 - loss: 1.4968 - val_accuracy: 0.6492 - val_loss: 1.3217\n",
      "Epoch 5/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6913 - loss: 1.2328 - val_accuracy: 0.6882 - val_loss: 1.1414\n",
      "Epoch 6/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7263 - loss: 1.0563 - val_accuracy: 0.7200 - val_loss: 1.0178\n",
      "Epoch 7/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7591 - loss: 0.9302 - val_accuracy: 0.7398 - val_loss: 0.9253\n",
      "Epoch 8/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7773 - loss: 0.8329 - val_accuracy: 0.7597 - val_loss: 0.8513\n",
      "Epoch 9/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8001 - loss: 0.7539 - val_accuracy: 0.7699 - val_loss: 0.7892\n",
      "Epoch 10/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8164 - loss: 0.6872 - val_accuracy: 0.7863 - val_loss: 0.7354\n",
      "Epoch 11/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8339 - loss: 0.6295 - val_accuracy: 0.7993 - val_loss: 0.6878\n",
      "Epoch 12/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8437 - loss: 0.5788 - val_accuracy: 0.8133 - val_loss: 0.6453\n",
      "Epoch 13/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8552 - loss: 0.5339 - val_accuracy: 0.8222 - val_loss: 0.6074\n",
      "Epoch 14/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8681 - loss: 0.4937 - val_accuracy: 0.8328 - val_loss: 0.5734\n",
      "Epoch 15/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8777 - loss: 0.4577 - val_accuracy: 0.8414 - val_loss: 0.5430\n",
      "Epoch 16/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8878 - loss: 0.4250 - val_accuracy: 0.8458 - val_loss: 0.5156\n",
      "Epoch 17/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8971 - loss: 0.3953 - val_accuracy: 0.8547 - val_loss: 0.4909\n",
      "Epoch 18/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9054 - loss: 0.3681 - val_accuracy: 0.8581 - val_loss: 0.4686\n",
      "Epoch 19/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9129 - loss: 0.3431 - val_accuracy: 0.8646 - val_loss: 0.4483\n",
      "Epoch 20/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9191 - loss: 0.3200 - val_accuracy: 0.8728 - val_loss: 0.4299\n",
      "Epoch 21/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9234 - loss: 0.2987 - val_accuracy: 0.8790 - val_loss: 0.4130\n",
      "Epoch 22/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9273 - loss: 0.2789 - val_accuracy: 0.8838 - val_loss: 0.3977\n",
      "Epoch 23/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9313 - loss: 0.2606 - val_accuracy: 0.8885 - val_loss: 0.3837\n",
      "Epoch 24/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9392 - loss: 0.2436 - val_accuracy: 0.8923 - val_loss: 0.3709\n",
      "Epoch 25/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9468 - loss: 0.2278 - val_accuracy: 0.8954 - val_loss: 0.3593\n",
      "Epoch 26/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9542 - loss: 0.2131 - val_accuracy: 0.8991 - val_loss: 0.3487\n",
      "Epoch 27/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9607 - loss: 0.1994 - val_accuracy: 0.9015 - val_loss: 0.3392\n",
      "Epoch 28/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9642 - loss: 0.1867 - val_accuracy: 0.9053 - val_loss: 0.3304\n",
      "Epoch 29/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9673 - loss: 0.1748 - val_accuracy: 0.9084 - val_loss: 0.3225\n",
      "Epoch 30/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9714 - loss: 0.1638 - val_accuracy: 0.9108 - val_loss: 0.3153\n",
      "Epoch 31/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9724 - loss: 0.1535 - val_accuracy: 0.9142 - val_loss: 0.3086\n",
      "Epoch 32/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9753 - loss: 0.1439 - val_accuracy: 0.9152 - val_loss: 0.3026\n",
      "Epoch 33/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9780 - loss: 0.1348 - val_accuracy: 0.9169 - val_loss: 0.2971\n",
      "Epoch 34/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9813 - loss: 0.1264 - val_accuracy: 0.9173 - val_loss: 0.2920\n",
      "Epoch 35/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9828 - loss: 0.1185 - val_accuracy: 0.9173 - val_loss: 0.2873\n",
      "Epoch 36/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9854 - loss: 0.1111 - val_accuracy: 0.9183 - val_loss: 0.2831\n",
      "Epoch 37/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9875 - loss: 0.1041 - val_accuracy: 0.9186 - val_loss: 0.2792\n",
      "Epoch 38/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9902 - loss: 0.0975 - val_accuracy: 0.9190 - val_loss: 0.2756\n",
      "Epoch 39/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9911 - loss: 0.0914 - val_accuracy: 0.9203 - val_loss: 0.2723\n",
      "Epoch 40/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9923 - loss: 0.0856 - val_accuracy: 0.9214 - val_loss: 0.2692\n",
      "Epoch 41/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9930 - loss: 0.0802 - val_accuracy: 0.9217 - val_loss: 0.2664\n",
      "Epoch 42/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9936 - loss: 0.0750 - val_accuracy: 0.9217 - val_loss: 0.2638\n",
      "Epoch 43/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9958 - loss: 0.0702 - val_accuracy: 0.9221 - val_loss: 0.2614\n",
      "Epoch 44/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9961 - loss: 0.0657 - val_accuracy: 0.9227 - val_loss: 0.2592\n",
      "Epoch 45/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9964 - loss: 0.0615 - val_accuracy: 0.9241 - val_loss: 0.2572\n",
      "Epoch 46/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9973 - loss: 0.0575 - val_accuracy: 0.9248 - val_loss: 0.2554\n",
      "Epoch 47/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0537 - val_accuracy: 0.9265 - val_loss: 0.2538\n",
      "Epoch 48/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0502 - val_accuracy: 0.9265 - val_loss: 0.2523\n",
      "Epoch 49/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9986 - loss: 0.0468 - val_accuracy: 0.9258 - val_loss: 0.2511\n",
      "Epoch 50/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9991 - loss: 0.0437 - val_accuracy: 0.9265 - val_loss: 0.2501\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "prueba_12: \n",
      "Epoch 1/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1820 - loss: 2.7793 - val_accuracy: 0.4855 - val_loss: 2.1188\n",
      "Epoch 2/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5956 - loss: 1.8744 - val_accuracy: 0.7788 - val_loss: 1.2519\n",
      "Epoch 3/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8071 - loss: 1.1027 - val_accuracy: 0.8390 - val_loss: 0.8151\n",
      "Epoch 4/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8747 - loss: 0.7010 - val_accuracy: 0.8745 - val_loss: 0.5885\n",
      "Epoch 5/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9133 - loss: 0.4846 - val_accuracy: 0.8971 - val_loss: 0.4550\n",
      "Epoch 6/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9415 - loss: 0.3545 - val_accuracy: 0.9145 - val_loss: 0.3679\n",
      "Epoch 7/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9567 - loss: 0.2692 - val_accuracy: 0.9275 - val_loss: 0.3072\n",
      "Epoch 8/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9681 - loss: 0.2095 - val_accuracy: 0.9385 - val_loss: 0.2629\n",
      "Epoch 9/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9764 - loss: 0.1654 - val_accuracy: 0.9470 - val_loss: 0.2293\n",
      "Epoch 10/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9815 - loss: 0.1317 - val_accuracy: 0.9525 - val_loss: 0.2031\n",
      "Epoch 11/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9875 - loss: 0.1052 - val_accuracy: 0.9569 - val_loss: 0.1820\n",
      "Epoch 12/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9921 - loss: 0.0839 - val_accuracy: 0.9603 - val_loss: 0.1647\n",
      "Epoch 13/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9945 - loss: 0.0667 - val_accuracy: 0.9614 - val_loss: 0.1505\n",
      "Epoch 14/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9973 - loss: 0.0528 - val_accuracy: 0.9631 - val_loss: 0.1387\n",
      "Epoch 15/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9988 - loss: 0.0417 - val_accuracy: 0.9648 - val_loss: 0.1287\n",
      "Epoch 16/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9988 - loss: 0.0329 - val_accuracy: 0.9675 - val_loss: 0.1203\n",
      "Epoch 17/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9993 - loss: 0.0258 - val_accuracy: 0.9689 - val_loss: 0.1132\n",
      "Epoch 18/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0202 - val_accuracy: 0.9696 - val_loss: 0.1072\n",
      "Epoch 19/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0157 - val_accuracy: 0.9703 - val_loss: 0.1021\n",
      "Epoch 20/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0122 - val_accuracy: 0.9720 - val_loss: 0.0979\n",
      "Epoch 21/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.9723 - val_loss: 0.0944\n",
      "Epoch 22/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.9733 - val_loss: 0.0915\n",
      "Epoch 23/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.9740 - val_loss: 0.0891\n",
      "Epoch 24/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9744 - val_loss: 0.0872\n",
      "Epoch 25/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9740 - val_loss: 0.0856\n",
      "Epoch 26/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9744 - val_loss: 0.0844\n",
      "Epoch 27/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9750 - val_loss: 0.0836\n",
      "Epoch 28/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9750 - val_loss: 0.0830\n",
      "Epoch 29/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9757 - val_loss: 0.0827\n",
      "Epoch 30/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.1818e-04 - val_accuracy: 0.9757 - val_loss: 0.0826\n",
      "Epoch 31/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.0270e-04 - val_accuracy: 0.9761 - val_loss: 0.0827\n",
      "Epoch 32/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.3715e-04 - val_accuracy: 0.9757 - val_loss: 0.0830\n",
      "Epoch 33/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.1021e-04 - val_accuracy: 0.9764 - val_loss: 0.0834\n",
      "Epoch 34/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.1301e-04 - val_accuracy: 0.9768 - val_loss: 0.0840\n",
      "Epoch 35/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.3867e-04 - val_accuracy: 0.9778 - val_loss: 0.0847\n",
      "Epoch 36/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.8187e-04 - val_accuracy: 0.9785 - val_loss: 0.0855\n",
      "Epoch 37/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.3851e-04 - val_accuracy: 0.9785 - val_loss: 0.0863\n",
      "Epoch 38/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.0542e-04 - val_accuracy: 0.9778 - val_loss: 0.0872\n",
      "Epoch 39/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.0202e-05 - val_accuracy: 0.9778 - val_loss: 0.0882\n",
      "Epoch 40/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.0989e-05 - val_accuracy: 0.9781 - val_loss: 0.0892\n",
      "Epoch 41/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.6366e-05 - val_accuracy: 0.9785 - val_loss: 0.0904\n",
      "Epoch 42/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.5239e-05 - val_accuracy: 0.9785 - val_loss: 0.0915\n",
      "Epoch 43/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.6783e-05 - val_accuracy: 0.9785 - val_loss: 0.0927\n",
      "Epoch 44/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.0363e-05 - val_accuracy: 0.9788 - val_loss: 0.0940\n",
      "Epoch 45/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.5487e-05 - val_accuracy: 0.9778 - val_loss: 0.0953\n",
      "Epoch 46/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.1787e-05 - val_accuracy: 0.9774 - val_loss: 0.0966\n",
      "Epoch 47/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.9836e-06 - val_accuracy: 0.9771 - val_loss: 0.0980\n",
      "Epoch 48/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.8567e-06 - val_accuracy: 0.9771 - val_loss: 0.0994\n",
      "Epoch 49/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.2454e-06 - val_accuracy: 0.9774 - val_loss: 0.1007\n",
      "Epoch 50/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.0240e-06 - val_accuracy: 0.9774 - val_loss: 0.1021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "prueba_13: \n",
      "Epoch 1/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1418 - loss: 2.8276 - val_accuracy: 0.3983 - val_loss: 2.3116\n",
      "Epoch 2/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5245 - loss: 2.0617 - val_accuracy: 0.6885 - val_loss: 1.4877\n",
      "Epoch 3/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7375 - loss: 1.3192 - val_accuracy: 0.7918 - val_loss: 1.0259\n",
      "Epoch 4/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8285 - loss: 0.8960 - val_accuracy: 0.8383 - val_loss: 0.7495\n",
      "Epoch 5/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8823 - loss: 0.6372 - val_accuracy: 0.8776 - val_loss: 0.5755\n",
      "Epoch 6/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9160 - loss: 0.4729 - val_accuracy: 0.9012 - val_loss: 0.4612\n",
      "Epoch 7/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9365 - loss: 0.3641 - val_accuracy: 0.9152 - val_loss: 0.3821\n",
      "Epoch 8/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9521 - loss: 0.2880 - val_accuracy: 0.9231 - val_loss: 0.3245\n",
      "Epoch 9/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9618 - loss: 0.2319 - val_accuracy: 0.9313 - val_loss: 0.2811\n",
      "Epoch 10/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9673 - loss: 0.1889 - val_accuracy: 0.9354 - val_loss: 0.2474\n",
      "Epoch 11/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9721 - loss: 0.1550 - val_accuracy: 0.9436 - val_loss: 0.2207\n",
      "Epoch 12/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9795 - loss: 0.1277 - val_accuracy: 0.9477 - val_loss: 0.1991\n",
      "Epoch 13/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9857 - loss: 0.1055 - val_accuracy: 0.9528 - val_loss: 0.1816\n",
      "Epoch 14/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9898 - loss: 0.0873 - val_accuracy: 0.9579 - val_loss: 0.1674\n",
      "Epoch 15/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9923 - loss: 0.0723 - val_accuracy: 0.9597 - val_loss: 0.1556\n",
      "Epoch 16/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9952 - loss: 0.0598 - val_accuracy: 0.9617 - val_loss: 0.1459\n",
      "Epoch 17/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9974 - loss: 0.0494 - val_accuracy: 0.9634 - val_loss: 0.1377\n",
      "Epoch 18/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0406 - val_accuracy: 0.9641 - val_loss: 0.1307\n",
      "Epoch 19/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0333 - val_accuracy: 0.9655 - val_loss: 0.1248\n",
      "Epoch 20/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9995 - loss: 0.0273 - val_accuracy: 0.9672 - val_loss: 0.1198\n",
      "Epoch 21/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0222 - val_accuracy: 0.9689 - val_loss: 0.1156\n",
      "Epoch 22/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0181 - val_accuracy: 0.9692 - val_loss: 0.1121\n",
      "Epoch 23/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0147 - val_accuracy: 0.9692 - val_loss: 0.1093\n",
      "Epoch 24/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0119 - val_accuracy: 0.9696 - val_loss: 0.1070\n",
      "Epoch 25/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.9706 - val_loss: 0.1053\n",
      "Epoch 26/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.9709 - val_loss: 0.1039\n",
      "Epoch 27/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.9706 - val_loss: 0.1030\n",
      "Epoch 28/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9713 - val_loss: 0.1023\n",
      "Epoch 29/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9709 - val_loss: 0.1020\n",
      "Epoch 30/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9713 - val_loss: 0.1019\n",
      "Epoch 31/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9706 - val_loss: 0.1020\n",
      "Epoch 32/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9713 - val_loss: 0.1023\n",
      "Epoch 33/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9703 - val_loss: 0.1028\n",
      "Epoch 34/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9713 - val_loss: 0.1034\n",
      "Epoch 35/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9723 - val_loss: 0.1042\n",
      "Epoch 36/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.4842e-04 - val_accuracy: 0.9723 - val_loss: 0.1050\n",
      "Epoch 37/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.7457e-04 - val_accuracy: 0.9720 - val_loss: 0.1060\n",
      "Epoch 38/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.3564e-04 - val_accuracy: 0.9720 - val_loss: 0.1071\n",
      "Epoch 39/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.2479e-04 - val_accuracy: 0.9713 - val_loss: 0.1083\n",
      "Epoch 40/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.3648e-04 - val_accuracy: 0.9709 - val_loss: 0.1095\n",
      "Epoch 41/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.6624e-04 - val_accuracy: 0.9709 - val_loss: 0.1109\n",
      "Epoch 42/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.1044e-04 - val_accuracy: 0.9709 - val_loss: 0.1123\n",
      "Epoch 43/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.6618e-04 - val_accuracy: 0.9709 - val_loss: 0.1138\n",
      "Epoch 44/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.3112e-04 - val_accuracy: 0.9706 - val_loss: 0.1154\n",
      "Epoch 45/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.0338e-04 - val_accuracy: 0.9716 - val_loss: 0.1170\n",
      "Epoch 46/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.1446e-05 - val_accuracy: 0.9716 - val_loss: 0.1187\n",
      "Epoch 47/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.4133e-05 - val_accuracy: 0.9716 - val_loss: 0.1204\n",
      "Epoch 48/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.0476e-05 - val_accuracy: 0.9716 - val_loss: 0.1222\n",
      "Epoch 49/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.9712e-05 - val_accuracy: 0.9726 - val_loss: 0.1239\n",
      "Epoch 50/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.1233e-05 - val_accuracy: 0.9723 - val_loss: 0.1257\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "prueba_14: \n",
      "Epoch 1/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1243 - loss: 2.8433 - val_accuracy: 0.3679 - val_loss: 2.4886\n",
      "Epoch 2/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4764 - loss: 2.2956 - val_accuracy: 0.5768 - val_loss: 1.8223\n",
      "Epoch 3/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6517 - loss: 1.6394 - val_accuracy: 0.6903 - val_loss: 1.3422\n",
      "Epoch 4/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7443 - loss: 1.1934 - val_accuracy: 0.7504 - val_loss: 1.0452\n",
      "Epoch 5/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7979 - loss: 0.9118 - val_accuracy: 0.7949 - val_loss: 0.8503\n",
      "Epoch 6/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8446 - loss: 0.7240 - val_accuracy: 0.8294 - val_loss: 0.7176\n",
      "Epoch 7/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8723 - loss: 0.5934 - val_accuracy: 0.8503 - val_loss: 0.6225\n",
      "Epoch 8/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8950 - loss: 0.4977 - val_accuracy: 0.8643 - val_loss: 0.5509\n",
      "Epoch 9/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9146 - loss: 0.4242 - val_accuracy: 0.8762 - val_loss: 0.4949\n",
      "Epoch 10/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9290 - loss: 0.3655 - val_accuracy: 0.8855 - val_loss: 0.4499\n",
      "Epoch 11/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9391 - loss: 0.3174 - val_accuracy: 0.8944 - val_loss: 0.4129\n",
      "Epoch 12/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9471 - loss: 0.2772 - val_accuracy: 0.9026 - val_loss: 0.3821\n",
      "Epoch 13/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9522 - loss: 0.2432 - val_accuracy: 0.9074 - val_loss: 0.3562\n",
      "Epoch 14/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9605 - loss: 0.2140 - val_accuracy: 0.9128 - val_loss: 0.3341\n",
      "Epoch 15/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9649 - loss: 0.1885 - val_accuracy: 0.9149 - val_loss: 0.3150\n",
      "Epoch 16/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9702 - loss: 0.1662 - val_accuracy: 0.9173 - val_loss: 0.2981\n",
      "Epoch 17/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9752 - loss: 0.1464 - val_accuracy: 0.9214 - val_loss: 0.2833\n",
      "Epoch 18/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9797 - loss: 0.1287 - val_accuracy: 0.9244 - val_loss: 0.2701\n",
      "Epoch 19/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9862 - loss: 0.1129 - val_accuracy: 0.9272 - val_loss: 0.2584\n",
      "Epoch 20/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9904 - loss: 0.0986 - val_accuracy: 0.9296 - val_loss: 0.2481\n",
      "Epoch 21/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9924 - loss: 0.0857 - val_accuracy: 0.9303 - val_loss: 0.2389\n",
      "Epoch 22/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9935 - loss: 0.0744 - val_accuracy: 0.9309 - val_loss: 0.2307\n",
      "Epoch 23/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9959 - loss: 0.0644 - val_accuracy: 0.9333 - val_loss: 0.2236\n",
      "Epoch 24/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9967 - loss: 0.0558 - val_accuracy: 0.9354 - val_loss: 0.2172\n",
      "Epoch 25/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9986 - loss: 0.0482 - val_accuracy: 0.9371 - val_loss: 0.2115\n",
      "Epoch 26/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9993 - loss: 0.0416 - val_accuracy: 0.9391 - val_loss: 0.2064\n",
      "Epoch 27/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0358 - val_accuracy: 0.9395 - val_loss: 0.2017\n",
      "Epoch 28/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0308 - val_accuracy: 0.9391 - val_loss: 0.1976\n",
      "Epoch 29/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0265 - val_accuracy: 0.9391 - val_loss: 0.1939\n",
      "Epoch 30/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0228 - val_accuracy: 0.9402 - val_loss: 0.1907\n",
      "Epoch 31/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0195 - val_accuracy: 0.9415 - val_loss: 0.1879\n",
      "Epoch 32/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0167 - val_accuracy: 0.9429 - val_loss: 0.1854\n",
      "Epoch 33/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0143 - val_accuracy: 0.9432 - val_loss: 0.1833\n",
      "Epoch 34/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0122 - val_accuracy: 0.9432 - val_loss: 0.1816\n",
      "Epoch 35/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.9436 - val_loss: 0.1801\n",
      "Epoch 36/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.9467 - val_loss: 0.1790\n",
      "Epoch 37/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.9467 - val_loss: 0.1781\n",
      "Epoch 38/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.9460 - val_loss: 0.1775\n",
      "Epoch 39/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9467 - val_loss: 0.1772\n",
      "Epoch 40/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9480 - val_loss: 0.1772\n",
      "Epoch 41/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9494 - val_loss: 0.1774\n",
      "Epoch 42/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9487 - val_loss: 0.1779\n",
      "Epoch 43/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9494 - val_loss: 0.1786\n",
      "Epoch 44/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9491 - val_loss: 0.1795\n",
      "Epoch 45/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9484 - val_loss: 0.1807\n",
      "Epoch 46/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9480 - val_loss: 0.1820\n",
      "Epoch 47/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9484 - val_loss: 0.1835\n",
      "Epoch 48/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9487 - val_loss: 0.1852\n",
      "Epoch 49/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.4788e-04 - val_accuracy: 0.9491 - val_loss: 0.1871\n",
      "Epoch 50/50\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.9192e-04 - val_accuracy: 0.9491 - val_loss: 0.1890\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prueba_4_1': 0.5,\n",
       " 'prueba_12': 0.4666666666666667,\n",
       " 'prueba_13': 0.7333333333333333,\n",
       " 'prueba_14': 0.7333333333333333}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PRUEBAS CON epochs 500 # SI TARDA MUCHO PROBAR CON 250...\n",
    "resutados = {}\n",
    "modelos_500 = {}\n",
    "for prueba, params in pruebas.items():\n",
    "    print(f\"{prueba}: \")\n",
    "    resultado, modelo = run_keras_model(n_pca=params.get('n_pca'), \n",
    "                    excl_n_prim_comp=params.get('excl_n_prim_comp'), \n",
    "                    nueronas_layer_1=params.get('nueronas_layer_1'),\n",
    "                    nueronas_layer_2=params.get('nueronas_layer_2'),\n",
    "                    n_epochs=50, # NO TOMA EL QUE DEFINIMOS EN PRUEBAS<<<<<<<<<<<<--------- epochs cambiar aca\n",
    "                    imagenes=imagenes_all,\n",
    "                    nombres=nombres_all,\n",
    "                    nuevas_imagenes=new_images,\n",
    "                    nuevos_nombres=nombres_new\n",
    "                    )\n",
    "    resutados[prueba]=resultado\n",
    "    modelos_500[prueba]=modelo\n",
    "resutados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prueba_4_1: \n",
      "Epoch 1/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1052 - loss: 2.8615 - val_accuracy: 0.2708 - val_loss: 2.5692\n",
      "Epoch 2/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3585 - loss: 2.4368 - val_accuracy: 0.5060 - val_loss: 2.0292\n",
      "Epoch 3/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5321 - loss: 1.9004 - val_accuracy: 0.6065 - val_loss: 1.6085\n",
      "Epoch 4/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6248 - loss: 1.4971 - val_accuracy: 0.6674 - val_loss: 1.3241\n",
      "Epoch 5/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6896 - loss: 1.2223 - val_accuracy: 0.7026 - val_loss: 1.1359\n",
      "Epoch 6/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7368 - loss: 1.0372 - val_accuracy: 0.7296 - val_loss: 1.0053\n",
      "Epoch 7/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7608 - loss: 0.9058 - val_accuracy: 0.7491 - val_loss: 0.9063\n",
      "Epoch 8/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7829 - loss: 0.8050 - val_accuracy: 0.7682 - val_loss: 0.8261\n",
      "Epoch 9/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8062 - loss: 0.7235 - val_accuracy: 0.7863 - val_loss: 0.7590\n",
      "Epoch 10/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8271 - loss: 0.6554 - val_accuracy: 0.8031 - val_loss: 0.7021\n",
      "Epoch 11/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8437 - loss: 0.5975 - val_accuracy: 0.8178 - val_loss: 0.6534\n",
      "Epoch 12/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8584 - loss: 0.5476 - val_accuracy: 0.8287 - val_loss: 0.6115\n",
      "Epoch 13/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8718 - loss: 0.5040 - val_accuracy: 0.8376 - val_loss: 0.5750\n",
      "Epoch 14/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8833 - loss: 0.4655 - val_accuracy: 0.8462 - val_loss: 0.5430\n",
      "Epoch 15/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8884 - loss: 0.4311 - val_accuracy: 0.8564 - val_loss: 0.5147\n",
      "Epoch 16/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8960 - loss: 0.4002 - val_accuracy: 0.8643 - val_loss: 0.4894\n",
      "Epoch 17/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9055 - loss: 0.3721 - val_accuracy: 0.8680 - val_loss: 0.4669\n",
      "Epoch 18/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9109 - loss: 0.3466 - val_accuracy: 0.8711 - val_loss: 0.4467\n",
      "Epoch 19/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9183 - loss: 0.3233 - val_accuracy: 0.8749 - val_loss: 0.4285\n",
      "Epoch 20/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9248 - loss: 0.3019 - val_accuracy: 0.8786 - val_loss: 0.4121\n",
      "Epoch 21/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9303 - loss: 0.2822 - val_accuracy: 0.8841 - val_loss: 0.3973\n",
      "Epoch 22/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9361 - loss: 0.2640 - val_accuracy: 0.8882 - val_loss: 0.3840\n",
      "Epoch 23/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9401 - loss: 0.2473 - val_accuracy: 0.8913 - val_loss: 0.3718\n",
      "Epoch 24/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.2318 - val_accuracy: 0.8944 - val_loss: 0.3608\n",
      "Epoch 25/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9498 - loss: 0.2173 - val_accuracy: 0.8961 - val_loss: 0.3507\n",
      "Epoch 26/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9560 - loss: 0.2039 - val_accuracy: 0.8991 - val_loss: 0.3415\n",
      "Epoch 27/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9602 - loss: 0.1913 - val_accuracy: 0.9015 - val_loss: 0.3331\n",
      "Epoch 28/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9642 - loss: 0.1795 - val_accuracy: 0.9056 - val_loss: 0.3254\n",
      "Epoch 29/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9680 - loss: 0.1685 - val_accuracy: 0.9067 - val_loss: 0.3184\n",
      "Epoch 30/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9728 - loss: 0.1581 - val_accuracy: 0.9077 - val_loss: 0.3119\n",
      "Epoch 31/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9753 - loss: 0.1483 - val_accuracy: 0.9094 - val_loss: 0.3060\n",
      "Epoch 32/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9789 - loss: 0.1391 - val_accuracy: 0.9104 - val_loss: 0.3005\n",
      "Epoch 33/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9815 - loss: 0.1305 - val_accuracy: 0.9135 - val_loss: 0.2955\n",
      "Epoch 34/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9831 - loss: 0.1224 - val_accuracy: 0.9135 - val_loss: 0.2909\n",
      "Epoch 35/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9852 - loss: 0.1148 - val_accuracy: 0.9135 - val_loss: 0.2866\n",
      "Epoch 36/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9877 - loss: 0.1077 - val_accuracy: 0.9145 - val_loss: 0.2827\n",
      "Epoch 37/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9892 - loss: 0.1010 - val_accuracy: 0.9149 - val_loss: 0.2792\n",
      "Epoch 38/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9902 - loss: 0.0948 - val_accuracy: 0.9159 - val_loss: 0.2759\n",
      "Epoch 39/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9918 - loss: 0.0889 - val_accuracy: 0.9159 - val_loss: 0.2730\n",
      "Epoch 40/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9928 - loss: 0.0833 - val_accuracy: 0.9176 - val_loss: 0.2703\n",
      "Epoch 41/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9932 - loss: 0.0781 - val_accuracy: 0.9183 - val_loss: 0.2679\n",
      "Epoch 42/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9939 - loss: 0.0733 - val_accuracy: 0.9190 - val_loss: 0.2658\n",
      "Epoch 43/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9950 - loss: 0.0687 - val_accuracy: 0.9200 - val_loss: 0.2639\n",
      "Epoch 44/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9954 - loss: 0.0643 - val_accuracy: 0.9207 - val_loss: 0.2623\n",
      "Epoch 45/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9955 - loss: 0.0603 - val_accuracy: 0.9210 - val_loss: 0.2609\n",
      "Epoch 46/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9963 - loss: 0.0564 - val_accuracy: 0.9224 - val_loss: 0.2597\n",
      "Epoch 47/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9968 - loss: 0.0529 - val_accuracy: 0.9231 - val_loss: 0.2587\n",
      "Epoch 48/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0495 - val_accuracy: 0.9231 - val_loss: 0.2580\n",
      "Epoch 49/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9979 - loss: 0.0463 - val_accuracy: 0.9234 - val_loss: 0.2574\n",
      "Epoch 50/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9988 - loss: 0.0434 - val_accuracy: 0.9255 - val_loss: 0.2571\n",
      "Epoch 51/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9988 - loss: 0.0406 - val_accuracy: 0.9268 - val_loss: 0.2569\n",
      "Epoch 52/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9990 - loss: 0.0379 - val_accuracy: 0.9279 - val_loss: 0.2569\n",
      "Epoch 53/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9992 - loss: 0.0355 - val_accuracy: 0.9285 - val_loss: 0.2570\n",
      "Epoch 54/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0331 - val_accuracy: 0.9268 - val_loss: 0.2573\n",
      "Epoch 55/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0309 - val_accuracy: 0.9272 - val_loss: 0.2577\n",
      "Epoch 56/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0288 - val_accuracy: 0.9268 - val_loss: 0.2583\n",
      "Epoch 57/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0269 - val_accuracy: 0.9282 - val_loss: 0.2589\n",
      "Epoch 58/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 0.0250 - val_accuracy: 0.9282 - val_loss: 0.2597\n",
      "Epoch 59/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 0.0233 - val_accuracy: 0.9282 - val_loss: 0.2605\n",
      "Epoch 60/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 0.0217 - val_accuracy: 0.9282 - val_loss: 0.2615\n",
      "Epoch 61/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 0.0202 - val_accuracy: 0.9272 - val_loss: 0.2625\n",
      "Epoch 62/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0188 - val_accuracy: 0.9272 - val_loss: 0.2635\n",
      "Epoch 63/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0175 - val_accuracy: 0.9275 - val_loss: 0.2647\n",
      "Epoch 64/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.9265 - val_loss: 0.2658\n",
      "Epoch 65/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0151 - val_accuracy: 0.9268 - val_loss: 0.2671\n",
      "Epoch 66/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0140 - val_accuracy: 0.9272 - val_loss: 0.2684\n",
      "Epoch 67/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 0.9272 - val_loss: 0.2698\n",
      "Epoch 68/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0120 - val_accuracy: 0.9275 - val_loss: 0.2712\n",
      "Epoch 69/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 0.9268 - val_loss: 0.2727\n",
      "Epoch 70/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 0.9258 - val_loss: 0.2743\n",
      "Epoch 71/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0096 - val_accuracy: 0.9268 - val_loss: 0.2760\n",
      "Epoch 72/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 0.9272 - val_loss: 0.2777\n",
      "Epoch 73/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 0.9268 - val_loss: 0.2795\n",
      "Epoch 74/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 0.9275 - val_loss: 0.2813\n",
      "Epoch 75/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.9279 - val_loss: 0.2833\n",
      "Epoch 76/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.9275 - val_loss: 0.2853\n",
      "Epoch 77/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.9272 - val_loss: 0.2874\n",
      "Epoch 78/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9265 - val_loss: 0.2896\n",
      "Epoch 79/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9272 - val_loss: 0.2918\n",
      "Epoch 80/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9272 - val_loss: 0.2941\n",
      "Epoch 81/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9282 - val_loss: 0.2964\n",
      "Epoch 82/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9285 - val_loss: 0.2988\n",
      "Epoch 83/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9285 - val_loss: 0.3012\n",
      "Epoch 84/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9285 - val_loss: 0.3037\n",
      "Epoch 85/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9292 - val_loss: 0.3062\n",
      "Epoch 86/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9292 - val_loss: 0.3088\n",
      "Epoch 87/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9303 - val_loss: 0.3114\n",
      "Epoch 88/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9309 - val_loss: 0.3140\n",
      "Epoch 89/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9313 - val_loss: 0.3167\n",
      "Epoch 90/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9309 - val_loss: 0.3194\n",
      "Epoch 91/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9303 - val_loss: 0.3221\n",
      "Epoch 92/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9296 - val_loss: 0.3249\n",
      "Epoch 93/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9299 - val_loss: 0.3278\n",
      "Epoch 94/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9303 - val_loss: 0.3307\n",
      "Epoch 95/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9309 - val_loss: 0.3336\n",
      "Epoch 96/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9313 - val_loss: 0.3366\n",
      "Epoch 97/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9320 - val_loss: 0.3396\n",
      "Epoch 98/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9316 - val_loss: 0.3426\n",
      "Epoch 99/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.5129e-04 - val_accuracy: 0.9320 - val_loss: 0.3457\n",
      "Epoch 100/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.7248e-04 - val_accuracy: 0.9316 - val_loss: 0.3489\n",
      "Epoch 101/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.0007e-04 - val_accuracy: 0.9326 - val_loss: 0.3520\n",
      "Epoch 102/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.3355e-04 - val_accuracy: 0.9320 - val_loss: 0.3552\n",
      "Epoch 103/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.7246e-04 - val_accuracy: 0.9320 - val_loss: 0.3585\n",
      "Epoch 104/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.1636e-04 - val_accuracy: 0.9320 - val_loss: 0.3618\n",
      "Epoch 105/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.6485e-04 - val_accuracy: 0.9320 - val_loss: 0.3651\n",
      "Epoch 106/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.1756e-04 - val_accuracy: 0.9323 - val_loss: 0.3684\n",
      "Epoch 107/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.7415e-04 - val_accuracy: 0.9320 - val_loss: 0.3718\n",
      "Epoch 108/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.3431e-04 - val_accuracy: 0.9320 - val_loss: 0.3751\n",
      "Epoch 109/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.9776e-04 - val_accuracy: 0.9309 - val_loss: 0.3786\n",
      "Epoch 110/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.6421e-04 - val_accuracy: 0.9306 - val_loss: 0.3820\n",
      "Epoch 111/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.3344e-04 - val_accuracy: 0.9309 - val_loss: 0.3855\n",
      "Epoch 112/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.0522e-04 - val_accuracy: 0.9303 - val_loss: 0.3890\n",
      "Epoch 113/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.7935e-04 - val_accuracy: 0.9303 - val_loss: 0.3925\n",
      "Epoch 114/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.5561e-04 - val_accuracy: 0.9306 - val_loss: 0.3961\n",
      "Epoch 115/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.3388e-04 - val_accuracy: 0.9303 - val_loss: 0.3997\n",
      "Epoch 116/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.1391e-04 - val_accuracy: 0.9299 - val_loss: 0.4034\n",
      "Epoch 117/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.9569e-04 - val_accuracy: 0.9303 - val_loss: 0.4069\n",
      "Epoch 118/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.7890e-04 - val_accuracy: 0.9299 - val_loss: 0.4108\n",
      "Epoch 119/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.6369e-04 - val_accuracy: 0.9292 - val_loss: 0.4142\n",
      "Epoch 120/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.4956e-04 - val_accuracy: 0.9285 - val_loss: 0.4185\n",
      "Epoch 121/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.3703e-04 - val_accuracy: 0.9292 - val_loss: 0.4214\n",
      "Epoch 122/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.2499e-04 - val_accuracy: 0.9285 - val_loss: 0.4264\n",
      "Epoch 123/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.1462e-04 - val_accuracy: 0.9289 - val_loss: 0.4288\n",
      "Epoch 124/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.0430e-04 - val_accuracy: 0.9285 - val_loss: 0.4341\n",
      "Epoch 125/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.5470e-05 - val_accuracy: 0.9279 - val_loss: 0.4366\n",
      "Epoch 126/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.7106e-05 - val_accuracy: 0.9272 - val_loss: 0.4419\n",
      "Epoch 127/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.9930e-05 - val_accuracy: 0.9268 - val_loss: 0.4442\n",
      "Epoch 128/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 7.2718e-05 - val_accuracy: 0.9272 - val_loss: 0.4493\n",
      "Epoch 129/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.6288e-05 - val_accuracy: 0.9265 - val_loss: 0.4525\n",
      "Epoch 130/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.0603e-05 - val_accuracy: 0.9272 - val_loss: 0.4568\n",
      "Epoch 131/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.5280e-05 - val_accuracy: 0.9268 - val_loss: 0.4604\n",
      "Epoch 132/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.0664e-05 - val_accuracy: 0.9268 - val_loss: 0.4648\n",
      "Epoch 133/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.6247e-05 - val_accuracy: 0.9268 - val_loss: 0.4678\n",
      "Epoch 134/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.2282e-05 - val_accuracy: 0.9279 - val_loss: 0.4727\n",
      "Epoch 135/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.8308e-05 - val_accuracy: 0.9268 - val_loss: 0.4757\n",
      "Epoch 136/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.5142e-05 - val_accuracy: 0.9279 - val_loss: 0.4807\n",
      "Epoch 137/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.2010e-05 - val_accuracy: 0.9275 - val_loss: 0.4831\n",
      "Epoch 138/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.9321e-05 - val_accuracy: 0.9285 - val_loss: 0.4888\n",
      "Epoch 139/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.6639e-05 - val_accuracy: 0.9282 - val_loss: 0.4911\n",
      "Epoch 140/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.4393e-05 - val_accuracy: 0.9285 - val_loss: 0.4965\n",
      "Epoch 141/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.2222e-05 - val_accuracy: 0.9279 - val_loss: 0.4988\n",
      "Epoch 142/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.0403e-05 - val_accuracy: 0.9285 - val_loss: 0.5045\n",
      "Epoch 143/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.8448e-05 - val_accuracy: 0.9279 - val_loss: 0.5072\n",
      "Epoch 144/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.6928e-05 - val_accuracy: 0.9292 - val_loss: 0.5120\n",
      "Epoch 145/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.5385e-05 - val_accuracy: 0.9285 - val_loss: 0.5148\n",
      "Epoch 146/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.4213e-05 - val_accuracy: 0.9285 - val_loss: 0.5204\n",
      "Epoch 147/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.2926e-05 - val_accuracy: 0.9289 - val_loss: 0.5228\n",
      "Epoch 148/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 978us/step - accuracy: 1.0000 - loss: 1.1854e-05 - val_accuracy: 0.9282 - val_loss: 0.5280\n",
      "Epoch 149/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 961us/step - accuracy: 1.0000 - loss: 1.0706e-05 - val_accuracy: 0.9282 - val_loss: 0.5305\n",
      "Epoch 150/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 890us/step - accuracy: 1.0000 - loss: 9.9683e-06 - val_accuracy: 0.9275 - val_loss: 0.5360\n",
      "Epoch 151/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 1.0000 - loss: 9.0224e-06 - val_accuracy: 0.9279 - val_loss: 0.5391\n",
      "Epoch 152/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 1.0000 - loss: 8.2829e-06 - val_accuracy: 0.9272 - val_loss: 0.5436\n",
      "Epoch 153/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - accuracy: 1.0000 - loss: 7.5298e-06 - val_accuracy: 0.9268 - val_loss: 0.5462\n",
      "Epoch 154/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - accuracy: 1.0000 - loss: 7.0392e-06 - val_accuracy: 0.9268 - val_loss: 0.5516\n",
      "Epoch 155/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 1.0000 - loss: 6.3382e-06 - val_accuracy: 0.9268 - val_loss: 0.5554\n",
      "Epoch 156/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 1.0000 - loss: 5.8179e-06 - val_accuracy: 0.9265 - val_loss: 0.5582\n",
      "Epoch 157/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 813us/step - accuracy: 1.0000 - loss: 5.2991e-06 - val_accuracy: 0.9262 - val_loss: 0.5625\n",
      "Epoch 158/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - accuracy: 1.0000 - loss: 4.8894e-06 - val_accuracy: 0.9258 - val_loss: 0.5667\n",
      "Epoch 159/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 1.0000 - loss: 4.5204e-06 - val_accuracy: 0.9255 - val_loss: 0.5697\n",
      "Epoch 160/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861us/step - accuracy: 1.0000 - loss: 4.1893e-06 - val_accuracy: 0.9251 - val_loss: 0.5746\n",
      "Epoch 161/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 1.0000 - loss: 3.8199e-06 - val_accuracy: 0.9251 - val_loss: 0.5783\n",
      "Epoch 162/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 1.0000 - loss: 3.5214e-06 - val_accuracy: 0.9248 - val_loss: 0.5809\n",
      "Epoch 163/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 881us/step - accuracy: 1.0000 - loss: 3.2547e-06 - val_accuracy: 0.9258 - val_loss: 0.5855\n",
      "Epoch 164/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step - accuracy: 1.0000 - loss: 2.9837e-06 - val_accuracy: 0.9251 - val_loss: 0.5891\n",
      "Epoch 165/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - accuracy: 1.0000 - loss: 2.7491e-06 - val_accuracy: 0.9258 - val_loss: 0.5924\n",
      "Epoch 166/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 1.0000 - loss: 2.5499e-06 - val_accuracy: 0.9258 - val_loss: 0.5952\n",
      "Epoch 167/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 1.0000 - loss: 2.3767e-06 - val_accuracy: 0.9255 - val_loss: 0.6000\n",
      "Epoch 168/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 1.0000 - loss: 2.1930e-06 - val_accuracy: 0.9244 - val_loss: 0.6028\n",
      "Epoch 169/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 872us/step - accuracy: 1.0000 - loss: 2.0266e-06 - val_accuracy: 0.9251 - val_loss: 0.6073\n",
      "Epoch 170/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 1.0000 - loss: 1.8682e-06 - val_accuracy: 0.9258 - val_loss: 0.6086\n",
      "Epoch 171/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 1.0000 - loss: 1.7377e-06 - val_accuracy: 0.9251 - val_loss: 0.6121\n",
      "Epoch 172/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 1.0000 - loss: 1.6001e-06 - val_accuracy: 0.9251 - val_loss: 0.6170\n",
      "Epoch 173/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - accuracy: 1.0000 - loss: 1.5035e-06 - val_accuracy: 0.9248 - val_loss: 0.6189\n",
      "Epoch 174/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 1.0000 - loss: 1.4027e-06 - val_accuracy: 0.9241 - val_loss: 0.6221\n",
      "Epoch 175/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 1.0000 - loss: 1.3280e-06 - val_accuracy: 0.9248 - val_loss: 0.6255\n",
      "Epoch 176/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 1.0000 - loss: 1.2252e-06 - val_accuracy: 0.9238 - val_loss: 0.6281\n",
      "Epoch 177/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 1.0000 - loss: 1.1650e-06 - val_accuracy: 0.9248 - val_loss: 0.6307\n",
      "Epoch 178/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 1.0000 - loss: 1.0718e-06 - val_accuracy: 0.9241 - val_loss: 0.6362\n",
      "Epoch 179/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 1.0000 - loss: 1.0049e-06 - val_accuracy: 0.9241 - val_loss: 0.6349\n",
      "Epoch 180/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867us/step - accuracy: 1.0000 - loss: 9.3541e-07 - val_accuracy: 0.9241 - val_loss: 0.6402\n",
      "Epoch 181/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 1.0000 - loss: 8.7261e-07 - val_accuracy: 0.9241 - val_loss: 0.6424\n",
      "Epoch 182/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 1.0000 - loss: 8.2009e-07 - val_accuracy: 0.9248 - val_loss: 0.6431\n",
      "Epoch 183/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 1.0000 - loss: 7.6916e-07 - val_accuracy: 0.9251 - val_loss: 0.6479\n",
      "Epoch 184/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 1.0000 - loss: 7.3034e-07 - val_accuracy: 0.9251 - val_loss: 0.6501\n",
      "Epoch 185/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 1.0000 - loss: 6.8636e-07 - val_accuracy: 0.9251 - val_loss: 0.6515\n",
      "Epoch 186/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 1.0000 - loss: 6.5073e-07 - val_accuracy: 0.9255 - val_loss: 0.6553\n",
      "Epoch 187/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 1.0000 - loss: 6.1595e-07 - val_accuracy: 0.9251 - val_loss: 0.6559\n",
      "Epoch 188/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 1.0000 - loss: 5.8045e-07 - val_accuracy: 0.9258 - val_loss: 0.6596\n",
      "Epoch 189/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 1.0000 - loss: 5.4943e-07 - val_accuracy: 0.9251 - val_loss: 0.6612\n",
      "Epoch 190/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 1.0000 - loss: 5.1625e-07 - val_accuracy: 0.9255 - val_loss: 0.6626\n",
      "Epoch 191/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 1.0000 - loss: 4.9115e-07 - val_accuracy: 0.9262 - val_loss: 0.6661\n",
      "Epoch 192/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - accuracy: 1.0000 - loss: 4.7177e-07 - val_accuracy: 0.9255 - val_loss: 0.6672\n",
      "Epoch 193/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 1.0000 - loss: 4.4448e-07 - val_accuracy: 0.9258 - val_loss: 0.6698\n",
      "Epoch 194/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 1.0000 - loss: 4.2364e-07 - val_accuracy: 0.9258 - val_loss: 0.6710\n",
      "Epoch 195/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 1.0000 - loss: 4.0296e-07 - val_accuracy: 0.9251 - val_loss: 0.6730\n",
      "Epoch 196/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 1.0000 - loss: 3.8547e-07 - val_accuracy: 0.9251 - val_loss: 0.6755\n",
      "Epoch 197/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864us/step - accuracy: 1.0000 - loss: 3.6652e-07 - val_accuracy: 0.9251 - val_loss: 0.6768\n",
      "Epoch 198/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 1.0000 - loss: 3.5068e-07 - val_accuracy: 0.9251 - val_loss: 0.6790\n",
      "Epoch 199/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 1.0000 - loss: 3.3421e-07 - val_accuracy: 0.9251 - val_loss: 0.6807\n",
      "Epoch 200/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 1.0000 - loss: 3.2250e-07 - val_accuracy: 0.9255 - val_loss: 0.6817\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "prueba_12: \n",
      "Epoch 1/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 991us/step - accuracy: 0.1772 - loss: 2.8042 - val_accuracy: 0.4950 - val_loss: 2.1791\n",
      "Epoch 2/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 0.6148 - loss: 1.9078 - val_accuracy: 0.7569 - val_loss: 1.2706\n",
      "Epoch 3/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 0.8192 - loss: 1.0975 - val_accuracy: 0.8462 - val_loss: 0.8063\n",
      "Epoch 4/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 0.8949 - loss: 0.6863 - val_accuracy: 0.8855 - val_loss: 0.5707\n",
      "Epoch 5/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864us/step - accuracy: 0.9243 - loss: 0.4723 - val_accuracy: 0.9080 - val_loss: 0.4369\n",
      "Epoch 6/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 884us/step - accuracy: 0.9470 - loss: 0.3472 - val_accuracy: 0.9193 - val_loss: 0.3509\n",
      "Epoch 7/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 0.9580 - loss: 0.2652 - val_accuracy: 0.9361 - val_loss: 0.2905\n",
      "Epoch 8/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 0.9682 - loss: 0.2068 - val_accuracy: 0.9429 - val_loss: 0.2454\n",
      "Epoch 9/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 0.9767 - loss: 0.1630 - val_accuracy: 0.9521 - val_loss: 0.2105\n",
      "Epoch 10/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 0.9837 - loss: 0.1292 - val_accuracy: 0.9552 - val_loss: 0.1829\n",
      "Epoch 11/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864us/step - accuracy: 0.9878 - loss: 0.1027 - val_accuracy: 0.9603 - val_loss: 0.1609\n",
      "Epoch 12/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - accuracy: 0.9924 - loss: 0.0817 - val_accuracy: 0.9644 - val_loss: 0.1431\n",
      "Epoch 13/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 872us/step - accuracy: 0.9950 - loss: 0.0648 - val_accuracy: 0.9703 - val_loss: 0.1286\n",
      "Epoch 14/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 885us/step - accuracy: 0.9967 - loss: 0.0513 - val_accuracy: 0.9737 - val_loss: 0.1169\n",
      "Epoch 15/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - accuracy: 0.9984 - loss: 0.0403 - val_accuracy: 0.9744 - val_loss: 0.1075\n",
      "Epoch 16/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 0.9988 - loss: 0.0315 - val_accuracy: 0.9764 - val_loss: 0.0999\n",
      "Epoch 17/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 0.9997 - loss: 0.0246 - val_accuracy: 0.9774 - val_loss: 0.0937\n",
      "Epoch 18/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 1.0000 - loss: 0.0192 - val_accuracy: 0.9785 - val_loss: 0.0887\n",
      "Epoch 19/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 1.0000 - loss: 0.0149 - val_accuracy: 0.9795 - val_loss: 0.0846\n",
      "Epoch 20/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 839us/step - accuracy: 1.0000 - loss: 0.0116 - val_accuracy: 0.9809 - val_loss: 0.0814\n",
      "Epoch 21/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 0.9809 - val_loss: 0.0788\n",
      "Epoch 22/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.9815 - val_loss: 0.0767\n",
      "Epoch 23/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9815 - val_loss: 0.0751\n",
      "Epoch 24/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9815 - val_loss: 0.0739\n",
      "Epoch 25/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9826 - val_loss: 0.0729\n",
      "Epoch 26/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9832 - val_loss: 0.0723\n",
      "Epoch 27/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9832 - val_loss: 0.0719\n",
      "Epoch 28/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864us/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9832 - val_loss: 0.0717\n",
      "Epoch 29/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 872us/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9829 - val_loss: 0.0717\n",
      "Epoch 30/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893us/step - accuracy: 1.0000 - loss: 8.9298e-04 - val_accuracy: 0.9826 - val_loss: 0.0718\n",
      "Epoch 31/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 1.0000 - loss: 6.8673e-04 - val_accuracy: 0.9832 - val_loss: 0.0721\n",
      "Epoch 32/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 885us/step - accuracy: 1.0000 - loss: 5.2754e-04 - val_accuracy: 0.9836 - val_loss: 0.0724\n",
      "Epoch 33/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 876us/step - accuracy: 1.0000 - loss: 4.0482e-04 - val_accuracy: 0.9832 - val_loss: 0.0729\n",
      "Epoch 34/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 1.0000 - loss: 3.1033e-04 - val_accuracy: 0.9832 - val_loss: 0.0735\n",
      "Epoch 35/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 1.0000 - loss: 2.3767e-04 - val_accuracy: 0.9836 - val_loss: 0.0742\n",
      "Epoch 36/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - accuracy: 1.0000 - loss: 1.8185e-04 - val_accuracy: 0.9832 - val_loss: 0.0749\n",
      "Epoch 37/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 1.0000 - loss: 1.3903e-04 - val_accuracy: 0.9832 - val_loss: 0.0757\n",
      "Epoch 38/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 1.0000 - loss: 1.0621e-04 - val_accuracy: 0.9836 - val_loss: 0.0766\n",
      "Epoch 39/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 1.0000 - loss: 8.1079e-05 - val_accuracy: 0.9836 - val_loss: 0.0775\n",
      "Epoch 40/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 1.0000 - loss: 6.1858e-05 - val_accuracy: 0.9832 - val_loss: 0.0784\n",
      "Epoch 41/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 1.0000 - loss: 4.7169e-05 - val_accuracy: 0.9829 - val_loss: 0.0794\n",
      "Epoch 42/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 1.0000 - loss: 3.5955e-05 - val_accuracy: 0.9826 - val_loss: 0.0805\n",
      "Epoch 43/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 1.0000 - loss: 2.7398e-05 - val_accuracy: 0.9826 - val_loss: 0.0816\n",
      "Epoch 44/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 1.0000 - loss: 2.0877e-05 - val_accuracy: 0.9822 - val_loss: 0.0827\n",
      "Epoch 45/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893us/step - accuracy: 1.0000 - loss: 1.5912e-05 - val_accuracy: 0.9822 - val_loss: 0.0839\n",
      "Epoch 46/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 1.0000 - loss: 1.2131e-05 - val_accuracy: 0.9822 - val_loss: 0.0851\n",
      "Epoch 47/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - accuracy: 1.0000 - loss: 9.2546e-06 - val_accuracy: 0.9826 - val_loss: 0.0864\n",
      "Epoch 48/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 876us/step - accuracy: 1.0000 - loss: 7.0673e-06 - val_accuracy: 0.9829 - val_loss: 0.0876\n",
      "Epoch 49/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 1.0000 - loss: 5.4090e-06 - val_accuracy: 0.9829 - val_loss: 0.0889\n",
      "Epoch 50/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 1.0000 - loss: 4.1455e-06 - val_accuracy: 0.9826 - val_loss: 0.0902\n",
      "Epoch 51/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 1.0000 - loss: 3.1886e-06 - val_accuracy: 0.9826 - val_loss: 0.0914\n",
      "Epoch 52/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 839us/step - accuracy: 1.0000 - loss: 2.4624e-06 - val_accuracy: 0.9822 - val_loss: 0.0927\n",
      "Epoch 53/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 1.0000 - loss: 1.9133e-06 - val_accuracy: 0.9819 - val_loss: 0.0940\n",
      "Epoch 54/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861us/step - accuracy: 1.0000 - loss: 1.4953e-06 - val_accuracy: 0.9819 - val_loss: 0.0952\n",
      "Epoch 55/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - accuracy: 1.0000 - loss: 1.1771e-06 - val_accuracy: 0.9815 - val_loss: 0.0964\n",
      "Epoch 56/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 1.0000 - loss: 9.3532e-07 - val_accuracy: 0.9815 - val_loss: 0.0976\n",
      "Epoch 57/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - accuracy: 1.0000 - loss: 7.4935e-07 - val_accuracy: 0.9815 - val_loss: 0.0987\n",
      "Epoch 58/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 1.0000 - loss: 6.0783e-07 - val_accuracy: 0.9815 - val_loss: 0.0997\n",
      "Epoch 59/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 1.0000 - loss: 4.9804e-07 - val_accuracy: 0.9815 - val_loss: 0.1006\n",
      "Epoch 60/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 1.0000 - loss: 4.1232e-07 - val_accuracy: 0.9815 - val_loss: 0.1015\n",
      "Epoch 61/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 1.0000 - loss: 3.4764e-07 - val_accuracy: 0.9812 - val_loss: 0.1023\n",
      "Epoch 62/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 1.0000 - loss: 2.9420e-07 - val_accuracy: 0.9812 - val_loss: 0.1031\n",
      "Epoch 63/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 1.0000 - loss: 2.5259e-07 - val_accuracy: 0.9809 - val_loss: 0.1038\n",
      "Epoch 64/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - accuracy: 1.0000 - loss: 2.1976e-07 - val_accuracy: 0.9809 - val_loss: 0.1044\n",
      "Epoch 65/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 1.0000 - loss: 1.9276e-07 - val_accuracy: 0.9809 - val_loss: 0.1051\n",
      "Epoch 66/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867us/step - accuracy: 1.0000 - loss: 1.7058e-07 - val_accuracy: 0.9809 - val_loss: 0.1057\n",
      "Epoch 67/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - accuracy: 1.0000 - loss: 1.5222e-07 - val_accuracy: 0.9809 - val_loss: 0.1063\n",
      "Epoch 68/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 1.0000 - loss: 1.3851e-07 - val_accuracy: 0.9809 - val_loss: 0.1067\n",
      "Epoch 69/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 1.0000 - loss: 1.2450e-07 - val_accuracy: 0.9809 - val_loss: 0.1071\n",
      "Epoch 70/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 1.0000 - loss: 1.1275e-07 - val_accuracy: 0.9809 - val_loss: 0.1072\n",
      "Epoch 71/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 1.0000 - loss: 1.0405e-07 - val_accuracy: 0.9812 - val_loss: 0.1077\n",
      "Epoch 72/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 872us/step - accuracy: 1.0000 - loss: 9.5435e-08 - val_accuracy: 0.9812 - val_loss: 0.1080\n",
      "Epoch 73/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 1.0000 - loss: 8.9541e-08 - val_accuracy: 0.9812 - val_loss: 0.1084\n",
      "Epoch 74/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 881us/step - accuracy: 1.0000 - loss: 8.3446e-08 - val_accuracy: 0.9812 - val_loss: 0.1085\n",
      "Epoch 75/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 1.0000 - loss: 7.7835e-08 - val_accuracy: 0.9815 - val_loss: 0.1088\n",
      "Epoch 76/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 1.0000 - loss: 7.2401e-08 - val_accuracy: 0.9815 - val_loss: 0.1091\n",
      "Epoch 77/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 1.0000 - loss: 6.8291e-08 - val_accuracy: 0.9819 - val_loss: 0.1094\n",
      "Epoch 78/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - accuracy: 1.0000 - loss: 6.4266e-08 - val_accuracy: 0.9819 - val_loss: 0.1096\n",
      "Epoch 79/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 1.0000 - loss: 6.0642e-08 - val_accuracy: 0.9819 - val_loss: 0.1097\n",
      "Epoch 80/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - accuracy: 1.0000 - loss: 5.7609e-08 - val_accuracy: 0.9819 - val_loss: 0.1099\n",
      "Epoch 81/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 1.0000 - loss: 5.4731e-08 - val_accuracy: 0.9815 - val_loss: 0.1101\n",
      "Epoch 82/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 1.0000 - loss: 5.2701e-08 - val_accuracy: 0.9815 - val_loss: 0.1103\n",
      "Epoch 83/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864us/step - accuracy: 1.0000 - loss: 5.0248e-08 - val_accuracy: 0.9815 - val_loss: 0.1104\n",
      "Epoch 84/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 1.0000 - loss: 4.8526e-08 - val_accuracy: 0.9815 - val_loss: 0.1104\n",
      "Epoch 85/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 1.0000 - loss: 4.6819e-08 - val_accuracy: 0.9815 - val_loss: 0.1106\n",
      "Epoch 86/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 1.0000 - loss: 4.4534e-08 - val_accuracy: 0.9815 - val_loss: 0.1108\n",
      "Epoch 87/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 1.0000 - loss: 4.3014e-08 - val_accuracy: 0.9819 - val_loss: 0.1109\n",
      "Epoch 88/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - accuracy: 1.0000 - loss: 4.1322e-08 - val_accuracy: 0.9819 - val_loss: 0.1109\n",
      "Epoch 89/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - accuracy: 1.0000 - loss: 4.0294e-08 - val_accuracy: 0.9819 - val_loss: 0.1112\n",
      "Epoch 90/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 1.0000 - loss: 3.8860e-08 - val_accuracy: 0.9819 - val_loss: 0.1113\n",
      "Epoch 91/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 884us/step - accuracy: 1.0000 - loss: 3.7194e-08 - val_accuracy: 0.9819 - val_loss: 0.1116\n",
      "Epoch 92/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 1.0000 - loss: 3.6340e-08 - val_accuracy: 0.9819 - val_loss: 0.1117\n",
      "Epoch 93/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 1.0000 - loss: 3.5365e-08 - val_accuracy: 0.9815 - val_loss: 0.1119\n",
      "Epoch 94/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 1.0000 - loss: 3.3690e-08 - val_accuracy: 0.9819 - val_loss: 0.1120\n",
      "Epoch 95/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824us/step - accuracy: 1.0000 - loss: 3.3059e-08 - val_accuracy: 0.9819 - val_loss: 0.1123\n",
      "Epoch 96/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 1.0000 - loss: 3.1933e-08 - val_accuracy: 0.9822 - val_loss: 0.1124\n",
      "Epoch 97/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 1.0000 - loss: 3.1201e-08 - val_accuracy: 0.9822 - val_loss: 0.1124\n",
      "Epoch 98/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 1.0000 - loss: 3.0692e-08 - val_accuracy: 0.9822 - val_loss: 0.1125\n",
      "Epoch 99/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 1.0000 - loss: 3.0118e-08 - val_accuracy: 0.9826 - val_loss: 0.1127\n",
      "Epoch 100/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 1.0000 - loss: 2.9026e-08 - val_accuracy: 0.9826 - val_loss: 0.1130\n",
      "Epoch 101/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 1.0000 - loss: 2.8443e-08 - val_accuracy: 0.9826 - val_loss: 0.1130\n",
      "Epoch 102/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 1.0000 - loss: 2.8250e-08 - val_accuracy: 0.9826 - val_loss: 0.1132\n",
      "Epoch 103/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 1.0000 - loss: 2.7631e-08 - val_accuracy: 0.9826 - val_loss: 0.1133\n",
      "Epoch 104/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 1.0000 - loss: 2.7111e-08 - val_accuracy: 0.9826 - val_loss: 0.1134\n",
      "Epoch 105/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 1.0000 - loss: 2.6730e-08 - val_accuracy: 0.9822 - val_loss: 0.1134\n",
      "Epoch 106/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 1.0000 - loss: 2.6478e-08 - val_accuracy: 0.9822 - val_loss: 0.1135\n",
      "Epoch 107/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 1.0000 - loss: 2.5226e-08 - val_accuracy: 0.9822 - val_loss: 0.1136\n",
      "Epoch 108/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 1.0000 - loss: 2.5424e-08 - val_accuracy: 0.9822 - val_loss: 0.1137\n",
      "Epoch 109/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 1.0000 - loss: 2.4573e-08 - val_accuracy: 0.9822 - val_loss: 0.1138\n",
      "Epoch 110/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853us/step - accuracy: 1.0000 - loss: 2.4500e-08 - val_accuracy: 0.9822 - val_loss: 0.1137\n",
      "Epoch 111/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 1.0000 - loss: 2.4083e-08 - val_accuracy: 0.9822 - val_loss: 0.1138\n",
      "Epoch 112/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 1.0000 - loss: 2.3650e-08 - val_accuracy: 0.9822 - val_loss: 0.1138\n",
      "Epoch 113/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - accuracy: 1.0000 - loss: 2.3025e-08 - val_accuracy: 0.9822 - val_loss: 0.1137\n",
      "Epoch 114/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 1.0000 - loss: 2.2803e-08 - val_accuracy: 0.9822 - val_loss: 0.1138\n",
      "Epoch 115/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 1.0000 - loss: 2.2413e-08 - val_accuracy: 0.9822 - val_loss: 0.1139\n",
      "Epoch 116/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 1.0000 - loss: 2.2401e-08 - val_accuracy: 0.9826 - val_loss: 0.1140\n",
      "Epoch 117/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 1.0000 - loss: 2.1742e-08 - val_accuracy: 0.9826 - val_loss: 0.1140\n",
      "Epoch 118/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 1.0000 - loss: 2.1977e-08 - val_accuracy: 0.9826 - val_loss: 0.1142\n",
      "Epoch 119/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 1.0000 - loss: 2.1370e-08 - val_accuracy: 0.9826 - val_loss: 0.1142\n",
      "Epoch 120/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 1.0000 - loss: 2.1673e-08 - val_accuracy: 0.9826 - val_loss: 0.1144\n",
      "Epoch 121/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 1.0000 - loss: 2.1094e-08 - val_accuracy: 0.9826 - val_loss: 0.1143\n",
      "Epoch 122/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 1.0000 - loss: 2.0722e-08 - val_accuracy: 0.9826 - val_loss: 0.1145\n",
      "Epoch 123/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - accuracy: 1.0000 - loss: 2.0528e-08 - val_accuracy: 0.9826 - val_loss: 0.1144\n",
      "Epoch 124/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 1.0000 - loss: 2.0218e-08 - val_accuracy: 0.9826 - val_loss: 0.1145\n",
      "Epoch 125/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 1.0000 - loss: 2.0287e-08 - val_accuracy: 0.9826 - val_loss: 0.1146\n",
      "Epoch 126/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 1.0000 - loss: 1.9422e-08 - val_accuracy: 0.9826 - val_loss: 0.1145\n",
      "Epoch 127/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step - accuracy: 1.0000 - loss: 1.9632e-08 - val_accuracy: 0.9826 - val_loss: 0.1146\n",
      "Epoch 128/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 1.0000 - loss: 1.9244e-08 - val_accuracy: 0.9826 - val_loss: 0.1147\n",
      "Epoch 129/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - accuracy: 1.0000 - loss: 1.9129e-08 - val_accuracy: 0.9826 - val_loss: 0.1148\n",
      "Epoch 130/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853us/step - accuracy: 1.0000 - loss: 1.9094e-08 - val_accuracy: 0.9822 - val_loss: 0.1146\n",
      "Epoch 131/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 1.0000 - loss: 1.9201e-08 - val_accuracy: 0.9822 - val_loss: 0.1148\n",
      "Epoch 132/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 1.0000 - loss: 1.8746e-08 - val_accuracy: 0.9822 - val_loss: 0.1149\n",
      "Epoch 133/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 1.0000 - loss: 1.8664e-08 - val_accuracy: 0.9822 - val_loss: 0.1148\n",
      "Epoch 134/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 1.0000 - loss: 1.8321e-08 - val_accuracy: 0.9822 - val_loss: 0.1149\n",
      "Epoch 135/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - accuracy: 1.0000 - loss: 1.7828e-08 - val_accuracy: 0.9822 - val_loss: 0.1150\n",
      "Epoch 136/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 1.0000 - loss: 1.8463e-08 - val_accuracy: 0.9822 - val_loss: 0.1151\n",
      "Epoch 137/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 1.0000 - loss: 1.7647e-08 - val_accuracy: 0.9822 - val_loss: 0.1151\n",
      "Epoch 138/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 1.0000 - loss: 1.7721e-08 - val_accuracy: 0.9819 - val_loss: 0.1153\n",
      "Epoch 139/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 1.0000 - loss: 1.7857e-08 - val_accuracy: 0.9822 - val_loss: 0.1152\n",
      "Epoch 140/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - accuracy: 1.0000 - loss: 1.7608e-08 - val_accuracy: 0.9822 - val_loss: 0.1154\n",
      "Epoch 141/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 1.0000 - loss: 1.7575e-08 - val_accuracy: 0.9822 - val_loss: 0.1155\n",
      "Epoch 142/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 831us/step - accuracy: 1.0000 - loss: 1.7102e-08 - val_accuracy: 0.9819 - val_loss: 0.1155\n",
      "Epoch 143/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 1.0000 - loss: 1.7328e-08 - val_accuracy: 0.9822 - val_loss: 0.1155\n",
      "Epoch 144/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 1.0000 - loss: 1.7280e-08 - val_accuracy: 0.9822 - val_loss: 0.1155\n",
      "Epoch 145/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 1.0000 - loss: 1.7485e-08 - val_accuracy: 0.9822 - val_loss: 0.1158\n",
      "Epoch 146/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - accuracy: 1.0000 - loss: 1.6949e-08 - val_accuracy: 0.9819 - val_loss: 0.1158\n",
      "Epoch 147/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 1.0000 - loss: 1.6698e-08 - val_accuracy: 0.9822 - val_loss: 0.1158\n",
      "Epoch 148/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 1.0000 - loss: 1.6437e-08 - val_accuracy: 0.9819 - val_loss: 0.1158\n",
      "Epoch 149/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 1.0000 - loss: 1.6850e-08 - val_accuracy: 0.9822 - val_loss: 0.1159\n",
      "Epoch 150/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 1.0000 - loss: 1.6486e-08 - val_accuracy: 0.9822 - val_loss: 0.1159\n",
      "Epoch 151/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 1.0000 - loss: 1.6774e-08 - val_accuracy: 0.9822 - val_loss: 0.1161\n",
      "Epoch 152/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 1.0000 - loss: 1.6791e-08 - val_accuracy: 0.9822 - val_loss: 0.1159\n",
      "Epoch 153/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 1.0000 - loss: 1.6643e-08 - val_accuracy: 0.9819 - val_loss: 0.1158\n",
      "Epoch 154/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 872us/step - accuracy: 1.0000 - loss: 1.6757e-08 - val_accuracy: 0.9812 - val_loss: 0.1161\n",
      "Epoch 155/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 1.0000 - loss: 1.6563e-08 - val_accuracy: 0.9815 - val_loss: 0.1161\n",
      "Epoch 156/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 1.0000 - loss: 1.6887e-08 - val_accuracy: 0.9815 - val_loss: 0.1161\n",
      "Epoch 157/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 1.0000 - loss: 1.6498e-08 - val_accuracy: 0.9812 - val_loss: 0.1162\n",
      "Epoch 158/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 839us/step - accuracy: 1.0000 - loss: 1.6418e-08 - val_accuracy: 0.9812 - val_loss: 0.1162\n",
      "Epoch 159/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 1.0000 - loss: 1.6751e-08 - val_accuracy: 0.9812 - val_loss: 0.1163\n",
      "Epoch 160/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 876us/step - accuracy: 1.0000 - loss: 1.6289e-08 - val_accuracy: 0.9812 - val_loss: 0.1162\n",
      "Epoch 161/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853us/step - accuracy: 1.0000 - loss: 1.6480e-08 - val_accuracy: 0.9812 - val_loss: 0.1163\n",
      "Epoch 162/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 1.0000 - loss: 1.5985e-08 - val_accuracy: 0.9812 - val_loss: 0.1164\n",
      "Epoch 163/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 1.0000 - loss: 1.6338e-08 - val_accuracy: 0.9812 - val_loss: 0.1164\n",
      "Epoch 164/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 839us/step - accuracy: 1.0000 - loss: 1.6103e-08 - val_accuracy: 0.9812 - val_loss: 0.1165\n",
      "Epoch 165/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 1.0000 - loss: 1.6144e-08 - val_accuracy: 0.9815 - val_loss: 0.1164\n",
      "Epoch 166/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 1.0000 - loss: 1.6282e-08 - val_accuracy: 0.9815 - val_loss: 0.1166\n",
      "Epoch 167/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 1.0000 - loss: 1.6289e-08 - val_accuracy: 0.9815 - val_loss: 0.1165\n",
      "Epoch 168/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 1.0000 - loss: 1.5797e-08 - val_accuracy: 0.9815 - val_loss: 0.1166\n",
      "Epoch 169/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 1.0000 - loss: 1.5761e-08 - val_accuracy: 0.9815 - val_loss: 0.1165\n",
      "Epoch 170/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 1.0000 - loss: 1.5858e-08 - val_accuracy: 0.9815 - val_loss: 0.1167\n",
      "Epoch 171/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 1.0000 - loss: 1.6201e-08 - val_accuracy: 0.9815 - val_loss: 0.1165\n",
      "Epoch 172/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 1.0000 - loss: 1.5596e-08 - val_accuracy: 0.9815 - val_loss: 0.1167\n",
      "Epoch 173/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864us/step - accuracy: 1.0000 - loss: 1.5817e-08 - val_accuracy: 0.9815 - val_loss: 0.1167\n",
      "Epoch 174/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 1.0000 - loss: 1.5693e-08 - val_accuracy: 0.9815 - val_loss: 0.1165\n",
      "Epoch 175/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 1.0000 - loss: 1.5626e-08 - val_accuracy: 0.9815 - val_loss: 0.1167\n",
      "Epoch 176/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 1.0000 - loss: 1.6074e-08 - val_accuracy: 0.9815 - val_loss: 0.1167\n",
      "Epoch 177/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 1.0000 - loss: 1.5401e-08 - val_accuracy: 0.9815 - val_loss: 0.1167\n",
      "Epoch 178/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 1.0000 - loss: 1.5737e-08 - val_accuracy: 0.9815 - val_loss: 0.1166\n",
      "Epoch 179/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 1.0000 - loss: 1.5512e-08 - val_accuracy: 0.9815 - val_loss: 0.1166\n",
      "Epoch 180/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 1.0000 - loss: 1.6060e-08 - val_accuracy: 0.9815 - val_loss: 0.1165\n",
      "Epoch 181/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 1.0000 - loss: 1.5528e-08 - val_accuracy: 0.9815 - val_loss: 0.1164\n",
      "Epoch 182/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 1.0000 - loss: 1.5212e-08 - val_accuracy: 0.9815 - val_loss: 0.1165\n",
      "Epoch 183/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 1.0000 - loss: 1.5406e-08 - val_accuracy: 0.9815 - val_loss: 0.1166\n",
      "Epoch 184/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 1.0000 - loss: 1.5596e-08 - val_accuracy: 0.9815 - val_loss: 0.1166\n",
      "Epoch 185/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 1.0000 - loss: 1.5566e-08 - val_accuracy: 0.9815 - val_loss: 0.1166\n",
      "Epoch 186/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - accuracy: 1.0000 - loss: 1.5293e-08 - val_accuracy: 0.9815 - val_loss: 0.1166\n",
      "Epoch 187/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 1.0000 - loss: 1.6157e-08 - val_accuracy: 0.9815 - val_loss: 0.1166\n",
      "Epoch 188/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864us/step - accuracy: 1.0000 - loss: 1.5400e-08 - val_accuracy: 0.9815 - val_loss: 0.1166\n",
      "Epoch 189/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 1.0000 - loss: 1.5640e-08 - val_accuracy: 0.9815 - val_loss: 0.1167\n",
      "Epoch 190/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 1.0000 - loss: 1.5325e-08 - val_accuracy: 0.9815 - val_loss: 0.1168\n",
      "Epoch 191/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 1.0000 - loss: 1.5664e-08 - val_accuracy: 0.9815 - val_loss: 0.1169\n",
      "Epoch 192/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 1.0000 - loss: 1.5673e-08 - val_accuracy: 0.9815 - val_loss: 0.1167\n",
      "Epoch 193/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 882us/step - accuracy: 1.0000 - loss: 1.5506e-08 - val_accuracy: 0.9815 - val_loss: 0.1168\n",
      "Epoch 194/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 1.0000 - loss: 1.5801e-08 - val_accuracy: 0.9815 - val_loss: 0.1168\n",
      "Epoch 195/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 1.0000 - loss: 1.5265e-08 - val_accuracy: 0.9815 - val_loss: 0.1170\n",
      "Epoch 196/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 1.0000 - loss: 1.5465e-08 - val_accuracy: 0.9815 - val_loss: 0.1168\n",
      "Epoch 197/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 1.0000 - loss: 1.5601e-08 - val_accuracy: 0.9815 - val_loss: 0.1167\n",
      "Epoch 198/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - accuracy: 1.0000 - loss: 1.5520e-08 - val_accuracy: 0.9815 - val_loss: 0.1169\n",
      "Epoch 199/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 1.0000 - loss: 1.5674e-08 - val_accuracy: 0.9815 - val_loss: 0.1169\n",
      "Epoch 200/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 1.0000 - loss: 1.5812e-08 - val_accuracy: 0.9815 - val_loss: 0.1171\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "prueba_13: \n",
      "Epoch 1/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 952us/step - accuracy: 0.1477 - loss: 2.8244 - val_accuracy: 0.4222 - val_loss: 2.3776\n",
      "Epoch 2/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 0.5047 - loss: 2.1623 - val_accuracy: 0.6578 - val_loss: 1.5766\n",
      "Epoch 3/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - accuracy: 0.7099 - loss: 1.4163 - val_accuracy: 0.7822 - val_loss: 1.0693\n",
      "Epoch 4/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - accuracy: 0.8196 - loss: 0.9530 - val_accuracy: 0.8513 - val_loss: 0.7709\n",
      "Epoch 5/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 0.8791 - loss: 0.6740 - val_accuracy: 0.8865 - val_loss: 0.5876\n",
      "Epoch 6/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 0.9157 - loss: 0.4990 - val_accuracy: 0.9022 - val_loss: 0.4679\n",
      "Epoch 7/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 823us/step - accuracy: 0.9364 - loss: 0.3826 - val_accuracy: 0.9121 - val_loss: 0.3851\n",
      "Epoch 8/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 0.9500 - loss: 0.3007 - val_accuracy: 0.9231 - val_loss: 0.3247\n",
      "Epoch 9/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 0.9595 - loss: 0.2401 - val_accuracy: 0.9323 - val_loss: 0.2789\n",
      "Epoch 10/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 0.9673 - loss: 0.1938 - val_accuracy: 0.9405 - val_loss: 0.2433\n",
      "Epoch 11/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864us/step - accuracy: 0.9761 - loss: 0.1576 - val_accuracy: 0.9484 - val_loss: 0.2151\n",
      "Epoch 12/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 0.9835 - loss: 0.1289 - val_accuracy: 0.9525 - val_loss: 0.1926\n",
      "Epoch 13/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 0.9858 - loss: 0.1057 - val_accuracy: 0.9556 - val_loss: 0.1744\n",
      "Epoch 14/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 0.9891 - loss: 0.0868 - val_accuracy: 0.9603 - val_loss: 0.1594\n",
      "Epoch 15/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - accuracy: 0.9935 - loss: 0.0713 - val_accuracy: 0.9621 - val_loss: 0.1470\n",
      "Epoch 16/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 0.9955 - loss: 0.0585 - val_accuracy: 0.9651 - val_loss: 0.1367\n",
      "Epoch 17/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 0.9971 - loss: 0.0481 - val_accuracy: 0.9675 - val_loss: 0.1282\n",
      "Epoch 18/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 0.9987 - loss: 0.0394 - val_accuracy: 0.9685 - val_loss: 0.1212\n",
      "Epoch 19/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853us/step - accuracy: 0.9989 - loss: 0.0323 - val_accuracy: 0.9703 - val_loss: 0.1155\n",
      "Epoch 20/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 819us/step - accuracy: 0.9997 - loss: 0.0263 - val_accuracy: 0.9726 - val_loss: 0.1109\n",
      "Epoch 21/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 0.9997 - loss: 0.0214 - val_accuracy: 0.9730 - val_loss: 0.1071\n",
      "Epoch 22/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 0.9998 - loss: 0.0174 - val_accuracy: 0.9733 - val_loss: 0.1040\n",
      "Epoch 23/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 0.9998 - loss: 0.0140 - val_accuracy: 0.9726 - val_loss: 0.1017\n",
      "Epoch 24/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835us/step - accuracy: 0.9998 - loss: 0.0113 - val_accuracy: 0.9726 - val_loss: 0.0998\n",
      "Epoch 25/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.9726 - val_loss: 0.0983\n",
      "Epoch 26/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853us/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9733 - val_loss: 0.0972\n",
      "Epoch 27/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.9744 - val_loss: 0.0964\n",
      "Epoch 28/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9744 - val_loss: 0.0959\n",
      "Epoch 29/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9747 - val_loss: 0.0957\n",
      "Epoch 30/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9750 - val_loss: 0.0957\n",
      "Epoch 31/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9754 - val_loss: 0.0958\n",
      "Epoch 32/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9757 - val_loss: 0.0961\n",
      "Epoch 33/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9750 - val_loss: 0.0965\n",
      "Epoch 34/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9750 - val_loss: 0.0971\n",
      "Epoch 35/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 1.0000 - loss: 9.5879e-04 - val_accuracy: 0.9750 - val_loss: 0.0977\n",
      "Epoch 36/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 822us/step - accuracy: 1.0000 - loss: 7.6055e-04 - val_accuracy: 0.9754 - val_loss: 0.0984\n",
      "Epoch 37/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 1.0000 - loss: 6.0252e-04 - val_accuracy: 0.9757 - val_loss: 0.0992\n",
      "Epoch 38/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 872us/step - accuracy: 1.0000 - loss: 4.7674e-04 - val_accuracy: 0.9757 - val_loss: 0.1001\n",
      "Epoch 39/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 1.0000 - loss: 3.7677e-04 - val_accuracy: 0.9754 - val_loss: 0.1010\n",
      "Epoch 40/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853us/step - accuracy: 1.0000 - loss: 2.9744e-04 - val_accuracy: 0.9761 - val_loss: 0.1020\n",
      "Epoch 41/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 811us/step - accuracy: 1.0000 - loss: 2.3457e-04 - val_accuracy: 0.9761 - val_loss: 0.1031\n",
      "Epoch 42/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 839us/step - accuracy: 1.0000 - loss: 1.8480e-04 - val_accuracy: 0.9761 - val_loss: 0.1042\n",
      "Epoch 43/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 1.0000 - loss: 1.4546e-04 - val_accuracy: 0.9764 - val_loss: 0.1054\n",
      "Epoch 44/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 1.0000 - loss: 1.1440e-04 - val_accuracy: 0.9768 - val_loss: 0.1067\n",
      "Epoch 45/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 1.0000 - loss: 8.9902e-05 - val_accuracy: 0.9768 - val_loss: 0.1081\n",
      "Epoch 46/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - accuracy: 1.0000 - loss: 7.0604e-05 - val_accuracy: 0.9764 - val_loss: 0.1095\n",
      "Epoch 47/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 814us/step - accuracy: 1.0000 - loss: 5.5414e-05 - val_accuracy: 0.9764 - val_loss: 0.1110\n",
      "Epoch 48/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824us/step - accuracy: 1.0000 - loss: 4.3475e-05 - val_accuracy: 0.9768 - val_loss: 0.1126\n",
      "Epoch 49/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 1.0000 - loss: 3.4098e-05 - val_accuracy: 0.9764 - val_loss: 0.1142\n",
      "Epoch 50/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 1.0000 - loss: 2.6738e-05 - val_accuracy: 0.9771 - val_loss: 0.1159\n",
      "Epoch 51/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step - accuracy: 1.0000 - loss: 2.0967e-05 - val_accuracy: 0.9768 - val_loss: 0.1177\n",
      "Epoch 52/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 1.0000 - loss: 1.6447e-05 - val_accuracy: 0.9768 - val_loss: 0.1195\n",
      "Epoch 53/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 1.0000 - loss: 1.2909e-05 - val_accuracy: 0.9764 - val_loss: 0.1213\n",
      "Epoch 54/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - accuracy: 1.0000 - loss: 1.0142e-05 - val_accuracy: 0.9761 - val_loss: 0.1232\n",
      "Epoch 55/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 839us/step - accuracy: 1.0000 - loss: 7.9773e-06 - val_accuracy: 0.9761 - val_loss: 0.1251\n",
      "Epoch 56/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 821us/step - accuracy: 1.0000 - loss: 6.2860e-06 - val_accuracy: 0.9761 - val_loss: 0.1270\n",
      "Epoch 57/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 1.0000 - loss: 4.9645e-06 - val_accuracy: 0.9761 - val_loss: 0.1289\n",
      "Epoch 58/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 1.0000 - loss: 3.9300e-06 - val_accuracy: 0.9764 - val_loss: 0.1308\n",
      "Epoch 59/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853us/step - accuracy: 1.0000 - loss: 3.1253e-06 - val_accuracy: 0.9764 - val_loss: 0.1326\n",
      "Epoch 60/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 1.0000 - loss: 2.4941e-06 - val_accuracy: 0.9757 - val_loss: 0.1345\n",
      "Epoch 61/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 1.0000 - loss: 2.0021e-06 - val_accuracy: 0.9761 - val_loss: 0.1363\n",
      "Epoch 62/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step - accuracy: 1.0000 - loss: 1.6147e-06 - val_accuracy: 0.9761 - val_loss: 0.1381\n",
      "Epoch 63/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 1.0000 - loss: 1.3111e-06 - val_accuracy: 0.9761 - val_loss: 0.1397\n",
      "Epoch 64/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step - accuracy: 1.0000 - loss: 1.0728e-06 - val_accuracy: 0.9761 - val_loss: 0.1413\n",
      "Epoch 65/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 823us/step - accuracy: 1.0000 - loss: 8.8412e-07 - val_accuracy: 0.9761 - val_loss: 0.1429\n",
      "Epoch 66/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - accuracy: 1.0000 - loss: 7.3579e-07 - val_accuracy: 0.9761 - val_loss: 0.1444\n",
      "Epoch 67/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 831us/step - accuracy: 1.0000 - loss: 6.1687e-07 - val_accuracy: 0.9761 - val_loss: 0.1458\n",
      "Epoch 68/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 1.0000 - loss: 5.2275e-07 - val_accuracy: 0.9761 - val_loss: 0.1469\n",
      "Epoch 69/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 1.0000 - loss: 4.4593e-07 - val_accuracy: 0.9764 - val_loss: 0.1483\n",
      "Epoch 70/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 1.0000 - loss: 3.8345e-07 - val_accuracy: 0.9764 - val_loss: 0.1493\n",
      "Epoch 71/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835us/step - accuracy: 1.0000 - loss: 3.3405e-07 - val_accuracy: 0.9764 - val_loss: 0.1502\n",
      "Epoch 72/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 1.0000 - loss: 2.9394e-07 - val_accuracy: 0.9764 - val_loss: 0.1513\n",
      "Epoch 73/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 822us/step - accuracy: 1.0000 - loss: 2.5948e-07 - val_accuracy: 0.9771 - val_loss: 0.1521\n",
      "Epoch 74/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 1.0000 - loss: 2.3032e-07 - val_accuracy: 0.9771 - val_loss: 0.1528\n",
      "Epoch 75/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 814us/step - accuracy: 1.0000 - loss: 2.0647e-07 - val_accuracy: 0.9771 - val_loss: 0.1535\n",
      "Epoch 76/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 1.0000 - loss: 1.8671e-07 - val_accuracy: 0.9771 - val_loss: 0.1542\n",
      "Epoch 77/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - accuracy: 1.0000 - loss: 1.6918e-07 - val_accuracy: 0.9768 - val_loss: 0.1549\n",
      "Epoch 78/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 1.0000 - loss: 1.5443e-07 - val_accuracy: 0.9768 - val_loss: 0.1554\n",
      "Epoch 79/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 1.0000 - loss: 1.4246e-07 - val_accuracy: 0.9768 - val_loss: 0.1559\n",
      "Epoch 80/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - accuracy: 1.0000 - loss: 1.3177e-07 - val_accuracy: 0.9764 - val_loss: 0.1562\n",
      "Epoch 81/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 1.0000 - loss: 1.2273e-07 - val_accuracy: 0.9764 - val_loss: 0.1565\n",
      "Epoch 82/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 819us/step - accuracy: 1.0000 - loss: 1.1407e-07 - val_accuracy: 0.9764 - val_loss: 0.1573\n",
      "Epoch 83/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 1.0000 - loss: 1.0603e-07 - val_accuracy: 0.9764 - val_loss: 0.1579\n",
      "Epoch 84/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 1.0000 - loss: 1.0010e-07 - val_accuracy: 0.9764 - val_loss: 0.1583\n",
      "Epoch 85/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853us/step - accuracy: 1.0000 - loss: 9.4071e-08 - val_accuracy: 0.9764 - val_loss: 0.1584\n",
      "Epoch 86/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 1.0000 - loss: 8.8920e-08 - val_accuracy: 0.9761 - val_loss: 0.1587\n",
      "Epoch 87/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 1.0000 - loss: 8.4394e-08 - val_accuracy: 0.9761 - val_loss: 0.1589\n",
      "Epoch 88/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 819us/step - accuracy: 1.0000 - loss: 8.0296e-08 - val_accuracy: 0.9761 - val_loss: 0.1592\n",
      "Epoch 89/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 822us/step - accuracy: 1.0000 - loss: 7.6127e-08 - val_accuracy: 0.9757 - val_loss: 0.1596\n",
      "Epoch 90/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 1.0000 - loss: 7.2567e-08 - val_accuracy: 0.9761 - val_loss: 0.1600\n",
      "Epoch 91/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 1.0000 - loss: 6.9706e-08 - val_accuracy: 0.9761 - val_loss: 0.1602\n",
      "Epoch 92/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 1.0000 - loss: 6.7222e-08 - val_accuracy: 0.9757 - val_loss: 0.1608\n",
      "Epoch 93/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 1.0000 - loss: 6.4119e-08 - val_accuracy: 0.9761 - val_loss: 0.1609\n",
      "Epoch 94/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 1.0000 - loss: 6.0919e-08 - val_accuracy: 0.9764 - val_loss: 0.1612\n",
      "Epoch 95/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824us/step - accuracy: 1.0000 - loss: 5.9516e-08 - val_accuracy: 0.9764 - val_loss: 0.1615\n",
      "Epoch 96/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 1.0000 - loss: 5.6960e-08 - val_accuracy: 0.9764 - val_loss: 0.1616\n",
      "Epoch 97/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - accuracy: 1.0000 - loss: 5.4779e-08 - val_accuracy: 0.9761 - val_loss: 0.1619\n",
      "Epoch 98/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 1.0000 - loss: 5.2856e-08 - val_accuracy: 0.9768 - val_loss: 0.1621\n",
      "Epoch 99/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 1.0000 - loss: 5.1142e-08 - val_accuracy: 0.9764 - val_loss: 0.1623\n",
      "Epoch 100/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 1.0000 - loss: 4.9023e-08 - val_accuracy: 0.9764 - val_loss: 0.1626\n",
      "Epoch 101/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 1.0000 - loss: 4.7706e-08 - val_accuracy: 0.9764 - val_loss: 0.1630\n",
      "Epoch 102/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 819us/step - accuracy: 1.0000 - loss: 4.6531e-08 - val_accuracy: 0.9764 - val_loss: 0.1631\n",
      "Epoch 103/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 1.0000 - loss: 4.5224e-08 - val_accuracy: 0.9764 - val_loss: 0.1636\n",
      "Epoch 104/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 831us/step - accuracy: 1.0000 - loss: 4.3710e-08 - val_accuracy: 0.9761 - val_loss: 0.1638\n",
      "Epoch 105/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 1.0000 - loss: 4.2225e-08 - val_accuracy: 0.9764 - val_loss: 0.1642\n",
      "Epoch 106/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 1.0000 - loss: 4.1312e-08 - val_accuracy: 0.9764 - val_loss: 0.1644\n",
      "Epoch 107/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 1.0000 - loss: 4.0516e-08 - val_accuracy: 0.9761 - val_loss: 0.1648\n",
      "Epoch 108/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803us/step - accuracy: 1.0000 - loss: 3.9401e-08 - val_accuracy: 0.9761 - val_loss: 0.1650\n",
      "Epoch 109/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - accuracy: 1.0000 - loss: 3.8180e-08 - val_accuracy: 0.9757 - val_loss: 0.1653\n",
      "Epoch 110/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 1.0000 - loss: 3.7813e-08 - val_accuracy: 0.9757 - val_loss: 0.1655\n",
      "Epoch 111/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 1.0000 - loss: 3.6933e-08 - val_accuracy: 0.9757 - val_loss: 0.1658\n",
      "Epoch 112/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 1.0000 - loss: 3.5796e-08 - val_accuracy: 0.9754 - val_loss: 0.1659\n",
      "Epoch 113/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 1.0000 - loss: 3.5299e-08 - val_accuracy: 0.9750 - val_loss: 0.1662\n",
      "Epoch 114/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - accuracy: 1.0000 - loss: 3.4827e-08 - val_accuracy: 0.9754 - val_loss: 0.1663\n",
      "Epoch 115/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - accuracy: 1.0000 - loss: 3.3677e-08 - val_accuracy: 0.9750 - val_loss: 0.1663\n",
      "Epoch 116/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 1.0000 - loss: 3.3208e-08 - val_accuracy: 0.9754 - val_loss: 0.1664\n",
      "Epoch 117/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 1.0000 - loss: 3.2079e-08 - val_accuracy: 0.9754 - val_loss: 0.1666\n",
      "Epoch 118/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 1.0000 - loss: 3.1902e-08 - val_accuracy: 0.9754 - val_loss: 0.1667\n",
      "Epoch 119/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 1.0000 - loss: 3.1707e-08 - val_accuracy: 0.9757 - val_loss: 0.1667\n",
      "Epoch 120/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 1.0000 - loss: 3.0932e-08 - val_accuracy: 0.9761 - val_loss: 0.1668\n",
      "Epoch 121/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 1.0000 - loss: 3.1078e-08 - val_accuracy: 0.9761 - val_loss: 0.1671\n",
      "Epoch 122/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - accuracy: 1.0000 - loss: 2.9810e-08 - val_accuracy: 0.9761 - val_loss: 0.1673\n",
      "Epoch 123/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 1.0000 - loss: 2.9630e-08 - val_accuracy: 0.9757 - val_loss: 0.1674\n",
      "Epoch 124/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - accuracy: 1.0000 - loss: 2.8862e-08 - val_accuracy: 0.9757 - val_loss: 0.1674\n",
      "Epoch 125/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 1.0000 - loss: 2.8729e-08 - val_accuracy: 0.9754 - val_loss: 0.1675\n",
      "Epoch 126/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 1.0000 - loss: 2.8517e-08 - val_accuracy: 0.9754 - val_loss: 0.1675\n",
      "Epoch 127/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 839us/step - accuracy: 1.0000 - loss: 2.7809e-08 - val_accuracy: 0.9754 - val_loss: 0.1676\n",
      "Epoch 128/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 1.0000 - loss: 2.7542e-08 - val_accuracy: 0.9754 - val_loss: 0.1678\n",
      "Epoch 129/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 814us/step - accuracy: 1.0000 - loss: 2.7368e-08 - val_accuracy: 0.9750 - val_loss: 0.1677\n",
      "Epoch 130/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 1.0000 - loss: 2.6898e-08 - val_accuracy: 0.9754 - val_loss: 0.1678\n",
      "Epoch 131/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824us/step - accuracy: 1.0000 - loss: 2.6856e-08 - val_accuracy: 0.9754 - val_loss: 0.1677\n",
      "Epoch 132/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 839us/step - accuracy: 1.0000 - loss: 2.6166e-08 - val_accuracy: 0.9754 - val_loss: 0.1678\n",
      "Epoch 133/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 1.0000 - loss: 2.5518e-08 - val_accuracy: 0.9750 - val_loss: 0.1678\n",
      "Epoch 134/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 823us/step - accuracy: 1.0000 - loss: 2.5948e-08 - val_accuracy: 0.9754 - val_loss: 0.1679\n",
      "Epoch 135/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864us/step - accuracy: 1.0000 - loss: 2.4916e-08 - val_accuracy: 0.9750 - val_loss: 0.1680\n",
      "Epoch 136/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - accuracy: 1.0000 - loss: 2.5107e-08 - val_accuracy: 0.9754 - val_loss: 0.1679\n",
      "Epoch 137/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 1.0000 - loss: 2.4400e-08 - val_accuracy: 0.9754 - val_loss: 0.1681\n",
      "Epoch 138/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 1.0000 - loss: 2.3841e-08 - val_accuracy: 0.9754 - val_loss: 0.1681\n",
      "Epoch 139/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 1.0000 - loss: 2.3493e-08 - val_accuracy: 0.9750 - val_loss: 0.1683\n",
      "Epoch 140/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 1.0000 - loss: 2.3379e-08 - val_accuracy: 0.9750 - val_loss: 0.1682\n",
      "Epoch 141/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 1.0000 - loss: 2.2940e-08 - val_accuracy: 0.9750 - val_loss: 0.1681\n",
      "Epoch 142/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 1.0000 - loss: 2.2745e-08 - val_accuracy: 0.9750 - val_loss: 0.1684\n",
      "Epoch 143/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824us/step - accuracy: 1.0000 - loss: 2.2306e-08 - val_accuracy: 0.9750 - val_loss: 0.1684\n",
      "Epoch 144/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 1.0000 - loss: 2.2174e-08 - val_accuracy: 0.9754 - val_loss: 0.1683\n",
      "Epoch 145/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 1.0000 - loss: 2.1887e-08 - val_accuracy: 0.9750 - val_loss: 0.1686\n",
      "Epoch 146/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 1.0000 - loss: 2.1951e-08 - val_accuracy: 0.9750 - val_loss: 0.1686\n",
      "Epoch 147/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - accuracy: 1.0000 - loss: 2.1685e-08 - val_accuracy: 0.9750 - val_loss: 0.1682\n",
      "Epoch 148/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 1.0000 - loss: 2.1267e-08 - val_accuracy: 0.9750 - val_loss: 0.1685\n",
      "Epoch 149/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 1.0000 - loss: 2.1241e-08 - val_accuracy: 0.9750 - val_loss: 0.1686\n",
      "Epoch 150/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 1.0000 - loss: 2.0746e-08 - val_accuracy: 0.9747 - val_loss: 0.1685\n",
      "Epoch 151/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 1.0000 - loss: 2.0642e-08 - val_accuracy: 0.9747 - val_loss: 0.1685\n",
      "Epoch 152/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 1.0000 - loss: 2.1102e-08 - val_accuracy: 0.9747 - val_loss: 0.1686\n",
      "Epoch 153/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 1.0000 - loss: 2.0412e-08 - val_accuracy: 0.9750 - val_loss: 0.1686\n",
      "Epoch 154/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 1.0000 - loss: 2.0263e-08 - val_accuracy: 0.9747 - val_loss: 0.1685\n",
      "Epoch 155/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 1.0000 - loss: 2.0221e-08 - val_accuracy: 0.9744 - val_loss: 0.1685\n",
      "Epoch 156/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 1.0000 - loss: 2.0065e-08 - val_accuracy: 0.9740 - val_loss: 0.1685\n",
      "Epoch 157/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - accuracy: 1.0000 - loss: 1.9527e-08 - val_accuracy: 0.9740 - val_loss: 0.1686\n",
      "Epoch 158/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 1.0000 - loss: 2.0061e-08 - val_accuracy: 0.9737 - val_loss: 0.1686\n",
      "Epoch 159/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 1.0000 - loss: 1.9502e-08 - val_accuracy: 0.9744 - val_loss: 0.1686\n",
      "Epoch 160/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 1.0000 - loss: 1.9748e-08 - val_accuracy: 0.9740 - val_loss: 0.1687\n",
      "Epoch 161/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 1.0000 - loss: 1.9229e-08 - val_accuracy: 0.9744 - val_loss: 0.1686\n",
      "Epoch 162/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - accuracy: 1.0000 - loss: 1.9341e-08 - val_accuracy: 0.9744 - val_loss: 0.1685\n",
      "Epoch 163/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 1.0000 - loss: 1.9449e-08 - val_accuracy: 0.9744 - val_loss: 0.1688\n",
      "Epoch 164/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 1.0000 - loss: 1.9213e-08 - val_accuracy: 0.9744 - val_loss: 0.1687\n",
      "Epoch 165/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893us/step - accuracy: 1.0000 - loss: 1.8748e-08 - val_accuracy: 0.9744 - val_loss: 0.1689\n",
      "Epoch 166/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911us/step - accuracy: 1.0000 - loss: 1.8994e-08 - val_accuracy: 0.9740 - val_loss: 0.1687\n",
      "Epoch 167/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - accuracy: 1.0000 - loss: 1.8517e-08 - val_accuracy: 0.9744 - val_loss: 0.1688\n",
      "Epoch 168/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 1.0000 - loss: 1.8701e-08 - val_accuracy: 0.9737 - val_loss: 0.1688\n",
      "Epoch 169/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - accuracy: 1.0000 - loss: 1.8187e-08 - val_accuracy: 0.9737 - val_loss: 0.1692\n",
      "Epoch 170/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - accuracy: 1.0000 - loss: 1.8636e-08 - val_accuracy: 0.9737 - val_loss: 0.1692\n",
      "Epoch 171/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - accuracy: 1.0000 - loss: 1.7957e-08 - val_accuracy: 0.9737 - val_loss: 0.1693\n",
      "Epoch 172/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 1.0000 - loss: 1.8093e-08 - val_accuracy: 0.9737 - val_loss: 0.1692\n",
      "Epoch 173/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - accuracy: 1.0000 - loss: 1.7991e-08 - val_accuracy: 0.9737 - val_loss: 0.1692\n",
      "Epoch 174/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 1.0000 - loss: 1.7675e-08 - val_accuracy: 0.9737 - val_loss: 0.1691\n",
      "Epoch 175/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 1.0000 - loss: 1.7884e-08 - val_accuracy: 0.9737 - val_loss: 0.1691\n",
      "Epoch 176/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 1.0000 - loss: 1.7750e-08 - val_accuracy: 0.9737 - val_loss: 0.1693\n",
      "Epoch 177/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 1.0000 - loss: 1.7881e-08 - val_accuracy: 0.9737 - val_loss: 0.1694\n",
      "Epoch 178/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 1.0000 - loss: 1.7927e-08 - val_accuracy: 0.9737 - val_loss: 0.1694\n",
      "Epoch 179/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 1.0000 - loss: 1.7837e-08 - val_accuracy: 0.9737 - val_loss: 0.1695\n",
      "Epoch 180/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - accuracy: 1.0000 - loss: 1.7152e-08 - val_accuracy: 0.9737 - val_loss: 0.1694\n",
      "Epoch 181/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - accuracy: 1.0000 - loss: 1.7351e-08 - val_accuracy: 0.9737 - val_loss: 0.1695\n",
      "Epoch 182/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 1.0000 - loss: 1.7276e-08 - val_accuracy: 0.9737 - val_loss: 0.1695\n",
      "Epoch 183/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 1.0000 - loss: 1.7642e-08 - val_accuracy: 0.9737 - val_loss: 0.1695\n",
      "Epoch 184/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 872us/step - accuracy: 1.0000 - loss: 1.7375e-08 - val_accuracy: 0.9737 - val_loss: 0.1698\n",
      "Epoch 185/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - accuracy: 1.0000 - loss: 1.6747e-08 - val_accuracy: 0.9737 - val_loss: 0.1695\n",
      "Epoch 186/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 1.0000 - loss: 1.6900e-08 - val_accuracy: 0.9737 - val_loss: 0.1697\n",
      "Epoch 187/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 885us/step - accuracy: 1.0000 - loss: 1.7436e-08 - val_accuracy: 0.9737 - val_loss: 0.1698\n",
      "Epoch 188/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 1.0000 - loss: 1.7203e-08 - val_accuracy: 0.9737 - val_loss: 0.1698\n",
      "Epoch 189/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 1.0000 - loss: 1.6929e-08 - val_accuracy: 0.9737 - val_loss: 0.1699\n",
      "Epoch 190/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 1.0000 - loss: 1.6327e-08 - val_accuracy: 0.9737 - val_loss: 0.1699\n",
      "Epoch 191/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 1.0000 - loss: 1.7172e-08 - val_accuracy: 0.9737 - val_loss: 0.1699\n",
      "Epoch 192/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867us/step - accuracy: 1.0000 - loss: 1.6907e-08 - val_accuracy: 0.9737 - val_loss: 0.1699\n",
      "Epoch 193/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 1.0000 - loss: 1.6378e-08 - val_accuracy: 0.9737 - val_loss: 0.1701\n",
      "Epoch 194/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864us/step - accuracy: 1.0000 - loss: 1.6970e-08 - val_accuracy: 0.9737 - val_loss: 0.1699\n",
      "Epoch 195/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - accuracy: 1.0000 - loss: 1.6535e-08 - val_accuracy: 0.9737 - val_loss: 0.1699\n",
      "Epoch 196/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 1.0000 - loss: 1.7224e-08 - val_accuracy: 0.9737 - val_loss: 0.1701\n",
      "Epoch 197/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 1.0000 - loss: 1.6804e-08 - val_accuracy: 0.9737 - val_loss: 0.1700\n",
      "Epoch 198/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 1.0000 - loss: 1.6609e-08 - val_accuracy: 0.9737 - val_loss: 0.1702\n",
      "Epoch 199/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 1.0000 - loss: 1.6257e-08 - val_accuracy: 0.9737 - val_loss: 0.1699\n",
      "Epoch 200/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 1.0000 - loss: 1.6880e-08 - val_accuracy: 0.9737 - val_loss: 0.1701\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "prueba_14: \n",
      "Epoch 1/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 960us/step - accuracy: 0.1190 - loss: 2.8190 - val_accuracy: 0.3733 - val_loss: 2.4372\n",
      "Epoch 2/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step - accuracy: 0.4797 - loss: 2.2578 - val_accuracy: 0.6027 - val_loss: 1.7817\n",
      "Epoch 3/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 0.6406 - loss: 1.6348 - val_accuracy: 0.6773 - val_loss: 1.3448\n",
      "Epoch 4/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 0.7232 - loss: 1.2309 - val_accuracy: 0.7337 - val_loss: 1.0760\n",
      "Epoch 5/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - accuracy: 0.7812 - loss: 0.9709 - val_accuracy: 0.7726 - val_loss: 0.8998\n",
      "Epoch 6/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 0.8161 - loss: 0.7935 - val_accuracy: 0.8041 - val_loss: 0.7756\n",
      "Epoch 7/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 0.8432 - loss: 0.6648 - val_accuracy: 0.8253 - val_loss: 0.6816\n",
      "Epoch 8/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 0.8659 - loss: 0.5659 - val_accuracy: 0.8441 - val_loss: 0.6070\n",
      "Epoch 9/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 0.8880 - loss: 0.4867 - val_accuracy: 0.8547 - val_loss: 0.5461\n",
      "Epoch 10/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - accuracy: 0.9056 - loss: 0.4217 - val_accuracy: 0.8687 - val_loss: 0.4957\n",
      "Epoch 11/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 0.9202 - loss: 0.3673 - val_accuracy: 0.8803 - val_loss: 0.4534\n",
      "Epoch 12/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 0.9285 - loss: 0.3211 - val_accuracy: 0.8899 - val_loss: 0.4176\n",
      "Epoch 13/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 876us/step - accuracy: 0.9373 - loss: 0.2814 - val_accuracy: 0.8964 - val_loss: 0.3870\n",
      "Epoch 14/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - accuracy: 0.9490 - loss: 0.2470 - val_accuracy: 0.9009 - val_loss: 0.3607\n",
      "Epoch 15/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 0.9583 - loss: 0.2168 - val_accuracy: 0.9080 - val_loss: 0.3379\n",
      "Epoch 16/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 0.9630 - loss: 0.1903 - val_accuracy: 0.9145 - val_loss: 0.3179\n",
      "Epoch 17/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 0.9695 - loss: 0.1669 - val_accuracy: 0.9173 - val_loss: 0.3002\n",
      "Epoch 18/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867us/step - accuracy: 0.9759 - loss: 0.1463 - val_accuracy: 0.9224 - val_loss: 0.2846\n",
      "Epoch 19/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 0.9811 - loss: 0.1282 - val_accuracy: 0.9251 - val_loss: 0.2710\n",
      "Epoch 20/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 0.9854 - loss: 0.1122 - val_accuracy: 0.9265 - val_loss: 0.2591\n",
      "Epoch 21/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 882us/step - accuracy: 0.9879 - loss: 0.0982 - val_accuracy: 0.9296 - val_loss: 0.2487\n",
      "Epoch 22/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 0.9897 - loss: 0.0859 - val_accuracy: 0.9316 - val_loss: 0.2395\n",
      "Epoch 23/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 0.9921 - loss: 0.0750 - val_accuracy: 0.9337 - val_loss: 0.2316\n",
      "Epoch 24/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 0.9943 - loss: 0.0654 - val_accuracy: 0.9333 - val_loss: 0.2247\n",
      "Epoch 25/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - accuracy: 0.9962 - loss: 0.0569 - val_accuracy: 0.9357 - val_loss: 0.2188\n",
      "Epoch 26/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 0.9982 - loss: 0.0495 - val_accuracy: 0.9374 - val_loss: 0.2136\n",
      "Epoch 27/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861us/step - accuracy: 0.9984 - loss: 0.0429 - val_accuracy: 0.9405 - val_loss: 0.2092\n",
      "Epoch 28/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 0.9985 - loss: 0.0372 - val_accuracy: 0.9415 - val_loss: 0.2054\n",
      "Epoch 29/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 0.9989 - loss: 0.0322 - val_accuracy: 0.9432 - val_loss: 0.2020\n",
      "Epoch 30/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - accuracy: 0.9996 - loss: 0.0278 - val_accuracy: 0.9439 - val_loss: 0.1990\n",
      "Epoch 31/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 0.9998 - loss: 0.0240 - val_accuracy: 0.9453 - val_loss: 0.1963\n",
      "Epoch 32/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - accuracy: 0.9998 - loss: 0.0206 - val_accuracy: 0.9463 - val_loss: 0.1941\n",
      "Epoch 33/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 1.0000 - loss: 0.0177 - val_accuracy: 0.9467 - val_loss: 0.1922\n",
      "Epoch 34/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864us/step - accuracy: 1.0000 - loss: 0.0151 - val_accuracy: 0.9470 - val_loss: 0.1908\n",
      "Epoch 35/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 1.0000 - loss: 0.0129 - val_accuracy: 0.9477 - val_loss: 0.1897\n",
      "Epoch 36/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 0.9480 - val_loss: 0.1889\n",
      "Epoch 37/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 839us/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.9480 - val_loss: 0.1883\n",
      "Epoch 38/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 890us/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.9487 - val_loss: 0.1880\n",
      "Epoch 39/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.9491 - val_loss: 0.1878\n",
      "Epoch 40/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864us/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.9491 - val_loss: 0.1878\n",
      "Epoch 41/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9487 - val_loss: 0.1880\n",
      "Epoch 42/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9487 - val_loss: 0.1884\n",
      "Epoch 43/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9494 - val_loss: 0.1888\n",
      "Epoch 44/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9494 - val_loss: 0.1894\n",
      "Epoch 45/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9491 - val_loss: 0.1901\n",
      "Epoch 46/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9487 - val_loss: 0.1910\n",
      "Epoch 47/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9484 - val_loss: 0.1919\n",
      "Epoch 48/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9491 - val_loss: 0.1929\n",
      "Epoch 49/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9491 - val_loss: 0.1940\n",
      "Epoch 50/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9484 - val_loss: 0.1953\n",
      "Epoch 51/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 1.0000 - loss: 8.9772e-04 - val_accuracy: 0.9501 - val_loss: 0.1966\n",
      "Epoch 52/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 1.0000 - loss: 7.5334e-04 - val_accuracy: 0.9501 - val_loss: 0.1981\n",
      "Epoch 53/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 1.0000 - loss: 6.3166e-04 - val_accuracy: 0.9511 - val_loss: 0.1996\n",
      "Epoch 54/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 1.0000 - loss: 5.2919e-04 - val_accuracy: 0.9518 - val_loss: 0.2013\n",
      "Epoch 55/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step - accuracy: 1.0000 - loss: 4.4298e-04 - val_accuracy: 0.9511 - val_loss: 0.2031\n",
      "Epoch 56/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - accuracy: 1.0000 - loss: 3.7050e-04 - val_accuracy: 0.9508 - val_loss: 0.2049\n",
      "Epoch 57/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step - accuracy: 1.0000 - loss: 3.0961e-04 - val_accuracy: 0.9511 - val_loss: 0.2069\n",
      "Epoch 58/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step - accuracy: 1.0000 - loss: 2.5850e-04 - val_accuracy: 0.9521 - val_loss: 0.2089\n",
      "Epoch 59/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - accuracy: 1.0000 - loss: 2.1564e-04 - val_accuracy: 0.9518 - val_loss: 0.2110\n",
      "Epoch 60/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 1.0000 - loss: 1.7972e-04 - val_accuracy: 0.9521 - val_loss: 0.2133\n",
      "Epoch 61/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 823us/step - accuracy: 1.0000 - loss: 1.4966e-04 - val_accuracy: 0.9528 - val_loss: 0.2156\n",
      "Epoch 62/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step - accuracy: 1.0000 - loss: 1.2453e-04 - val_accuracy: 0.9528 - val_loss: 0.2180\n",
      "Epoch 63/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 940us/step - accuracy: 1.0000 - loss: 1.0355e-04 - val_accuracy: 0.9532 - val_loss: 0.2204\n",
      "Epoch 64/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - accuracy: 1.0000 - loss: 8.6060e-05 - val_accuracy: 0.9528 - val_loss: 0.2230\n",
      "Epoch 65/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 792us/step - accuracy: 1.0000 - loss: 7.1485e-05 - val_accuracy: 0.9535 - val_loss: 0.2256\n",
      "Epoch 66/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803us/step - accuracy: 1.0000 - loss: 5.9356e-05 - val_accuracy: 0.9545 - val_loss: 0.2283\n",
      "Epoch 67/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 791us/step - accuracy: 1.0000 - loss: 4.9267e-05 - val_accuracy: 0.9538 - val_loss: 0.2311\n",
      "Epoch 68/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - accuracy: 1.0000 - loss: 4.0881e-05 - val_accuracy: 0.9542 - val_loss: 0.2340\n",
      "Epoch 69/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 831us/step - accuracy: 1.0000 - loss: 3.3913e-05 - val_accuracy: 0.9542 - val_loss: 0.2370\n",
      "Epoch 70/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 807us/step - accuracy: 1.0000 - loss: 2.8130e-05 - val_accuracy: 0.9542 - val_loss: 0.2401\n",
      "Epoch 71/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 940us/step - accuracy: 1.0000 - loss: 2.3332e-05 - val_accuracy: 0.9535 - val_loss: 0.2432\n",
      "Epoch 72/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - accuracy: 1.0000 - loss: 1.9351e-05 - val_accuracy: 0.9538 - val_loss: 0.2464\n",
      "Epoch 73/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 1.0000 - loss: 1.6054e-05 - val_accuracy: 0.9535 - val_loss: 0.2497\n",
      "Epoch 74/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 811us/step - accuracy: 1.0000 - loss: 1.3325e-05 - val_accuracy: 0.9535 - val_loss: 0.2530\n",
      "Epoch 75/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 1.0000 - loss: 1.1064e-05 - val_accuracy: 0.9535 - val_loss: 0.2564\n",
      "Epoch 76/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 1.0000 - loss: 9.1968e-06 - val_accuracy: 0.9525 - val_loss: 0.2597\n",
      "Epoch 77/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 799us/step - accuracy: 1.0000 - loss: 7.6483e-06 - val_accuracy: 0.9521 - val_loss: 0.2632\n",
      "Epoch 78/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 808us/step - accuracy: 1.0000 - loss: 6.3697e-06 - val_accuracy: 0.9525 - val_loss: 0.2666\n",
      "Epoch 79/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - accuracy: 1.0000 - loss: 5.3144e-06 - val_accuracy: 0.9521 - val_loss: 0.2701\n",
      "Epoch 80/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 1.0000 - loss: 4.4398e-06 - val_accuracy: 0.9521 - val_loss: 0.2736\n",
      "Epoch 81/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 1.0000 - loss: 3.7186e-06 - val_accuracy: 0.9511 - val_loss: 0.2772\n",
      "Epoch 82/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - accuracy: 1.0000 - loss: 3.1241e-06 - val_accuracy: 0.9518 - val_loss: 0.2807\n",
      "Epoch 83/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 1.0000 - loss: 2.6304e-06 - val_accuracy: 0.9515 - val_loss: 0.2842\n",
      "Epoch 84/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 1.0000 - loss: 2.2240e-06 - val_accuracy: 0.9518 - val_loss: 0.2877\n",
      "Epoch 85/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 1.0000 - loss: 1.8846e-06 - val_accuracy: 0.9521 - val_loss: 0.2911\n",
      "Epoch 86/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - accuracy: 1.0000 - loss: 1.6047e-06 - val_accuracy: 0.9518 - val_loss: 0.2944\n",
      "Epoch 87/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 1.0000 - loss: 1.3725e-06 - val_accuracy: 0.9518 - val_loss: 0.2977\n",
      "Epoch 88/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 892us/step - accuracy: 1.0000 - loss: 1.1784e-06 - val_accuracy: 0.9518 - val_loss: 0.3007\n",
      "Epoch 89/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 1.0000 - loss: 1.0182e-06 - val_accuracy: 0.9511 - val_loss: 0.3037\n",
      "Epoch 90/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 1.0000 - loss: 8.8114e-07 - val_accuracy: 0.9511 - val_loss: 0.3065\n",
      "Epoch 91/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step - accuracy: 1.0000 - loss: 7.7051e-07 - val_accuracy: 0.9511 - val_loss: 0.3092\n",
      "Epoch 92/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - accuracy: 1.0000 - loss: 6.7378e-07 - val_accuracy: 0.9511 - val_loss: 0.3117\n",
      "Epoch 93/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 1.0000 - loss: 5.9399e-07 - val_accuracy: 0.9518 - val_loss: 0.3142\n",
      "Epoch 94/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 901us/step - accuracy: 1.0000 - loss: 5.2485e-07 - val_accuracy: 0.9511 - val_loss: 0.3166\n",
      "Epoch 95/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 1.0000 - loss: 4.6917e-07 - val_accuracy: 0.9511 - val_loss: 0.3187\n",
      "Epoch 96/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 804us/step - accuracy: 1.0000 - loss: 4.1945e-07 - val_accuracy: 0.9504 - val_loss: 0.3211\n",
      "Epoch 97/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 892us/step - accuracy: 1.0000 - loss: 3.7714e-07 - val_accuracy: 0.9501 - val_loss: 0.3232\n",
      "Epoch 98/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step - accuracy: 1.0000 - loss: 3.4132e-07 - val_accuracy: 0.9508 - val_loss: 0.3254\n",
      "Epoch 99/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 804us/step - accuracy: 1.0000 - loss: 3.1023e-07 - val_accuracy: 0.9501 - val_loss: 0.3272\n",
      "Epoch 100/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 1.0000 - loss: 2.8222e-07 - val_accuracy: 0.9501 - val_loss: 0.3288\n",
      "Epoch 101/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 798us/step - accuracy: 1.0000 - loss: 2.6003e-07 - val_accuracy: 0.9504 - val_loss: 0.3305\n",
      "Epoch 102/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - accuracy: 1.0000 - loss: 2.3837e-07 - val_accuracy: 0.9508 - val_loss: 0.3318\n",
      "Epoch 103/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800us/step - accuracy: 1.0000 - loss: 2.2021e-07 - val_accuracy: 0.9508 - val_loss: 0.3332\n",
      "Epoch 104/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 819us/step - accuracy: 1.0000 - loss: 2.0425e-07 - val_accuracy: 0.9504 - val_loss: 0.3346\n",
      "Epoch 105/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 1.0000 - loss: 1.9025e-07 - val_accuracy: 0.9497 - val_loss: 0.3359\n",
      "Epoch 106/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 812us/step - accuracy: 1.0000 - loss: 1.7833e-07 - val_accuracy: 0.9497 - val_loss: 0.3373\n",
      "Epoch 107/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 1.0000 - loss: 1.6776e-07 - val_accuracy: 0.9497 - val_loss: 0.3385\n",
      "Epoch 108/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - accuracy: 1.0000 - loss: 1.5694e-07 - val_accuracy: 0.9497 - val_loss: 0.3395\n",
      "Epoch 109/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824us/step - accuracy: 1.0000 - loss: 1.4762e-07 - val_accuracy: 0.9494 - val_loss: 0.3404\n",
      "Epoch 110/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 814us/step - accuracy: 1.0000 - loss: 1.4008e-07 - val_accuracy: 0.9494 - val_loss: 0.3411\n",
      "Epoch 111/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 1.0000 - loss: 1.3299e-07 - val_accuracy: 0.9494 - val_loss: 0.3418\n",
      "Epoch 112/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 1.0000 - loss: 1.2535e-07 - val_accuracy: 0.9494 - val_loss: 0.3431\n",
      "Epoch 113/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 801us/step - accuracy: 1.0000 - loss: 1.2025e-07 - val_accuracy: 0.9497 - val_loss: 0.3439\n",
      "Epoch 114/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - accuracy: 1.0000 - loss: 1.1364e-07 - val_accuracy: 0.9497 - val_loss: 0.3443\n",
      "Epoch 115/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 801us/step - accuracy: 1.0000 - loss: 1.0957e-07 - val_accuracy: 0.9501 - val_loss: 0.3450\n",
      "Epoch 116/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 961us/step - accuracy: 1.0000 - loss: 1.0444e-07 - val_accuracy: 0.9501 - val_loss: 0.3457\n",
      "Epoch 117/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 956us/step - accuracy: 1.0000 - loss: 9.9630e-08 - val_accuracy: 0.9494 - val_loss: 0.3464\n",
      "Epoch 118/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 908us/step - accuracy: 1.0000 - loss: 9.4918e-08 - val_accuracy: 0.9497 - val_loss: 0.3470\n",
      "Epoch 119/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 1.0000 - loss: 9.1763e-08 - val_accuracy: 0.9501 - val_loss: 0.3478\n",
      "Epoch 120/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853us/step - accuracy: 1.0000 - loss: 8.7947e-08 - val_accuracy: 0.9501 - val_loss: 0.3482\n",
      "Epoch 121/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 1.0000 - loss: 8.4599e-08 - val_accuracy: 0.9501 - val_loss: 0.3488\n",
      "Epoch 122/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 1.0000 - loss: 8.1607e-08 - val_accuracy: 0.9501 - val_loss: 0.3495\n",
      "Epoch 123/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step - accuracy: 1.0000 - loss: 7.8848e-08 - val_accuracy: 0.9497 - val_loss: 0.3501\n",
      "Epoch 124/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step - accuracy: 1.0000 - loss: 7.6464e-08 - val_accuracy: 0.9497 - val_loss: 0.3506\n",
      "Epoch 125/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 1.0000 - loss: 7.4222e-08 - val_accuracy: 0.9497 - val_loss: 0.3509\n",
      "Epoch 126/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 1.0000 - loss: 7.2086e-08 - val_accuracy: 0.9497 - val_loss: 0.3512\n",
      "Epoch 127/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step - accuracy: 1.0000 - loss: 6.9588e-08 - val_accuracy: 0.9501 - val_loss: 0.3519\n",
      "Epoch 128/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - accuracy: 1.0000 - loss: 6.7625e-08 - val_accuracy: 0.9497 - val_loss: 0.3522\n",
      "Epoch 129/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 908us/step - accuracy: 1.0000 - loss: 6.5691e-08 - val_accuracy: 0.9497 - val_loss: 0.3528\n",
      "Epoch 130/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - accuracy: 1.0000 - loss: 6.3620e-08 - val_accuracy: 0.9497 - val_loss: 0.3533\n",
      "Epoch 131/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 887us/step - accuracy: 1.0000 - loss: 6.1767e-08 - val_accuracy: 0.9497 - val_loss: 0.3538\n",
      "Epoch 132/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 1.0000 - loss: 6.0951e-08 - val_accuracy: 0.9497 - val_loss: 0.3540\n",
      "Epoch 133/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 882us/step - accuracy: 1.0000 - loss: 5.8870e-08 - val_accuracy: 0.9497 - val_loss: 0.3548\n",
      "Epoch 134/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 872us/step - accuracy: 1.0000 - loss: 5.7755e-08 - val_accuracy: 0.9497 - val_loss: 0.3552\n",
      "Epoch 135/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 1.0000 - loss: 5.6177e-08 - val_accuracy: 0.9497 - val_loss: 0.3550\n",
      "Epoch 136/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 1.0000 - loss: 5.4120e-08 - val_accuracy: 0.9497 - val_loss: 0.3561\n",
      "Epoch 137/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 1.0000 - loss: 5.3065e-08 - val_accuracy: 0.9497 - val_loss: 0.3565\n",
      "Epoch 138/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 1.0000 - loss: 5.1371e-08 - val_accuracy: 0.9491 - val_loss: 0.3571\n",
      "Epoch 139/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 937us/step - accuracy: 1.0000 - loss: 5.1458e-08 - val_accuracy: 0.9491 - val_loss: 0.3577\n",
      "Epoch 140/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 1.0000 - loss: 4.9558e-08 - val_accuracy: 0.9491 - val_loss: 0.3582\n",
      "Epoch 141/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 942us/step - accuracy: 1.0000 - loss: 4.8835e-08 - val_accuracy: 0.9487 - val_loss: 0.3584\n",
      "Epoch 142/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 1.0000 - loss: 4.7827e-08 - val_accuracy: 0.9491 - val_loss: 0.3589\n",
      "Epoch 143/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 1.0000 - loss: 4.6148e-08 - val_accuracy: 0.9484 - val_loss: 0.3596\n",
      "Epoch 144/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.6311e-08 - val_accuracy: 0.9491 - val_loss: 0.3598\n",
      "Epoch 145/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 965us/step - accuracy: 1.0000 - loss: 4.4790e-08 - val_accuracy: 0.9484 - val_loss: 0.3603\n",
      "Epoch 146/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 1.0000 - loss: 4.4314e-08 - val_accuracy: 0.9484 - val_loss: 0.3603\n",
      "Epoch 147/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 1.0000 - loss: 4.3182e-08 - val_accuracy: 0.9491 - val_loss: 0.3607\n",
      "Epoch 148/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 985us/step - accuracy: 1.0000 - loss: 4.2480e-08 - val_accuracy: 0.9491 - val_loss: 0.3608\n",
      "Epoch 149/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 1.0000 - loss: 4.1607e-08 - val_accuracy: 0.9491 - val_loss: 0.3615\n",
      "Epoch 150/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step - accuracy: 1.0000 - loss: 4.1313e-08 - val_accuracy: 0.9487 - val_loss: 0.3616\n",
      "Epoch 151/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.0623e-08 - val_accuracy: 0.9487 - val_loss: 0.3620\n",
      "Epoch 152/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 935us/step - accuracy: 1.0000 - loss: 4.0111e-08 - val_accuracy: 0.9491 - val_loss: 0.3623\n",
      "Epoch 153/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 969us/step - accuracy: 1.0000 - loss: 3.9368e-08 - val_accuracy: 0.9480 - val_loss: 0.3624\n",
      "Epoch 154/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.8914e-08 - val_accuracy: 0.9484 - val_loss: 0.3628\n",
      "Epoch 155/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 973us/step - accuracy: 1.0000 - loss: 3.7938e-08 - val_accuracy: 0.9487 - val_loss: 0.3633\n",
      "Epoch 156/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 901us/step - accuracy: 1.0000 - loss: 3.7891e-08 - val_accuracy: 0.9484 - val_loss: 0.3635\n",
      "Epoch 157/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - accuracy: 1.0000 - loss: 3.7240e-08 - val_accuracy: 0.9480 - val_loss: 0.3640\n",
      "Epoch 158/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 970us/step - accuracy: 1.0000 - loss: 3.6936e-08 - val_accuracy: 0.9480 - val_loss: 0.3642\n",
      "Epoch 159/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.6705e-08 - val_accuracy: 0.9480 - val_loss: 0.3645\n",
      "Epoch 160/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.5409e-08 - val_accuracy: 0.9477 - val_loss: 0.3652\n",
      "Epoch 161/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 985us/step - accuracy: 1.0000 - loss: 3.5555e-08 - val_accuracy: 0.9477 - val_loss: 0.3650\n",
      "Epoch 162/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864us/step - accuracy: 1.0000 - loss: 3.4623e-08 - val_accuracy: 0.9477 - val_loss: 0.3654\n",
      "Epoch 163/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 1.0000 - loss: 3.5209e-08 - val_accuracy: 0.9477 - val_loss: 0.3657\n",
      "Epoch 164/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 885us/step - accuracy: 1.0000 - loss: 3.4144e-08 - val_accuracy: 0.9477 - val_loss: 0.3662\n",
      "Epoch 165/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 1.0000 - loss: 3.3803e-08 - val_accuracy: 0.9467 - val_loss: 0.3659\n",
      "Epoch 166/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 1.0000 - loss: 3.3893e-08 - val_accuracy: 0.9474 - val_loss: 0.3667\n",
      "Epoch 167/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - accuracy: 1.0000 - loss: 3.3051e-08 - val_accuracy: 0.9480 - val_loss: 0.3670\n",
      "Epoch 168/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 823us/step - accuracy: 1.0000 - loss: 3.2450e-08 - val_accuracy: 0.9477 - val_loss: 0.3670\n",
      "Epoch 169/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 813us/step - accuracy: 1.0000 - loss: 3.2892e-08 - val_accuracy: 0.9480 - val_loss: 0.3677\n",
      "Epoch 170/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800us/step - accuracy: 1.0000 - loss: 3.1500e-08 - val_accuracy: 0.9480 - val_loss: 0.3679\n",
      "Epoch 171/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 1.0000 - loss: 3.1894e-08 - val_accuracy: 0.9480 - val_loss: 0.3686\n",
      "Epoch 172/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 819us/step - accuracy: 1.0000 - loss: 3.1731e-08 - val_accuracy: 0.9480 - val_loss: 0.3685\n",
      "Epoch 173/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 797us/step - accuracy: 1.0000 - loss: 3.0892e-08 - val_accuracy: 0.9480 - val_loss: 0.3689\n",
      "Epoch 174/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 1.0000 - loss: 3.1167e-08 - val_accuracy: 0.9477 - val_loss: 0.3693\n",
      "Epoch 175/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step - accuracy: 1.0000 - loss: 2.9949e-08 - val_accuracy: 0.9474 - val_loss: 0.3694\n",
      "Epoch 176/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - accuracy: 1.0000 - loss: 3.0332e-08 - val_accuracy: 0.9480 - val_loss: 0.3698\n",
      "Epoch 177/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - accuracy: 1.0000 - loss: 2.9798e-08 - val_accuracy: 0.9474 - val_loss: 0.3700\n",
      "Epoch 178/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 831us/step - accuracy: 1.0000 - loss: 2.9620e-08 - val_accuracy: 0.9477 - val_loss: 0.3702\n",
      "Epoch 179/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 792us/step - accuracy: 1.0000 - loss: 2.9227e-08 - val_accuracy: 0.9477 - val_loss: 0.3707\n",
      "Epoch 180/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 805us/step - accuracy: 1.0000 - loss: 2.9380e-08 - val_accuracy: 0.9477 - val_loss: 0.3707\n",
      "Epoch 181/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 802us/step - accuracy: 1.0000 - loss: 2.8915e-08 - val_accuracy: 0.9470 - val_loss: 0.3711\n",
      "Epoch 182/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 1.0000 - loss: 2.8874e-08 - val_accuracy: 0.9470 - val_loss: 0.3714\n",
      "Epoch 183/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 1.0000 - loss: 2.8284e-08 - val_accuracy: 0.9477 - val_loss: 0.3715\n",
      "Epoch 184/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 1.0000 - loss: 2.8204e-08 - val_accuracy: 0.9474 - val_loss: 0.3722\n",
      "Epoch 185/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 1.0000 - loss: 2.7588e-08 - val_accuracy: 0.9477 - val_loss: 0.3725\n",
      "Epoch 186/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 1.0000 - loss: 2.7545e-08 - val_accuracy: 0.9477 - val_loss: 0.3723\n",
      "Epoch 187/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - accuracy: 1.0000 - loss: 2.7770e-08 - val_accuracy: 0.9477 - val_loss: 0.3725\n",
      "Epoch 188/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 1.0000 - loss: 2.7171e-08 - val_accuracy: 0.9474 - val_loss: 0.3727\n",
      "Epoch 189/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 1.0000 - loss: 2.6705e-08 - val_accuracy: 0.9470 - val_loss: 0.3730\n",
      "Epoch 190/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 831us/step - accuracy: 1.0000 - loss: 2.7264e-08 - val_accuracy: 0.9474 - val_loss: 0.3731\n",
      "Epoch 191/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824us/step - accuracy: 1.0000 - loss: 2.6851e-08 - val_accuracy: 0.9474 - val_loss: 0.3737\n",
      "Epoch 192/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 1.0000 - loss: 2.6272e-08 - val_accuracy: 0.9474 - val_loss: 0.3738\n",
      "Epoch 193/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 1.0000 - loss: 2.6225e-08 - val_accuracy: 0.9480 - val_loss: 0.3740\n",
      "Epoch 194/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 814us/step - accuracy: 1.0000 - loss: 2.6354e-08 - val_accuracy: 0.9467 - val_loss: 0.3742\n",
      "Epoch 195/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 1.0000 - loss: 2.5900e-08 - val_accuracy: 0.9467 - val_loss: 0.3741\n",
      "Epoch 196/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 1.0000 - loss: 2.5841e-08 - val_accuracy: 0.9467 - val_loss: 0.3745\n",
      "Epoch 197/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step - accuracy: 1.0000 - loss: 2.5016e-08 - val_accuracy: 0.9467 - val_loss: 0.3748\n",
      "Epoch 198/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - accuracy: 1.0000 - loss: 2.5787e-08 - val_accuracy: 0.9467 - val_loss: 0.3747\n",
      "Epoch 199/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - accuracy: 1.0000 - loss: 2.5078e-08 - val_accuracy: 0.9467 - val_loss: 0.3754\n",
      "Epoch 200/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 814us/step - accuracy: 1.0000 - loss: 2.4872e-08 - val_accuracy: 0.9467 - val_loss: 0.3755\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "prueba_19: \n",
      "Epoch 1/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 966us/step - accuracy: 0.1754 - loss: 2.7804 - val_accuracy: 0.4930 - val_loss: 2.1270\n",
      "Epoch 2/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 831us/step - accuracy: 0.6285 - loss: 1.8429 - val_accuracy: 0.7655 - val_loss: 1.2253\n",
      "Epoch 3/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step - accuracy: 0.8231 - loss: 1.0573 - val_accuracy: 0.8489 - val_loss: 0.7920\n",
      "Epoch 4/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 810us/step - accuracy: 0.8847 - loss: 0.6761 - val_accuracy: 0.8885 - val_loss: 0.5659\n",
      "Epoch 5/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - accuracy: 0.9231 - loss: 0.4682 - val_accuracy: 0.9091 - val_loss: 0.4307\n",
      "Epoch 6/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 0.9487 - loss: 0.3411 - val_accuracy: 0.9241 - val_loss: 0.3430\n",
      "Epoch 7/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - accuracy: 0.9620 - loss: 0.2572 - val_accuracy: 0.9330 - val_loss: 0.2826\n",
      "Epoch 8/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - accuracy: 0.9716 - loss: 0.1984 - val_accuracy: 0.9415 - val_loss: 0.2386\n",
      "Epoch 9/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 897us/step - accuracy: 0.9768 - loss: 0.1551 - val_accuracy: 0.9508 - val_loss: 0.2055\n",
      "Epoch 10/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 804us/step - accuracy: 0.9815 - loss: 0.1222 - val_accuracy: 0.9583 - val_loss: 0.1798\n",
      "Epoch 11/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 0.9870 - loss: 0.0967 - val_accuracy: 0.9621 - val_loss: 0.1594\n",
      "Epoch 12/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 975us/step - accuracy: 0.9929 - loss: 0.0765 - val_accuracy: 0.9644 - val_loss: 0.1430\n",
      "Epoch 13/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9961 - loss: 0.0604 - val_accuracy: 0.9641 - val_loss: 0.1295\n",
      "Epoch 14/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9985 - loss: 0.0475 - val_accuracy: 0.9682 - val_loss: 0.1184\n",
      "Epoch 15/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 998us/step - accuracy: 0.9990 - loss: 0.0373 - val_accuracy: 0.9699 - val_loss: 0.1094\n",
      "Epoch 16/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 922us/step - accuracy: 0.9994 - loss: 0.0293 - val_accuracy: 0.9713 - val_loss: 0.1019\n",
      "Epoch 17/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 0.9997 - loss: 0.0229 - val_accuracy: 0.9720 - val_loss: 0.0956\n",
      "Epoch 18/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 1.0000 - loss: 0.0179 - val_accuracy: 0.9730 - val_loss: 0.0904\n",
      "Epoch 19/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861us/step - accuracy: 1.0000 - loss: 0.0140 - val_accuracy: 0.9744 - val_loss: 0.0860\n",
      "Epoch 20/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.9754 - val_loss: 0.0824\n",
      "Epoch 21/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.9764 - val_loss: 0.0794\n",
      "Epoch 22/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.9764 - val_loss: 0.0770\n",
      "Epoch 23/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9771 - val_loss: 0.0751\n",
      "Epoch 24/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9778 - val_loss: 0.0735\n",
      "Epoch 25/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9778 - val_loss: 0.0723\n",
      "Epoch 26/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 967us/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9785 - val_loss: 0.0713\n",
      "Epoch 27/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 884us/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9781 - val_loss: 0.0706\n",
      "Epoch 28/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9788 - val_loss: 0.0701\n",
      "Epoch 29/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9791 - val_loss: 0.0698\n",
      "Epoch 30/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - accuracy: 1.0000 - loss: 8.3342e-04 - val_accuracy: 0.9795 - val_loss: 0.0697\n",
      "Epoch 31/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 1.0000 - loss: 6.3912e-04 - val_accuracy: 0.9798 - val_loss: 0.0697\n",
      "Epoch 32/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 1.0000 - loss: 4.8949e-04 - val_accuracy: 0.9802 - val_loss: 0.0699\n",
      "Epoch 33/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - accuracy: 1.0000 - loss: 3.7445e-04 - val_accuracy: 0.9809 - val_loss: 0.0701\n",
      "Epoch 34/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 1.0000 - loss: 2.8615e-04 - val_accuracy: 0.9809 - val_loss: 0.0704\n",
      "Epoch 35/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 1.0000 - loss: 2.1845e-04 - val_accuracy: 0.9812 - val_loss: 0.0709\n",
      "Epoch 36/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - accuracy: 1.0000 - loss: 1.6664e-04 - val_accuracy: 0.9812 - val_loss: 0.0714\n",
      "Epoch 37/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864us/step - accuracy: 1.0000 - loss: 1.2701e-04 - val_accuracy: 0.9812 - val_loss: 0.0719\n",
      "Epoch 38/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 1.0000 - loss: 9.6739e-05 - val_accuracy: 0.9819 - val_loss: 0.0725\n",
      "Epoch 39/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - accuracy: 1.0000 - loss: 7.3644e-05 - val_accuracy: 0.9815 - val_loss: 0.0731\n",
      "Epoch 40/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 823us/step - accuracy: 1.0000 - loss: 5.6034e-05 - val_accuracy: 0.9815 - val_loss: 0.0738\n",
      "Epoch 41/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - accuracy: 1.0000 - loss: 4.2622e-05 - val_accuracy: 0.9822 - val_loss: 0.0745\n",
      "Epoch 42/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 811us/step - accuracy: 1.0000 - loss: 3.2413e-05 - val_accuracy: 0.9826 - val_loss: 0.0753\n",
      "Epoch 43/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 1.0000 - loss: 2.4651e-05 - val_accuracy: 0.9826 - val_loss: 0.0760\n",
      "Epoch 44/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861us/step - accuracy: 1.0000 - loss: 1.8753e-05 - val_accuracy: 0.9826 - val_loss: 0.0768\n",
      "Epoch 45/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 887us/step - accuracy: 1.0000 - loss: 1.4271e-05 - val_accuracy: 0.9822 - val_loss: 0.0776\n",
      "Epoch 46/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 1.0000 - loss: 1.0867e-05 - val_accuracy: 0.9822 - val_loss: 0.0784\n",
      "Epoch 47/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 1.0000 - loss: 8.2868e-06 - val_accuracy: 0.9822 - val_loss: 0.0792\n",
      "Epoch 48/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 1.0000 - loss: 6.3261e-06 - val_accuracy: 0.9822 - val_loss: 0.0800\n",
      "Epoch 49/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 945us/step - accuracy: 1.0000 - loss: 4.8413e-06 - val_accuracy: 0.9822 - val_loss: 0.0808\n",
      "Epoch 50/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step - accuracy: 1.0000 - loss: 3.7174e-06 - val_accuracy: 0.9815 - val_loss: 0.0816\n",
      "Epoch 51/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 1.0000 - loss: 2.8630e-06 - val_accuracy: 0.9815 - val_loss: 0.0824\n",
      "Epoch 52/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 1.0000 - loss: 2.2168e-06 - val_accuracy: 0.9815 - val_loss: 0.0832\n",
      "Epoch 53/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 885us/step - accuracy: 1.0000 - loss: 1.7254e-06 - val_accuracy: 0.9812 - val_loss: 0.0840\n",
      "Epoch 54/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 1.0000 - loss: 1.3532e-06 - val_accuracy: 0.9812 - val_loss: 0.0847\n",
      "Epoch 55/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 997us/step - accuracy: 1.0000 - loss: 1.0695e-06 - val_accuracy: 0.9815 - val_loss: 0.0855\n",
      "Epoch 56/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 882us/step - accuracy: 1.0000 - loss: 8.5181e-07 - val_accuracy: 0.9819 - val_loss: 0.0862\n",
      "Epoch 57/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 910us/step - accuracy: 1.0000 - loss: 6.8865e-07 - val_accuracy: 0.9819 - val_loss: 0.0869\n",
      "Epoch 58/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867us/step - accuracy: 1.0000 - loss: 5.6047e-07 - val_accuracy: 0.9822 - val_loss: 0.0875\n",
      "Epoch 59/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 1.0000 - loss: 4.6173e-07 - val_accuracy: 0.9829 - val_loss: 0.0882\n",
      "Epoch 60/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 1.0000 - loss: 3.8528e-07 - val_accuracy: 0.9832 - val_loss: 0.0888\n",
      "Epoch 61/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - accuracy: 1.0000 - loss: 3.2319e-07 - val_accuracy: 0.9832 - val_loss: 0.0893\n",
      "Epoch 62/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861us/step - accuracy: 1.0000 - loss: 2.7737e-07 - val_accuracy: 0.9829 - val_loss: 0.0898\n",
      "Epoch 63/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 1.0000 - loss: 2.3998e-07 - val_accuracy: 0.9836 - val_loss: 0.0903\n",
      "Epoch 64/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 955us/step - accuracy: 1.0000 - loss: 2.0899e-07 - val_accuracy: 0.9836 - val_loss: 0.0907\n",
      "Epoch 65/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911us/step - accuracy: 1.0000 - loss: 1.8424e-07 - val_accuracy: 0.9832 - val_loss: 0.0909\n",
      "Epoch 66/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 887us/step - accuracy: 1.0000 - loss: 1.6348e-07 - val_accuracy: 0.9836 - val_loss: 0.0911\n",
      "Epoch 67/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 949us/step - accuracy: 1.0000 - loss: 1.4709e-07 - val_accuracy: 0.9836 - val_loss: 0.0915\n",
      "Epoch 68/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 932us/step - accuracy: 1.0000 - loss: 1.3264e-07 - val_accuracy: 0.9836 - val_loss: 0.0918\n",
      "Epoch 69/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 1.0000 - loss: 1.2051e-07 - val_accuracy: 0.9836 - val_loss: 0.0920\n",
      "Epoch 70/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867us/step - accuracy: 1.0000 - loss: 1.0990e-07 - val_accuracy: 0.9832 - val_loss: 0.0922\n",
      "Epoch 71/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 1.0000 - loss: 1.0064e-07 - val_accuracy: 0.9829 - val_loss: 0.0924\n",
      "Epoch 72/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 1.0000 - loss: 9.2829e-08 - val_accuracy: 0.9829 - val_loss: 0.0925\n",
      "Epoch 73/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 960us/step - accuracy: 1.0000 - loss: 8.6889e-08 - val_accuracy: 0.9829 - val_loss: 0.0926\n",
      "Epoch 74/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 917us/step - accuracy: 1.0000 - loss: 8.1556e-08 - val_accuracy: 0.9829 - val_loss: 0.0928\n",
      "Epoch 75/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 1.0000 - loss: 7.5961e-08 - val_accuracy: 0.9829 - val_loss: 0.0929\n",
      "Epoch 76/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 1.0000 - loss: 7.2107e-08 - val_accuracy: 0.9829 - val_loss: 0.0930\n",
      "Epoch 77/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 1.0000 - loss: 6.7294e-08 - val_accuracy: 0.9829 - val_loss: 0.0931\n",
      "Epoch 78/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 1.0000 - loss: 6.4062e-08 - val_accuracy: 0.9829 - val_loss: 0.0931\n",
      "Epoch 79/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 1.0000 - loss: 6.0610e-08 - val_accuracy: 0.9836 - val_loss: 0.0931\n",
      "Epoch 80/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 1.0000 - loss: 5.7878e-08 - val_accuracy: 0.9836 - val_loss: 0.0932\n",
      "Epoch 81/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 1.0000 - loss: 5.5592e-08 - val_accuracy: 0.9836 - val_loss: 0.0932\n",
      "Epoch 82/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 1.0000 - loss: 5.3138e-08 - val_accuracy: 0.9836 - val_loss: 0.0933\n",
      "Epoch 83/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835us/step - accuracy: 1.0000 - loss: 5.0403e-08 - val_accuracy: 0.9836 - val_loss: 0.0934\n",
      "Epoch 84/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - accuracy: 1.0000 - loss: 4.8706e-08 - val_accuracy: 0.9839 - val_loss: 0.0934\n",
      "Epoch 85/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - accuracy: 1.0000 - loss: 4.6433e-08 - val_accuracy: 0.9839 - val_loss: 0.0934\n",
      "Epoch 86/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 1.0000 - loss: 4.4437e-08 - val_accuracy: 0.9839 - val_loss: 0.0934\n",
      "Epoch 87/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 1.0000 - loss: 4.2359e-08 - val_accuracy: 0.9839 - val_loss: 0.0934\n",
      "Epoch 88/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 1.0000 - loss: 4.0715e-08 - val_accuracy: 0.9839 - val_loss: 0.0934\n",
      "Epoch 89/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 1.0000 - loss: 3.9524e-08 - val_accuracy: 0.9839 - val_loss: 0.0934\n",
      "Epoch 90/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 808us/step - accuracy: 1.0000 - loss: 3.8254e-08 - val_accuracy: 0.9839 - val_loss: 0.0934\n",
      "Epoch 91/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 1.0000 - loss: 3.7025e-08 - val_accuracy: 0.9839 - val_loss: 0.0933\n",
      "Epoch 92/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 936us/step - accuracy: 1.0000 - loss: 3.5665e-08 - val_accuracy: 0.9843 - val_loss: 0.0933\n",
      "Epoch 93/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 945us/step - accuracy: 1.0000 - loss: 3.4921e-08 - val_accuracy: 0.9843 - val_loss: 0.0934\n",
      "Epoch 94/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 1.0000 - loss: 3.3441e-08 - val_accuracy: 0.9843 - val_loss: 0.0933\n",
      "Epoch 95/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 1.0000 - loss: 3.3184e-08 - val_accuracy: 0.9843 - val_loss: 0.0934\n",
      "Epoch 96/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 1.0000 - loss: 3.1862e-08 - val_accuracy: 0.9839 - val_loss: 0.0933\n",
      "Epoch 97/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 1.0000 - loss: 3.1045e-08 - val_accuracy: 0.9843 - val_loss: 0.0933\n",
      "Epoch 98/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 802us/step - accuracy: 1.0000 - loss: 3.0153e-08 - val_accuracy: 0.9843 - val_loss: 0.0933\n",
      "Epoch 99/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 1.0000 - loss: 2.9941e-08 - val_accuracy: 0.9843 - val_loss: 0.0932\n",
      "Epoch 100/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 1.0000 - loss: 2.8870e-08 - val_accuracy: 0.9839 - val_loss: 0.0932\n",
      "Epoch 101/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 1.0000 - loss: 2.8427e-08 - val_accuracy: 0.9836 - val_loss: 0.0933\n",
      "Epoch 102/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 811us/step - accuracy: 1.0000 - loss: 2.7876e-08 - val_accuracy: 0.9836 - val_loss: 0.0932\n",
      "Epoch 103/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 1.0000 - loss: 2.6949e-08 - val_accuracy: 0.9836 - val_loss: 0.0932\n",
      "Epoch 104/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 822us/step - accuracy: 1.0000 - loss: 2.6342e-08 - val_accuracy: 0.9836 - val_loss: 0.0933\n",
      "Epoch 105/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 1.0000 - loss: 2.5834e-08 - val_accuracy: 0.9832 - val_loss: 0.0933\n",
      "Epoch 106/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - accuracy: 1.0000 - loss: 2.4895e-08 - val_accuracy: 0.9832 - val_loss: 0.0931\n",
      "Epoch 107/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - accuracy: 1.0000 - loss: 2.5094e-08 - val_accuracy: 0.9829 - val_loss: 0.0931\n",
      "Epoch 108/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - accuracy: 1.0000 - loss: 2.4332e-08 - val_accuracy: 0.9829 - val_loss: 0.0930\n",
      "Epoch 109/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.4010e-08 - val_accuracy: 0.9829 - val_loss: 0.0929\n",
      "Epoch 110/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.3815e-08 - val_accuracy: 0.9826 - val_loss: 0.0930\n",
      "Epoch 111/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 941us/step - accuracy: 1.0000 - loss: 2.3399e-08 - val_accuracy: 0.9826 - val_loss: 0.0930\n",
      "Epoch 112/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 1.0000 - loss: 2.3069e-08 - val_accuracy: 0.9826 - val_loss: 0.0928\n",
      "Epoch 113/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step - accuracy: 1.0000 - loss: 2.2788e-08 - val_accuracy: 0.9826 - val_loss: 0.0929\n",
      "Epoch 114/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 810us/step - accuracy: 1.0000 - loss: 2.2195e-08 - val_accuracy: 0.9826 - val_loss: 0.0928\n",
      "Epoch 115/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step - accuracy: 1.0000 - loss: 2.2200e-08 - val_accuracy: 0.9826 - val_loss: 0.0928\n",
      "Epoch 116/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 1.0000 - loss: 2.1434e-08 - val_accuracy: 0.9826 - val_loss: 0.0928\n",
      "Epoch 117/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 1.0000 - loss: 2.1195e-08 - val_accuracy: 0.9826 - val_loss: 0.0927\n",
      "Epoch 118/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.1053e-08 - val_accuracy: 0.9826 - val_loss: 0.0926\n",
      "Epoch 119/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.0843e-08 - val_accuracy: 0.9822 - val_loss: 0.0926\n",
      "Epoch 120/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905us/step - accuracy: 1.0000 - loss: 2.0437e-08 - val_accuracy: 0.9822 - val_loss: 0.0927\n",
      "Epoch 121/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 994us/step - accuracy: 1.0000 - loss: 2.0611e-08 - val_accuracy: 0.9819 - val_loss: 0.0927\n",
      "Epoch 122/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - accuracy: 1.0000 - loss: 2.0064e-08 - val_accuracy: 0.9819 - val_loss: 0.0926\n",
      "Epoch 123/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 1.0000 - loss: 1.9834e-08 - val_accuracy: 0.9819 - val_loss: 0.0926\n",
      "Epoch 124/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 1.0000 - loss: 1.9467e-08 - val_accuracy: 0.9819 - val_loss: 0.0926\n",
      "Epoch 125/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 1.0000 - loss: 1.9555e-08 - val_accuracy: 0.9819 - val_loss: 0.0926\n",
      "Epoch 126/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 1.0000 - loss: 1.9127e-08 - val_accuracy: 0.9819 - val_loss: 0.0927\n",
      "Epoch 127/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 1.0000 - loss: 1.8821e-08 - val_accuracy: 0.9819 - val_loss: 0.0925\n",
      "Epoch 128/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - accuracy: 1.0000 - loss: 1.8775e-08 - val_accuracy: 0.9819 - val_loss: 0.0927\n",
      "Epoch 129/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 1.0000 - loss: 1.8879e-08 - val_accuracy: 0.9819 - val_loss: 0.0926\n",
      "Epoch 130/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 1.0000 - loss: 1.8165e-08 - val_accuracy: 0.9819 - val_loss: 0.0927\n",
      "Epoch 131/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - accuracy: 1.0000 - loss: 1.8428e-08 - val_accuracy: 0.9819 - val_loss: 0.0927\n",
      "Epoch 132/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 988us/step - accuracy: 1.0000 - loss: 1.8178e-08 - val_accuracy: 0.9819 - val_loss: 0.0926\n",
      "Epoch 133/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 1.0000 - loss: 1.7931e-08 - val_accuracy: 0.9819 - val_loss: 0.0927\n",
      "Epoch 134/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 1.0000 - loss: 1.8119e-08 - val_accuracy: 0.9819 - val_loss: 0.0927\n",
      "Epoch 135/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 1.0000 - loss: 1.7871e-08 - val_accuracy: 0.9819 - val_loss: 0.0926\n",
      "Epoch 136/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 1.0000 - loss: 1.7503e-08 - val_accuracy: 0.9819 - val_loss: 0.0927\n",
      "Epoch 137/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 1.0000 - loss: 1.7295e-08 - val_accuracy: 0.9819 - val_loss: 0.0927\n",
      "Epoch 138/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 1.0000 - loss: 1.6954e-08 - val_accuracy: 0.9819 - val_loss: 0.0927\n",
      "Epoch 139/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 1.0000 - loss: 1.6893e-08 - val_accuracy: 0.9819 - val_loss: 0.0927\n",
      "Epoch 140/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 1.0000 - loss: 1.6721e-08 - val_accuracy: 0.9819 - val_loss: 0.0928\n",
      "Epoch 141/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 1.0000 - loss: 1.7012e-08 - val_accuracy: 0.9819 - val_loss: 0.0929\n",
      "Epoch 142/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 1.0000 - loss: 1.6990e-08 - val_accuracy: 0.9819 - val_loss: 0.0929\n",
      "Epoch 143/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - accuracy: 1.0000 - loss: 1.6353e-08 - val_accuracy: 0.9819 - val_loss: 0.0928\n",
      "Epoch 144/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - accuracy: 1.0000 - loss: 1.6632e-08 - val_accuracy: 0.9819 - val_loss: 0.0931\n",
      "Epoch 145/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 1.0000 - loss: 1.5860e-08 - val_accuracy: 0.9819 - val_loss: 0.0930\n",
      "Epoch 146/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 1.0000 - loss: 1.6546e-08 - val_accuracy: 0.9819 - val_loss: 0.0929\n",
      "Epoch 147/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - accuracy: 1.0000 - loss: 1.6086e-08 - val_accuracy: 0.9815 - val_loss: 0.0930\n",
      "Epoch 148/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 892us/step - accuracy: 1.0000 - loss: 1.6049e-08 - val_accuracy: 0.9819 - val_loss: 0.0931\n",
      "Epoch 149/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 1.0000 - loss: 1.5856e-08 - val_accuracy: 0.9812 - val_loss: 0.0931\n",
      "Epoch 150/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 1.0000 - loss: 1.6296e-08 - val_accuracy: 0.9812 - val_loss: 0.0933\n",
      "Epoch 151/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 1.0000 - loss: 1.6035e-08 - val_accuracy: 0.9812 - val_loss: 0.0931\n",
      "Epoch 152/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853us/step - accuracy: 1.0000 - loss: 1.5830e-08 - val_accuracy: 0.9812 - val_loss: 0.0931\n",
      "Epoch 153/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 950us/step - accuracy: 1.0000 - loss: 1.5618e-08 - val_accuracy: 0.9812 - val_loss: 0.0932\n",
      "Epoch 154/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 1.0000 - loss: 1.5418e-08 - val_accuracy: 0.9812 - val_loss: 0.0932\n",
      "Epoch 155/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853us/step - accuracy: 1.0000 - loss: 1.5639e-08 - val_accuracy: 0.9815 - val_loss: 0.0933\n",
      "Epoch 156/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 1.0000 - loss: 1.6239e-08 - val_accuracy: 0.9812 - val_loss: 0.0933\n",
      "Epoch 157/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835us/step - accuracy: 1.0000 - loss: 1.5665e-08 - val_accuracy: 0.9815 - val_loss: 0.0932\n",
      "Epoch 158/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 1.0000 - loss: 1.5819e-08 - val_accuracy: 0.9815 - val_loss: 0.0933\n",
      "Epoch 159/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 1.0000 - loss: 1.5413e-08 - val_accuracy: 0.9815 - val_loss: 0.0932\n",
      "Epoch 160/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - accuracy: 1.0000 - loss: 1.5511e-08 - val_accuracy: 0.9815 - val_loss: 0.0933\n",
      "Epoch 161/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 1.0000 - loss: 1.5572e-08 - val_accuracy: 0.9815 - val_loss: 0.0934\n",
      "Epoch 162/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 1.0000 - loss: 1.5487e-08 - val_accuracy: 0.9815 - val_loss: 0.0936\n",
      "Epoch 163/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 1.0000 - loss: 1.5309e-08 - val_accuracy: 0.9815 - val_loss: 0.0934\n",
      "Epoch 164/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - accuracy: 1.0000 - loss: 1.5121e-08 - val_accuracy: 0.9815 - val_loss: 0.0935\n",
      "Epoch 165/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853us/step - accuracy: 1.0000 - loss: 1.4984e-08 - val_accuracy: 0.9815 - val_loss: 0.0935\n",
      "Epoch 166/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step - accuracy: 1.0000 - loss: 1.5207e-08 - val_accuracy: 0.9815 - val_loss: 0.0936\n",
      "Epoch 167/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 1.0000 - loss: 1.5079e-08 - val_accuracy: 0.9812 - val_loss: 0.0935\n",
      "Epoch 168/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 1.0000 - loss: 1.5134e-08 - val_accuracy: 0.9815 - val_loss: 0.0937\n",
      "Epoch 169/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 1.0000 - loss: 1.4935e-08 - val_accuracy: 0.9815 - val_loss: 0.0936\n",
      "Epoch 170/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 1.0000 - loss: 1.4866e-08 - val_accuracy: 0.9812 - val_loss: 0.0937\n",
      "Epoch 171/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 1.0000 - loss: 1.4794e-08 - val_accuracy: 0.9812 - val_loss: 0.0938\n",
      "Epoch 172/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 999us/step - accuracy: 1.0000 - loss: 1.5018e-08 - val_accuracy: 0.9809 - val_loss: 0.0938\n",
      "Epoch 173/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 885us/step - accuracy: 1.0000 - loss: 1.4442e-08 - val_accuracy: 0.9812 - val_loss: 0.0939\n",
      "Epoch 174/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - accuracy: 1.0000 - loss: 1.5147e-08 - val_accuracy: 0.9805 - val_loss: 0.0938\n",
      "Epoch 175/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 1.0000 - loss: 1.4777e-08 - val_accuracy: 0.9805 - val_loss: 0.0939\n",
      "Epoch 176/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 1.0000 - loss: 1.4675e-08 - val_accuracy: 0.9805 - val_loss: 0.0939\n",
      "Epoch 177/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 1.0000 - loss: 1.4592e-08 - val_accuracy: 0.9802 - val_loss: 0.0941\n",
      "Epoch 178/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 1.0000 - loss: 1.4175e-08 - val_accuracy: 0.9805 - val_loss: 0.0940\n",
      "Epoch 179/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - accuracy: 1.0000 - loss: 1.4509e-08 - val_accuracy: 0.9805 - val_loss: 0.0941\n",
      "Epoch 180/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 1.0000 - loss: 1.5026e-08 - val_accuracy: 0.9805 - val_loss: 0.0941\n",
      "Epoch 181/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 1.0000 - loss: 1.4509e-08 - val_accuracy: 0.9802 - val_loss: 0.0942\n",
      "Epoch 182/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 1.0000 - loss: 1.4559e-08 - val_accuracy: 0.9802 - val_loss: 0.0941\n",
      "Epoch 183/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 1.0000 - loss: 1.4841e-08 - val_accuracy: 0.9802 - val_loss: 0.0943\n",
      "Epoch 184/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - accuracy: 1.0000 - loss: 1.4519e-08 - val_accuracy: 0.9802 - val_loss: 0.0943\n",
      "Epoch 185/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 1.0000 - loss: 1.5134e-08 - val_accuracy: 0.9798 - val_loss: 0.0943\n",
      "Epoch 186/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 945us/step - accuracy: 1.0000 - loss: 1.4283e-08 - val_accuracy: 0.9802 - val_loss: 0.0943\n",
      "Epoch 187/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step - accuracy: 1.0000 - loss: 1.4569e-08 - val_accuracy: 0.9802 - val_loss: 0.0944\n",
      "Epoch 188/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861us/step - accuracy: 1.0000 - loss: 1.3964e-08 - val_accuracy: 0.9798 - val_loss: 0.0944\n",
      "Epoch 189/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 1.0000 - loss: 1.4962e-08 - val_accuracy: 0.9802 - val_loss: 0.0945\n",
      "Epoch 190/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 1.0000 - loss: 1.4290e-08 - val_accuracy: 0.9798 - val_loss: 0.0944\n",
      "Epoch 191/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - accuracy: 1.0000 - loss: 1.4692e-08 - val_accuracy: 0.9798 - val_loss: 0.0946\n",
      "Epoch 192/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 1.0000 - loss: 1.4688e-08 - val_accuracy: 0.9798 - val_loss: 0.0946\n",
      "Epoch 193/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step - accuracy: 1.0000 - loss: 1.4479e-08 - val_accuracy: 0.9798 - val_loss: 0.0945\n",
      "Epoch 194/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 1.0000 - loss: 1.4263e-08 - val_accuracy: 0.9798 - val_loss: 0.0947\n",
      "Epoch 195/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 1.0000 - loss: 1.4607e-08 - val_accuracy: 0.9798 - val_loss: 0.0947\n",
      "Epoch 196/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 823us/step - accuracy: 1.0000 - loss: 1.4327e-08 - val_accuracy: 0.9798 - val_loss: 0.0948\n",
      "Epoch 197/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - accuracy: 1.0000 - loss: 1.4241e-08 - val_accuracy: 0.9798 - val_loss: 0.0949\n",
      "Epoch 198/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853us/step - accuracy: 1.0000 - loss: 1.4054e-08 - val_accuracy: 0.9798 - val_loss: 0.0949\n",
      "Epoch 199/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - accuracy: 1.0000 - loss: 1.3775e-08 - val_accuracy: 0.9798 - val_loss: 0.0949\n",
      "Epoch 200/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 1.0000 - loss: 1.4119e-08 - val_accuracy: 0.9798 - val_loss: 0.0950\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "prueba_20: \n",
      "Epoch 1/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1460 - loss: 2.8199 - val_accuracy: 0.4704 - val_loss: 2.3335\n",
      "Epoch 2/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 959us/step - accuracy: 0.5267 - loss: 2.0998 - val_accuracy: 0.6687 - val_loss: 1.5604\n",
      "Epoch 3/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 0.7112 - loss: 1.3836 - val_accuracy: 0.7600 - val_loss: 1.1105\n",
      "Epoch 4/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 0.8021 - loss: 0.9755 - val_accuracy: 0.8065 - val_loss: 0.8587\n",
      "Epoch 5/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 0.8409 - loss: 0.7418 - val_accuracy: 0.8277 - val_loss: 0.7066\n",
      "Epoch 6/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 0.8700 - loss: 0.5942 - val_accuracy: 0.8427 - val_loss: 0.6045\n",
      "Epoch 7/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 0.8920 - loss: 0.4903 - val_accuracy: 0.8588 - val_loss: 0.5295\n",
      "Epoch 8/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 0.9122 - loss: 0.4111 - val_accuracy: 0.8759 - val_loss: 0.4710\n",
      "Epoch 9/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888us/step - accuracy: 0.9324 - loss: 0.3476 - val_accuracy: 0.8872 - val_loss: 0.4237\n",
      "Epoch 10/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893us/step - accuracy: 0.9408 - loss: 0.2954 - val_accuracy: 0.8978 - val_loss: 0.3847\n",
      "Epoch 11/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 0.9507 - loss: 0.2515 - val_accuracy: 0.9039 - val_loss: 0.3520\n",
      "Epoch 12/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 0.9602 - loss: 0.2142 - val_accuracy: 0.9118 - val_loss: 0.3244\n",
      "Epoch 13/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 0.9687 - loss: 0.1822 - val_accuracy: 0.9169 - val_loss: 0.3008\n",
      "Epoch 14/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 0.9780 - loss: 0.1546 - val_accuracy: 0.9210 - val_loss: 0.2803\n",
      "Epoch 15/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 0.9830 - loss: 0.1307 - val_accuracy: 0.9217 - val_loss: 0.2623\n",
      "Epoch 16/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 0.9869 - loss: 0.1100 - val_accuracy: 0.9268 - val_loss: 0.2465\n",
      "Epoch 17/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 0.9914 - loss: 0.0923 - val_accuracy: 0.9306 - val_loss: 0.2328\n",
      "Epoch 18/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 0.9945 - loss: 0.0773 - val_accuracy: 0.9330 - val_loss: 0.2209\n",
      "Epoch 19/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 0.9974 - loss: 0.0645 - val_accuracy: 0.9385 - val_loss: 0.2105\n",
      "Epoch 20/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 0.9981 - loss: 0.0536 - val_accuracy: 0.9415 - val_loss: 0.2013\n",
      "Epoch 21/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 0.9990 - loss: 0.0444 - val_accuracy: 0.9429 - val_loss: 0.1932\n",
      "Epoch 22/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 0.9996 - loss: 0.0366 - val_accuracy: 0.9460 - val_loss: 0.1861\n",
      "Epoch 23/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 818us/step - accuracy: 0.9999 - loss: 0.0301 - val_accuracy: 0.9480 - val_loss: 0.1801\n",
      "Epoch 24/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - accuracy: 0.9999 - loss: 0.0248 - val_accuracy: 0.9491 - val_loss: 0.1751\n",
      "Epoch 25/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 1.0000 - loss: 0.0203 - val_accuracy: 0.9504 - val_loss: 0.1710\n",
      "Epoch 26/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 1.0000 - loss: 0.0167 - val_accuracy: 0.9508 - val_loss: 0.1675\n",
      "Epoch 27/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 1.0000 - loss: 0.0136 - val_accuracy: 0.9518 - val_loss: 0.1647\n",
      "Epoch 28/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835us/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 0.9538 - val_loss: 0.1625\n",
      "Epoch 29/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 0.9532 - val_loss: 0.1608\n",
      "Epoch 30/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9549 - val_loss: 0.1595\n",
      "Epoch 31/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.9556 - val_loss: 0.1587\n",
      "Epoch 32/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.9556 - val_loss: 0.1583\n",
      "Epoch 33/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9569 - val_loss: 0.1583\n",
      "Epoch 34/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 881us/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9573 - val_loss: 0.1587\n",
      "Epoch 35/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824us/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9569 - val_loss: 0.1593\n",
      "Epoch 36/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9573 - val_loss: 0.1603\n",
      "Epoch 37/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9573 - val_loss: 0.1616\n",
      "Epoch 38/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9576 - val_loss: 0.1630\n",
      "Epoch 39/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - accuracy: 1.0000 - loss: 9.9265e-04 - val_accuracy: 0.9576 - val_loss: 0.1648\n",
      "Epoch 40/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 1.0000 - loss: 7.8864e-04 - val_accuracy: 0.9573 - val_loss: 0.1667\n",
      "Epoch 41/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 1.0000 - loss: 6.2578e-04 - val_accuracy: 0.9573 - val_loss: 0.1689\n",
      "Epoch 42/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 1.0000 - loss: 4.9596e-04 - val_accuracy: 0.9579 - val_loss: 0.1712\n",
      "Epoch 43/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 1.0000 - loss: 3.9261e-04 - val_accuracy: 0.9579 - val_loss: 0.1737\n",
      "Epoch 44/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 1.0000 - loss: 3.1047e-04 - val_accuracy: 0.9573 - val_loss: 0.1763\n",
      "Epoch 45/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867us/step - accuracy: 1.0000 - loss: 2.4526e-04 - val_accuracy: 0.9576 - val_loss: 0.1791\n",
      "Epoch 46/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - accuracy: 1.0000 - loss: 1.9358e-04 - val_accuracy: 0.9576 - val_loss: 0.1820\n",
      "Epoch 47/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step - accuracy: 1.0000 - loss: 1.5265e-04 - val_accuracy: 0.9583 - val_loss: 0.1849\n",
      "Epoch 48/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 821us/step - accuracy: 1.0000 - loss: 1.2030e-04 - val_accuracy: 0.9579 - val_loss: 0.1880\n",
      "Epoch 49/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 1.0000 - loss: 9.4740e-05 - val_accuracy: 0.9576 - val_loss: 0.1911\n",
      "Epoch 50/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 1.0000 - loss: 7.4574e-05 - val_accuracy: 0.9576 - val_loss: 0.1943\n",
      "Epoch 51/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 1.0000 - loss: 5.8676e-05 - val_accuracy: 0.9579 - val_loss: 0.1976\n",
      "Epoch 52/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 1.0000 - loss: 4.6150e-05 - val_accuracy: 0.9586 - val_loss: 0.2010\n",
      "Epoch 53/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - accuracy: 1.0000 - loss: 3.6294e-05 - val_accuracy: 0.9590 - val_loss: 0.2044\n",
      "Epoch 54/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 821us/step - accuracy: 1.0000 - loss: 2.8538e-05 - val_accuracy: 0.9593 - val_loss: 0.2078\n",
      "Epoch 55/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - accuracy: 1.0000 - loss: 2.2442e-05 - val_accuracy: 0.9597 - val_loss: 0.2113\n",
      "Epoch 56/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - accuracy: 1.0000 - loss: 1.7652e-05 - val_accuracy: 0.9600 - val_loss: 0.2147\n",
      "Epoch 57/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 1.0000 - loss: 1.3891e-05 - val_accuracy: 0.9600 - val_loss: 0.2182\n",
      "Epoch 58/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 1.0000 - loss: 1.0940e-05 - val_accuracy: 0.9597 - val_loss: 0.2217\n",
      "Epoch 59/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895us/step - accuracy: 1.0000 - loss: 8.6251e-06 - val_accuracy: 0.9593 - val_loss: 0.2251\n",
      "Epoch 60/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 1.0000 - loss: 6.8097e-06 - val_accuracy: 0.9593 - val_loss: 0.2285\n",
      "Epoch 61/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 988us/step - accuracy: 1.0000 - loss: 5.3889e-06 - val_accuracy: 0.9597 - val_loss: 0.2318\n",
      "Epoch 62/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 887us/step - accuracy: 1.0000 - loss: 4.2750e-06 - val_accuracy: 0.9597 - val_loss: 0.2351\n",
      "Epoch 63/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - accuracy: 1.0000 - loss: 3.4008e-06 - val_accuracy: 0.9600 - val_loss: 0.2382\n",
      "Epoch 64/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 1.0000 - loss: 2.7180e-06 - val_accuracy: 0.9600 - val_loss: 0.2412\n",
      "Epoch 65/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 1.0000 - loss: 2.1819e-06 - val_accuracy: 0.9600 - val_loss: 0.2441\n",
      "Epoch 66/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 853us/step - accuracy: 1.0000 - loss: 1.7600e-06 - val_accuracy: 0.9603 - val_loss: 0.2468\n",
      "Epoch 67/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 821us/step - accuracy: 1.0000 - loss: 1.4282e-06 - val_accuracy: 0.9600 - val_loss: 0.2495\n",
      "Epoch 68/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 1.0000 - loss: 1.1694e-06 - val_accuracy: 0.9597 - val_loss: 0.2518\n",
      "Epoch 69/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 1.0000 - loss: 9.6592e-07 - val_accuracy: 0.9600 - val_loss: 0.2542\n",
      "Epoch 70/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 1.0000 - loss: 8.0028e-07 - val_accuracy: 0.9600 - val_loss: 0.2561\n",
      "Epoch 71/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 1.0000 - loss: 6.7172e-07 - val_accuracy: 0.9600 - val_loss: 0.2579\n",
      "Epoch 72/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 1.0000 - loss: 5.6646e-07 - val_accuracy: 0.9603 - val_loss: 0.2598\n",
      "Epoch 73/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 1.0000 - loss: 4.8401e-07 - val_accuracy: 0.9607 - val_loss: 0.2614\n",
      "Epoch 74/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 1.0000 - loss: 4.1729e-07 - val_accuracy: 0.9610 - val_loss: 0.2629\n",
      "Epoch 75/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820us/step - accuracy: 1.0000 - loss: 3.6236e-07 - val_accuracy: 0.9610 - val_loss: 0.2642\n",
      "Epoch 76/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 1.0000 - loss: 3.1731e-07 - val_accuracy: 0.9610 - val_loss: 0.2655\n",
      "Epoch 77/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 1.0000 - loss: 2.8091e-07 - val_accuracy: 0.9603 - val_loss: 0.2666\n",
      "Epoch 78/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 1.0000 - loss: 2.4928e-07 - val_accuracy: 0.9603 - val_loss: 0.2676\n",
      "Epoch 79/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 904us/step - accuracy: 1.0000 - loss: 2.2426e-07 - val_accuracy: 0.9603 - val_loss: 0.2683\n",
      "Epoch 80/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step - accuracy: 1.0000 - loss: 2.0213e-07 - val_accuracy: 0.9607 - val_loss: 0.2694\n",
      "Epoch 81/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 1.0000 - loss: 1.8321e-07 - val_accuracy: 0.9607 - val_loss: 0.2701\n",
      "Epoch 82/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - accuracy: 1.0000 - loss: 1.6828e-07 - val_accuracy: 0.9610 - val_loss: 0.2707\n",
      "Epoch 83/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 1.0000 - loss: 1.5406e-07 - val_accuracy: 0.9610 - val_loss: 0.2716\n",
      "Epoch 84/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 819us/step - accuracy: 1.0000 - loss: 1.4159e-07 - val_accuracy: 0.9610 - val_loss: 0.2726\n",
      "Epoch 85/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 1.0000 - loss: 1.3113e-07 - val_accuracy: 0.9610 - val_loss: 0.2733\n",
      "Epoch 86/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - accuracy: 1.0000 - loss: 1.2233e-07 - val_accuracy: 0.9607 - val_loss: 0.2740\n",
      "Epoch 87/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 839us/step - accuracy: 1.0000 - loss: 1.1551e-07 - val_accuracy: 0.9607 - val_loss: 0.2746\n",
      "Epoch 88/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 1.0000 - loss: 1.0790e-07 - val_accuracy: 0.9603 - val_loss: 0.2751\n",
      "Epoch 89/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867us/step - accuracy: 1.0000 - loss: 1.0147e-07 - val_accuracy: 0.9600 - val_loss: 0.2757\n",
      "Epoch 90/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 1.0000 - loss: 9.5876e-08 - val_accuracy: 0.9597 - val_loss: 0.2763\n",
      "Epoch 91/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867us/step - accuracy: 1.0000 - loss: 9.0682e-08 - val_accuracy: 0.9590 - val_loss: 0.2768\n",
      "Epoch 92/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 821us/step - accuracy: 1.0000 - loss: 8.5952e-08 - val_accuracy: 0.9593 - val_loss: 0.2774\n",
      "Epoch 93/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 839us/step - accuracy: 1.0000 - loss: 8.1936e-08 - val_accuracy: 0.9593 - val_loss: 0.2781\n",
      "Epoch 94/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 1.0000 - loss: 7.7811e-08 - val_accuracy: 0.9593 - val_loss: 0.2788\n",
      "Epoch 95/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 1.0000 - loss: 7.5035e-08 - val_accuracy: 0.9593 - val_loss: 0.2795\n",
      "Epoch 96/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867us/step - accuracy: 1.0000 - loss: 7.1656e-08 - val_accuracy: 0.9590 - val_loss: 0.2801\n",
      "Epoch 97/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 1.0000 - loss: 6.8482e-08 - val_accuracy: 0.9590 - val_loss: 0.2805\n",
      "Epoch 98/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 1.0000 - loss: 6.5577e-08 - val_accuracy: 0.9590 - val_loss: 0.2810\n",
      "Epoch 99/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 1.0000 - loss: 6.3364e-08 - val_accuracy: 0.9593 - val_loss: 0.2813\n",
      "Epoch 100/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 1.0000 - loss: 6.1058e-08 - val_accuracy: 0.9593 - val_loss: 0.2819\n",
      "Epoch 101/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864us/step - accuracy: 1.0000 - loss: 5.8844e-08 - val_accuracy: 0.9593 - val_loss: 0.2820\n",
      "Epoch 102/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step - accuracy: 1.0000 - loss: 5.6193e-08 - val_accuracy: 0.9593 - val_loss: 0.2826\n",
      "Epoch 103/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893us/step - accuracy: 1.0000 - loss: 5.5172e-08 - val_accuracy: 0.9593 - val_loss: 0.2831\n",
      "Epoch 104/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 1.0000 - loss: 5.2238e-08 - val_accuracy: 0.9597 - val_loss: 0.2837\n",
      "Epoch 105/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 1.0000 - loss: 5.0556e-08 - val_accuracy: 0.9597 - val_loss: 0.2840\n",
      "Epoch 106/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - accuracy: 1.0000 - loss: 4.9656e-08 - val_accuracy: 0.9597 - val_loss: 0.2842\n",
      "Epoch 107/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 1.0000 - loss: 4.7557e-08 - val_accuracy: 0.9597 - val_loss: 0.2849\n",
      "Epoch 108/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 910us/step - accuracy: 1.0000 - loss: 4.6811e-08 - val_accuracy: 0.9597 - val_loss: 0.2851\n",
      "Epoch 109/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 1.0000 - loss: 4.5514e-08 - val_accuracy: 0.9597 - val_loss: 0.2855\n",
      "Epoch 110/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - accuracy: 1.0000 - loss: 4.3937e-08 - val_accuracy: 0.9593 - val_loss: 0.2859\n",
      "Epoch 111/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 1.0000 - loss: 4.3017e-08 - val_accuracy: 0.9593 - val_loss: 0.2863\n",
      "Epoch 112/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 966us/step - accuracy: 1.0000 - loss: 4.1854e-08 - val_accuracy: 0.9597 - val_loss: 0.2866\n",
      "Epoch 113/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 885us/step - accuracy: 1.0000 - loss: 4.1085e-08 - val_accuracy: 0.9597 - val_loss: 0.2870\n",
      "Epoch 114/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 885us/step - accuracy: 1.0000 - loss: 4.0466e-08 - val_accuracy: 0.9597 - val_loss: 0.2873\n",
      "Epoch 115/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 1.0000 - loss: 3.9221e-08 - val_accuracy: 0.9597 - val_loss: 0.2875\n",
      "Epoch 116/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 1.0000 - loss: 3.8283e-08 - val_accuracy: 0.9597 - val_loss: 0.2880\n",
      "Epoch 117/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 1.0000 - loss: 3.7147e-08 - val_accuracy: 0.9597 - val_loss: 0.2882\n",
      "Epoch 118/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 1.0000 - loss: 3.6488e-08 - val_accuracy: 0.9597 - val_loss: 0.2889\n",
      "Epoch 119/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 1.0000 - loss: 3.6494e-08 - val_accuracy: 0.9597 - val_loss: 0.2892\n",
      "Epoch 120/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 822us/step - accuracy: 1.0000 - loss: 3.5266e-08 - val_accuracy: 0.9597 - val_loss: 0.2894\n",
      "Epoch 121/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 1.0000 - loss: 3.4985e-08 - val_accuracy: 0.9593 - val_loss: 0.2899\n",
      "Epoch 122/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 1.0000 - loss: 3.3934e-08 - val_accuracy: 0.9593 - val_loss: 0.2902\n",
      "Epoch 123/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835us/step - accuracy: 1.0000 - loss: 3.3746e-08 - val_accuracy: 0.9593 - val_loss: 0.2905\n",
      "Epoch 124/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 1.0000 - loss: 3.3535e-08 - val_accuracy: 0.9593 - val_loss: 0.2911\n",
      "Epoch 125/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 1.0000 - loss: 3.2419e-08 - val_accuracy: 0.9593 - val_loss: 0.2912\n",
      "Epoch 126/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 1.0000 - loss: 3.2394e-08 - val_accuracy: 0.9593 - val_loss: 0.2919\n",
      "Epoch 127/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 1.0000 - loss: 3.1556e-08 - val_accuracy: 0.9593 - val_loss: 0.2921\n",
      "Epoch 128/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 1.0000 - loss: 3.0879e-08 - val_accuracy: 0.9593 - val_loss: 0.2924\n",
      "Epoch 129/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 922us/step - accuracy: 1.0000 - loss: 3.0911e-08 - val_accuracy: 0.9597 - val_loss: 0.2924\n",
      "Epoch 130/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 936us/step - accuracy: 1.0000 - loss: 3.0123e-08 - val_accuracy: 0.9593 - val_loss: 0.2929\n",
      "Epoch 131/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - accuracy: 1.0000 - loss: 2.9648e-08 - val_accuracy: 0.9593 - val_loss: 0.2933\n",
      "Epoch 132/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835us/step - accuracy: 1.0000 - loss: 2.9263e-08 - val_accuracy: 0.9593 - val_loss: 0.2936\n",
      "Epoch 133/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 872us/step - accuracy: 1.0000 - loss: 2.8899e-08 - val_accuracy: 0.9593 - val_loss: 0.2937\n",
      "Epoch 134/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 837us/step - accuracy: 1.0000 - loss: 2.8043e-08 - val_accuracy: 0.9593 - val_loss: 0.2939\n",
      "Epoch 135/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 1.0000 - loss: 2.8662e-08 - val_accuracy: 0.9593 - val_loss: 0.2945\n",
      "Epoch 136/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 1.0000 - loss: 2.7686e-08 - val_accuracy: 0.9593 - val_loss: 0.2946\n",
      "Epoch 137/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 1.0000 - loss: 2.7461e-08 - val_accuracy: 0.9593 - val_loss: 0.2951\n",
      "Epoch 138/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 1.0000 - loss: 2.7169e-08 - val_accuracy: 0.9590 - val_loss: 0.2953\n",
      "Epoch 139/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861us/step - accuracy: 1.0000 - loss: 2.6789e-08 - val_accuracy: 0.9590 - val_loss: 0.2958\n",
      "Epoch 140/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 1.0000 - loss: 2.6455e-08 - val_accuracy: 0.9593 - val_loss: 0.2957\n",
      "Epoch 141/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 1.0000 - loss: 2.5902e-08 - val_accuracy: 0.9590 - val_loss: 0.2964\n",
      "Epoch 142/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 1.0000 - loss: 2.5625e-08 - val_accuracy: 0.9590 - val_loss: 0.2970\n",
      "Epoch 143/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 1.0000 - loss: 2.6162e-08 - val_accuracy: 0.9593 - val_loss: 0.2970\n",
      "Epoch 144/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 1.0000 - loss: 2.5393e-08 - val_accuracy: 0.9590 - val_loss: 0.2974\n",
      "Epoch 145/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 1.0000 - loss: 2.5572e-08 - val_accuracy: 0.9590 - val_loss: 0.2977\n",
      "Epoch 146/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 1.0000 - loss: 2.5167e-08 - val_accuracy: 0.9586 - val_loss: 0.2983\n",
      "Epoch 147/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step - accuracy: 1.0000 - loss: 2.4123e-08 - val_accuracy: 0.9586 - val_loss: 0.2987\n",
      "Epoch 148/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 1.0000 - loss: 2.4748e-08 - val_accuracy: 0.9586 - val_loss: 0.2993\n",
      "Epoch 149/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 1.0000 - loss: 2.4403e-08 - val_accuracy: 0.9586 - val_loss: 0.2998\n",
      "Epoch 150/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 1.0000 - loss: 2.3845e-08 - val_accuracy: 0.9586 - val_loss: 0.3001\n",
      "Epoch 151/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - accuracy: 1.0000 - loss: 2.4400e-08 - val_accuracy: 0.9586 - val_loss: 0.3006\n",
      "Epoch 152/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 1.0000 - loss: 2.3713e-08 - val_accuracy: 0.9586 - val_loss: 0.3012\n",
      "Epoch 153/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 1.0000 - loss: 2.3558e-08 - val_accuracy: 0.9590 - val_loss: 0.3011\n",
      "Epoch 154/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 1.0000 - loss: 2.3260e-08 - val_accuracy: 0.9590 - val_loss: 0.3017\n",
      "Epoch 155/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 1.0000 - loss: 2.3086e-08 - val_accuracy: 0.9590 - val_loss: 0.3024\n",
      "Epoch 156/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - accuracy: 1.0000 - loss: 2.3085e-08 - val_accuracy: 0.9593 - val_loss: 0.3026\n",
      "Epoch 157/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 1.0000 - loss: 2.2833e-08 - val_accuracy: 0.9593 - val_loss: 0.3032\n",
      "Epoch 158/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 834us/step - accuracy: 1.0000 - loss: 2.2793e-08 - val_accuracy: 0.9597 - val_loss: 0.3034\n",
      "Epoch 159/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 840us/step - accuracy: 1.0000 - loss: 2.2595e-08 - val_accuracy: 0.9597 - val_loss: 0.3039\n",
      "Epoch 160/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 881us/step - accuracy: 1.0000 - loss: 2.2825e-08 - val_accuracy: 0.9593 - val_loss: 0.3039\n",
      "Epoch 161/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - accuracy: 1.0000 - loss: 2.2711e-08 - val_accuracy: 0.9593 - val_loss: 0.3048\n",
      "Epoch 162/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 922us/step - accuracy: 1.0000 - loss: 2.2397e-08 - val_accuracy: 0.9593 - val_loss: 0.3049\n",
      "Epoch 163/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step - accuracy: 1.0000 - loss: 2.2310e-08 - val_accuracy: 0.9593 - val_loss: 0.3053\n",
      "Epoch 164/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.2464e-08 - val_accuracy: 0.9593 - val_loss: 0.3058\n",
      "Epoch 165/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.1901e-08 - val_accuracy: 0.9593 - val_loss: 0.3059\n",
      "Epoch 166/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 937us/step - accuracy: 1.0000 - loss: 2.2106e-08 - val_accuracy: 0.9590 - val_loss: 0.3062\n",
      "Epoch 167/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 1.0000 - loss: 2.2020e-08 - val_accuracy: 0.9590 - val_loss: 0.3067\n",
      "Epoch 168/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 1.0000 - loss: 2.1856e-08 - val_accuracy: 0.9590 - val_loss: 0.3072\n",
      "Epoch 169/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895us/step - accuracy: 1.0000 - loss: 2.1656e-08 - val_accuracy: 0.9590 - val_loss: 0.3073\n",
      "Epoch 170/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - accuracy: 1.0000 - loss: 2.1287e-08 - val_accuracy: 0.9590 - val_loss: 0.3077\n",
      "Epoch 171/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 902us/step - accuracy: 1.0000 - loss: 2.1608e-08 - val_accuracy: 0.9593 - val_loss: 0.3082\n",
      "Epoch 172/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 972us/step - accuracy: 1.0000 - loss: 2.1299e-08 - val_accuracy: 0.9586 - val_loss: 0.3081\n",
      "Epoch 173/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - accuracy: 1.0000 - loss: 2.1717e-08 - val_accuracy: 0.9583 - val_loss: 0.3086\n",
      "Epoch 174/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 953us/step - accuracy: 1.0000 - loss: 2.1365e-08 - val_accuracy: 0.9583 - val_loss: 0.3089\n",
      "Epoch 175/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 1.0000 - loss: 2.1130e-08 - val_accuracy: 0.9583 - val_loss: 0.3092\n",
      "Epoch 176/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 1.0000 - loss: 2.0815e-08 - val_accuracy: 0.9583 - val_loss: 0.3094\n",
      "Epoch 177/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 1.0000 - loss: 2.1125e-08 - val_accuracy: 0.9579 - val_loss: 0.3100\n",
      "Epoch 178/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - accuracy: 1.0000 - loss: 2.1194e-08 - val_accuracy: 0.9583 - val_loss: 0.3101\n",
      "Epoch 179/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 1.0000 - loss: 2.0879e-08 - val_accuracy: 0.9579 - val_loss: 0.3105\n",
      "Epoch 180/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888us/step - accuracy: 1.0000 - loss: 2.0074e-08 - val_accuracy: 0.9576 - val_loss: 0.3109\n",
      "Epoch 181/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step - accuracy: 1.0000 - loss: 2.1142e-08 - val_accuracy: 0.9579 - val_loss: 0.3112\n",
      "Epoch 182/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - accuracy: 1.0000 - loss: 2.0654e-08 - val_accuracy: 0.9579 - val_loss: 0.3112\n",
      "Epoch 183/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - accuracy: 1.0000 - loss: 2.0182e-08 - val_accuracy: 0.9579 - val_loss: 0.3116\n",
      "Epoch 184/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - accuracy: 1.0000 - loss: 2.0757e-08 - val_accuracy: 0.9579 - val_loss: 0.3119\n",
      "Epoch 185/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - accuracy: 1.0000 - loss: 2.0423e-08 - val_accuracy: 0.9579 - val_loss: 0.3125\n",
      "Epoch 186/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899us/step - accuracy: 1.0000 - loss: 2.0377e-08 - val_accuracy: 0.9576 - val_loss: 0.3126\n",
      "Epoch 187/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895us/step - accuracy: 1.0000 - loss: 2.0431e-08 - val_accuracy: 0.9576 - val_loss: 0.3131\n",
      "Epoch 188/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - accuracy: 1.0000 - loss: 2.0183e-08 - val_accuracy: 0.9576 - val_loss: 0.3130\n",
      "Epoch 189/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888us/step - accuracy: 1.0000 - loss: 2.0302e-08 - val_accuracy: 0.9576 - val_loss: 0.3137\n",
      "Epoch 190/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861us/step - accuracy: 1.0000 - loss: 2.0288e-08 - val_accuracy: 0.9573 - val_loss: 0.3140\n",
      "Epoch 191/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 1.0000 - loss: 2.0434e-08 - val_accuracy: 0.9566 - val_loss: 0.3142\n",
      "Epoch 192/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 849us/step - accuracy: 1.0000 - loss: 1.9813e-08 - val_accuracy: 0.9566 - val_loss: 0.3145\n",
      "Epoch 193/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 881us/step - accuracy: 1.0000 - loss: 2.0143e-08 - val_accuracy: 0.9566 - val_loss: 0.3147\n",
      "Epoch 194/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 1.0000 - loss: 1.9750e-08 - val_accuracy: 0.9569 - val_loss: 0.3151\n",
      "Epoch 195/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 907us/step - accuracy: 1.0000 - loss: 2.0145e-08 - val_accuracy: 0.9566 - val_loss: 0.3154\n",
      "Epoch 196/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 975us/step - accuracy: 1.0000 - loss: 1.9635e-08 - val_accuracy: 0.9566 - val_loss: 0.3158\n",
      "Epoch 197/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step - accuracy: 1.0000 - loss: 1.9752e-08 - val_accuracy: 0.9566 - val_loss: 0.3162\n",
      "Epoch 198/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 1.0000 - loss: 1.9506e-08 - val_accuracy: 0.9562 - val_loss: 0.3165\n",
      "Epoch 199/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888us/step - accuracy: 1.0000 - loss: 2.0286e-08 - val_accuracy: 0.9562 - val_loss: 0.3171\n",
      "Epoch 200/200\n",
      "\u001b[1m683/683\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - accuracy: 1.0000 - loss: 1.9845e-08 - val_accuracy: 0.9562 - val_loss: 0.3173\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prueba_4_1': 0.75,\n",
       " 'prueba_12': 0.75,\n",
       " 'prueba_13': 0.25,\n",
       " 'prueba_14': 0.75,\n",
       " 'prueba_19': 0.75,\n",
       " 'prueba_20': 0.75}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PRUEBAS CON epochs 200\n",
    "resutados = {}\n",
    "modelos_200 = {}\n",
    "for prueba, params in pruebas.items():\n",
    "    print(f\"{prueba}: \")\n",
    "    resultado, modelo = run_keras_model(n_pca=params.get('n_pca'), \n",
    "                    excl_n_prim_comp=params.get('excl_n_prim_comp'), \n",
    "                    nueronas_layer_1=params.get('nueronas_layer_1'),\n",
    "                    nueronas_layer_2=params.get('nueronas_layer_2'),\n",
    "                    n_epochs=200, # NO TOMA EL QUE DEFINIMOS EN PRUEBAS <<<<<--------- epochs cambiar aca\n",
    "                    imagenes=imagenes_all,\n",
    "                    nombres=nombres_all,\n",
    "                    nuevas_imagenes=new_images,\n",
    "                    nuevos_nombres=nombres_new\n",
    "                    )\n",
    "    resutados[prueba]=resultado\n",
    "    modelos_200[prueba]=modelo\n",
    "resutados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebo predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si cargo nuevas fotos es importante correr esta parte (con True en lugar de False)\n",
    "# hacer check manual que TOME BIEN LAS CARAS (puede pasar que recorte algo que NO es una cara)\n",
    "if False:\n",
    "    cortar_imagenes(input_dir=\"fotos_probamos_distintas_opciones/probar_nuevas_fotos_input\", output_dir=\"fotos_probamos_distintas_opciones/probar_nuevas_fotos_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 900)\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "# importo imagenes predict 2\n",
    "data_dir = (\"fotos_probamos_distintas_opciones/probar_nuevas_fotos_output\")  # Cambia esto a la ruta de tu directorio de imágenes\n",
    "nombres = []\n",
    "imagenes = []\n",
    "\n",
    "# Cargar imágenes y etiquetas\n",
    "for archivo in os.listdir(data_dir):\n",
    "    if archivo.endswith('.jpeg') or archivo.endswith('.jpg'):\n",
    "        nombre = archivo.split('_')[0].replace(\".jpg\",\"\").replace(\".jpeg\",\"\")\n",
    "        nombre = eliminar_numeros(nombre)\n",
    "        ruta_imagen = os.path.join(data_dir, archivo)\n",
    "        imagen = Image.open(ruta_imagen)\n",
    "        imagen = np.array(imagen.resize((dim_imagenes, dim_imagenes)))  # Redimensionar imágenes para un tamaño uniforme\n",
    "        if len(imagen.shape) == 3 and imagen.shape[2] == 3:\n",
    "            imagen = cv2.cvtColor(imagen, cv2.COLOR_RGB2GRAY)  # Convertir a escala de grises si es necesario\n",
    "        imagenes.append(imagen.flatten())\n",
    "        nombres.append(nombre)\n",
    "\n",
    "new_images = np.array(imagenes)\n",
    "nombres_new = np.array(nombres)\n",
    "\n",
    "# estand\n",
    "new_images = new_images/255.0\n",
    "print(new_images.shape)\n",
    "print(nombres_new.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nombres_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_predict2(model, n_pca, excl_n_prim_comp, imagenes, nombres, nuevas_imagenes, nuevos_nombres):\n",
    "    \n",
    "    # Dividir en entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(imagenes, nombres, test_size=0.05, random_state=42, stratify=nombres)\n",
    "\n",
    "    # Aplicar PCA\n",
    "    pca = PCA(n_components=n_pca, random_state=12)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    #X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    # Escalar los datos \n",
    "    scaler = StandardScaler()\n",
    "    #scaler = MinMaxScaler()\n",
    "    X_train_pca_scaled = scaler.fit_transform(X_train_pca)\n",
    "    #X_test_pca_scaled = scaler.transform(X_test_pca)\n",
    "    \n",
    "    \n",
    "    # Codificar las etiquetas\n",
    "    encoder = LabelEncoder()\n",
    "    y_train_encoded = encoder.fit_transform(y_train)\n",
    "    #y_test_encoded = encoder.transform(y_test)\n",
    "    y_train_categorical = to_categorical(y_train_encoded, num_classes=18)\n",
    "    #y_test_categorical = to_categorical(y_test_encoded, num_classes=18)\n",
    "    \n",
    "    \n",
    "    # Definir la red neuronal\n",
    "    entreno_con = X_train_pca_scaled[:,excl_n_prim_comp:]\n",
    "    #testeo_con = X_test_pca_scaled[:,excl_n_prim_comp:]    \n",
    "    \n",
    "    # PREDICCIONES\n",
    "    # 2. Aplicar PCA\n",
    "    new_images_pca = pca.transform(nuevas_imagenes)\n",
    "    new_images_pca_scaled = scaler.transform(new_images_pca)\n",
    "    evaluo_con = new_images_pca_scaled[:,excl_n_prim_comp:]\n",
    "\n",
    "    # 3. Hacer predicciones\n",
    "    predictions = model.predict(evaluo_con)\n",
    "\n",
    "    # Obtener los nombres correspondientes a las clases predichas\n",
    "    predicted_names = encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
    "\n",
    "    # Imprimir las predicciones\n",
    "    total_predict = len(nuevos_nombres)\n",
    "    total_correcto = 0\n",
    "    for real, pred in zip(nuevos_nombres, predicted_names):\n",
    "        if real == pred:\n",
    "            total_correcto += 1\n",
    "         \n",
    "    # df predicciones        \n",
    "    df_preds = pd.DataFrame(predictions.round(2))\n",
    "    class_names = encoder.classes_\n",
    "    df_preds.columns = class_names\n",
    "    \n",
    "    # devuelve resultado corrida\n",
    "    resultado = total_correcto/total_predict\n",
    "    return resultado, df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n"
     ]
    }
   ],
   "source": [
    "resultado13, df_preds13 = get_preds_predict2(\n",
    "    model=modelos_500[\"prueba_13\"], \n",
    "    n_pca=100, \n",
    "    excl_n_prim_comp=0, \n",
    "    imagenes=imagenes_all, \n",
    "    nombres=nombres_all, \n",
    "    nuevas_imagenes=new_images, \n",
    "    nuevos_nombres=nombres_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carlos</th>\n",
       "      <th>federicoG</th>\n",
       "      <th>federicoR</th>\n",
       "      <th>florencia</th>\n",
       "      <th>francoA</th>\n",
       "      <th>francoS</th>\n",
       "      <th>gerard</th>\n",
       "      <th>gustavo</th>\n",
       "      <th>joaquin</th>\n",
       "      <th>juan</th>\n",
       "      <th>lautaro</th>\n",
       "      <th>lisandro</th>\n",
       "      <th>marco</th>\n",
       "      <th>matias</th>\n",
       "      <th>natalia</th>\n",
       "      <th>noelia</th>\n",
       "      <th>paola</th>\n",
       "      <th>victorio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carlos  federicoG  federicoR  florencia  francoA  francoS  gerard  gustavo  \\\n",
       "0     0.0        0.0        0.0        0.0      0.0      0.0     0.0     0.04   \n",
       "1     0.0        0.0        0.0        0.0      0.0      0.0     0.0     0.00   \n",
       "2     0.0        0.0        0.0        0.0      0.0      0.0     0.0     0.00   \n",
       "3     0.0        0.0        0.0        0.0      0.0      0.0     0.0     0.00   \n",
       "\n",
       "   joaquin  juan  lautaro  lisandro  marco  matias  natalia  noelia  paola  \\\n",
       "0      0.0   0.0     0.00       0.0   0.96     0.0      0.0     0.0    0.0   \n",
       "1      0.0   0.0     0.86       0.0   0.10     0.0      0.0     0.0    0.0   \n",
       "2      0.0   0.0     1.00       0.0   0.00     0.0      0.0     0.0    0.0   \n",
       "3      0.0   0.0     0.00       1.0   0.00     0.0      0.0     0.0    0.0   \n",
       "\n",
       "   victorio  \n",
       "0      0.00  \n",
       "1      0.04  \n",
       "2      0.00  \n",
       "3      0.00  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
     ]
    }
   ],
   "source": [
    "resultado14, df_preds14 = get_preds_predict2(\n",
    "    model=modelos_500[\"prueba_14\"], \n",
    "    n_pca=100, \n",
    "    excl_n_prim_comp=3, \n",
    "    imagenes=imagenes_all, \n",
    "    nombres=nombres_all, \n",
    "    nuevas_imagenes=new_images, \n",
    "    nuevos_nombres=nombres_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carlos</th>\n",
       "      <th>federicoG</th>\n",
       "      <th>federicoR</th>\n",
       "      <th>florencia</th>\n",
       "      <th>francoA</th>\n",
       "      <th>francoS</th>\n",
       "      <th>gerard</th>\n",
       "      <th>gustavo</th>\n",
       "      <th>joaquin</th>\n",
       "      <th>juan</th>\n",
       "      <th>lautaro</th>\n",
       "      <th>lisandro</th>\n",
       "      <th>marco</th>\n",
       "      <th>matias</th>\n",
       "      <th>natalia</th>\n",
       "      <th>noelia</th>\n",
       "      <th>paola</th>\n",
       "      <th>victorio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carlos  federicoG  federicoR  florencia  francoA  francoS  gerard  gustavo  \\\n",
       "0     0.0        0.0        0.0        0.0      0.0      0.0     0.0      0.0   \n",
       "1     0.0        0.0        0.0        0.0      0.0      0.0     0.0      0.0   \n",
       "2     0.0        0.0        0.0        0.0      0.0      0.0     0.0      0.0   \n",
       "3     0.0        0.0        0.0        0.0      0.0      0.0     0.0      0.0   \n",
       "\n",
       "   joaquin  juan  lautaro  lisandro  marco  matias  natalia  noelia  paola  \\\n",
       "0      0.0   0.0      1.0      0.00   0.00     0.0      0.0     0.0   0.00   \n",
       "1      0.0   0.0      1.0      0.00   0.00     0.0      0.0     0.0   0.00   \n",
       "2      0.0   0.0      1.0      0.00   0.00     0.0      0.0     0.0   0.00   \n",
       "3      0.0   0.0      0.0      0.34   0.27     0.0      0.0     0.0   0.38   \n",
       "\n",
       "   victorio  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n"
     ]
    }
   ],
   "source": [
    "resultado14, df_preds14 = get_preds_predict2(\n",
    "    model=modelos_200[\"prueba_14\"], \n",
    "    n_pca=100,              #<<<---- tiene que tener mismos valores que el experimento\n",
    "    excl_n_prim_comp=3,     #<<<---- tiene que tener mismos valores que el experimento\n",
    "    imagenes=imagenes_all, \n",
    "    nombres=nombres_all, \n",
    "    nuevas_imagenes=new_images, \n",
    "    nuevos_nombres=nombres_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    }
   ],
   "source": [
    "resultado13, df_preds13 = get_preds_predict2(\n",
    "    model=modelos_200[\"prueba_13\"], \n",
    "    n_pca=100,          #<<<---- tiene que tener mismos valores que el experimento\n",
    "    excl_n_prim_comp=0, #<<<---- tiene que tener mismos valores que el experimento\n",
    "    imagenes=imagenes_all, \n",
    "    nombres=nombres_all, \n",
    "    nuevas_imagenes=new_images, \n",
    "    nuevos_nombres=nombres_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carlos</th>\n",
       "      <th>federicoG</th>\n",
       "      <th>federicoR</th>\n",
       "      <th>florencia</th>\n",
       "      <th>francoA</th>\n",
       "      <th>francoS</th>\n",
       "      <th>gerard</th>\n",
       "      <th>gustavo</th>\n",
       "      <th>joaquin</th>\n",
       "      <th>juan</th>\n",
       "      <th>lautaro</th>\n",
       "      <th>lisandro</th>\n",
       "      <th>marco</th>\n",
       "      <th>matias</th>\n",
       "      <th>natalia</th>\n",
       "      <th>noelia</th>\n",
       "      <th>paola</th>\n",
       "      <th>victorio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carlos  federicoG  federicoR  florencia  francoA  francoS  gerard  gustavo  \\\n",
       "0     0.0        0.0        0.0        0.0      0.0      0.0    0.04     0.00   \n",
       "1     0.0        0.0        0.0        0.0      0.0      0.0    0.00     0.00   \n",
       "2     0.0        0.0        0.0        0.0      0.0      0.0    0.00     0.00   \n",
       "3     0.0        0.0        0.0        0.0      0.0      0.0    0.00     0.01   \n",
       "\n",
       "   joaquin  juan  lautaro  lisandro  marco  matias  natalia  noelia  paola  \\\n",
       "0      0.0   0.0     0.95      0.00   0.00    0.00      0.0    0.00    0.0   \n",
       "1      0.0   0.0     0.83      0.12   0.00    0.01      0.0    0.02    0.0   \n",
       "2      0.0   0.0     0.99      0.00   0.00    0.00      0.0    0.00    0.0   \n",
       "3      0.0   0.0     0.00      0.56   0.43    0.00      0.0    0.00    0.0   \n",
       "\n",
       "   victorio  \n",
       "0      0.00  \n",
       "1      0.02  \n",
       "2      0.00  \n",
       "3      0.00  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    }
   ],
   "source": [
    "resultado19, df_preds19 = get_preds_predict2(\n",
    "    model=modelos_200[\"prueba_19\"], \n",
    "    n_pca=100,          #<<<---- tiene que tener mismos valores que el experimento\n",
    "    excl_n_prim_comp=0, #<<<---- tiene que tener mismos valores que el experimento\n",
    "    imagenes=imagenes_all, \n",
    "    nombres=nombres_all, \n",
    "    nuevas_imagenes=new_images, \n",
    "    nuevos_nombres=nombres_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carlos</th>\n",
       "      <th>federicoG</th>\n",
       "      <th>federicoR</th>\n",
       "      <th>florencia</th>\n",
       "      <th>francoA</th>\n",
       "      <th>francoS</th>\n",
       "      <th>gerard</th>\n",
       "      <th>gustavo</th>\n",
       "      <th>joaquin</th>\n",
       "      <th>juan</th>\n",
       "      <th>lautaro</th>\n",
       "      <th>lisandro</th>\n",
       "      <th>marco</th>\n",
       "      <th>matias</th>\n",
       "      <th>natalia</th>\n",
       "      <th>noelia</th>\n",
       "      <th>paola</th>\n",
       "      <th>victorio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carlos  federicoG  federicoR  florencia  francoA  francoS  gerard  gustavo  \\\n",
       "0     0.0        0.0        0.0        0.0      0.0     0.01     0.0      0.0   \n",
       "1     0.0        0.0        0.0        0.0      0.0     0.00     0.0      0.0   \n",
       "2     0.0        0.0        0.0        0.0      0.0     0.00     0.0      0.0   \n",
       "3     0.0        0.0        0.0        0.0      0.0     0.00     0.0      0.0   \n",
       "\n",
       "   joaquin  juan  lautaro  lisandro  marco  matias  natalia  noelia  paola  \\\n",
       "0      0.0   0.0     0.79      0.01   0.19     0.0      0.0     0.0    0.0   \n",
       "1      0.0   0.0     1.00      0.00   0.00     0.0      0.0     0.0    0.0   \n",
       "2      0.0   0.0     1.00      0.00   0.00     0.0      0.0     0.0    0.0   \n",
       "3      0.0   0.0     0.00      0.04   0.95     0.0      0.0     0.0    0.0   \n",
       "\n",
       "   victorio  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
     ]
    }
   ],
   "source": [
    "resultado20, df_preds20 = get_preds_predict2(\n",
    "    model=modelos_200[\"prueba_20\"], \n",
    "    n_pca=100,          #<<<---- tiene que tener mismos valores que el experimento\n",
    "    excl_n_prim_comp=3, #<<<---- tiene que tener mismos valores que el experimento\n",
    "    imagenes=imagenes_all, \n",
    "    nombres=nombres_all, \n",
    "    nuevas_imagenes=new_images, \n",
    "    nuevos_nombres=nombres_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carlos</th>\n",
       "      <th>federicoG</th>\n",
       "      <th>federicoR</th>\n",
       "      <th>florencia</th>\n",
       "      <th>francoA</th>\n",
       "      <th>francoS</th>\n",
       "      <th>gerard</th>\n",
       "      <th>gustavo</th>\n",
       "      <th>joaquin</th>\n",
       "      <th>juan</th>\n",
       "      <th>lautaro</th>\n",
       "      <th>lisandro</th>\n",
       "      <th>marco</th>\n",
       "      <th>matias</th>\n",
       "      <th>natalia</th>\n",
       "      <th>noelia</th>\n",
       "      <th>paola</th>\n",
       "      <th>victorio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carlos  federicoG  federicoR  florencia  francoA  francoS  gerard  gustavo  \\\n",
       "0     0.0        0.0       0.02        0.0      0.0      0.0     0.0      0.0   \n",
       "1     0.0        0.0       0.00        0.0      0.0      0.0     0.0      0.0   \n",
       "2     0.0        0.0       0.00        0.0      0.0      0.0     0.0      0.0   \n",
       "3     0.0        0.0       0.00        0.0      0.0      0.0     0.0      0.0   \n",
       "\n",
       "   joaquin  juan  lautaro  lisandro  marco  matias  natalia  noelia  paola  \\\n",
       "0      0.0   0.0     0.97       0.0   0.01     0.0      0.0     0.0    0.0   \n",
       "1      0.0   0.0     1.00       0.0   0.00     0.0      0.0     0.0    0.0   \n",
       "2      0.0   0.0     1.00       0.0   0.00     0.0      0.0     0.0    0.0   \n",
       "3      0.0   0.0     0.00       0.0   0.49     0.0      0.0     0.0    0.5   \n",
       "\n",
       "   victorio  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nuestras_caras_grupo_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
